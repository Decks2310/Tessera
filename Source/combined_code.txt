================================================================================
// File: DSPUtils.h
================================================================================

//================================================================================
// File: DSPUtils.h
//================================================================================
#pragma once
#include <juce_dsp/juce_dsp.h>
#include <random>
#include <array>
#include <cmath> // Included for std::floor, std::abs

namespace DSPUtils
{
    //==============================================================================
    // NEW: Fast Math Approximations
    //==============================================================================

    // Fast approximation of tanh(x) using a Pade approximation variation.
    // Optimized for speed and sufficient accuracy for audio saturation.
    inline float fastTanh(float x)
    {
        // Clamping input range for stability of the approximation
        // The approximation is very accurate within this range.
        if (x > 4.97f) return 1.0f;
        if (x < -4.97f) return -1.0f;

        // Pade (3,3) approximation variation: x * (27 + x^2) / (27 + 9*x^2)
        float x2 = x * x;
        return x * (27.0f + x2) / (27.0f + 9.0f * x2);
    }

    // FIX: Replaced the mathematically incorrect fastSinCycle implementation.
    // The previous version outputted an asymmetric waveform from -1.0 to 3.0, causing
    // significant DC offset and feedback issues in modules like BBDCloud.

    // NEW IMPLEMENTATION (FIXED - Accurate Pade-improved Parabolic Approximation):
    // Fast approximation of sin(2*pi*x). Input x is phase from 0.0 to 1.0.
    inline double fastSinCycle(double x)
    {
        // Ensure x is in [0, 1]
        x = x - std::floor(x);

        // Map [0, 1] to [-PI, PI] for the approximation input
        const double PI = juce::MathConstants<double>::pi;
        const double TWO_PI = juce::MathConstants<double>::twoPi;

        // t is the angle in radians from -PI to PI
        double t = x * TWO_PI - PI;

        // Optimized Parabolic approximation for range [-PI, PI]
        const double B = 4.0 / PI;
        const double C = -4.0 / (PI * PI);

        // Basic parabola
        double y = B * t + C * t * std::abs(t);

        // Pade improvement step (P=0.225) improves accuracy near the peaks.
        const double P = 0.225;
        y = P * (y * std::abs(y) - y) + y;

        return y;
    }


    //==============================================================================
    // NoiseGenerator (Based on Blueprint 1.1, Doc 2 1.3)
    //==============================================================================
    class NoiseGenerator
    {
    public:
        enum class NoiseType { White, Pink };

        NoiseGenerator() : distribution(-1.0f, 1.0f)
        {
            randomEngine.seed(static_cast<unsigned long>(juce::Time::currentTimeMillis()));
            std::fill(pinkState.begin(), pinkState.end(), 0.0f);
        }

        void setType(NoiseType newType) { type = newType; }

        float getNextSample()
        {
            if (type == NoiseType::White)
            {
                return distribution(randomEngine);
            }
            else // Pink Noise (Approximation using Voss-McCartney method)
            {
                float white = distribution(randomEngine);
                // Efficient implementation of Voss-McCartney approximation
                pinkState[0] = 0.99886f * pinkState[0] + white * 0.0555179f;
                pinkState[1] = 0.99332f * pinkState[1] + white * 0.0750759f;
                pinkState[2] = 0.96900f * pinkState[2] + white * 0.1538520f;
                pinkState[3] = 0.86650f * pinkState[3] + white * 0.3104856f;
                pinkState[4] = 0.55000f * pinkState[4] + white * 0.5329522f;
                pinkState[5] = -0.7616f * pinkState[5] - white * 0.0168980f;
                float pink = pinkState[0] + pinkState[1] + pinkState[2] + pinkState[3] + pinkState[4] + pinkState[5] + pinkState[6] + white * 0.5362f;
                pinkState[6] = white * 0.115926f;
                return pink * 0.11f; // Normalize output level
            }
        }

    private:
        NoiseType type = NoiseType::White;
        std::minstd_rand randomEngine;
        std::uniform_real_distribution<float> distribution;
        std::array<float, 7> pinkState;
    };

    //==============================================================================
    // Advanced LFO (Based on Blueprint 1.1, Doc 2 1.3)
    // Replaces juce::dsp::Oscillator with a custom phase accumulator (0.0 to 1.0).
    //==============================================================================
    class LFO
    {
    public:
        enum class Waveform { Sine, Triangle, Saw, Square, SampleAndHold };

        LFO() = default;

        void prepare(const juce::dsp::ProcessSpec& spec)
        {
            sampleRate = spec.sampleRate;
            reset();
        }

        void reset()
        {
            phase = 0.0;
            currentSNHValue = noiseGen.getNextSample();
        }

        void setFrequency(float freqHz)
        {
            if (sampleRate > 0)
                phaseIncrement = (double)freqHz / sampleRate;
            else
                phaseIncrement = 0.0;
        }

        void setWaveform(Waveform newShape) { shape = newShape; }
        // Offset from 0.0 to 1.0
        void setStereoOffset(float offset) { stereoOffset = juce::jlimit(0.0, 1.0, (double)offset); }

        // Returns a pair of L/R samples (Bipolar: -1.0 to 1.0)
        // NOTE: This advances the LFO state. Call only once per sample frame.
        std::pair<float, float> getNextStereoSample()
        {
            // Handle S&H update at the beginning of the cycle
            if (shape == Waveform::SampleAndHold && phase < phaseIncrement)
            {
                currentSNHValue = noiseGen.getNextSample();
            }

            float leftSample = (float)generateWaveform(phase);
            double rightPhase = std::fmod(phase + stereoOffset, 1.0);
            float rightSample = (float)generateWaveform(rightPhase);

            // Advance the main phase
            phase += phaseIncrement;
            if (phase >= 1.0)
                phase -= 1.0;

            return { leftSample, rightSample };
        }

        // Utility functions for mono/backward compatibility
        float getNextBipolar() { return getNextStereoSample().first; }
        float getNextUnipolar() { return (getNextStereoSample().first + 1.0f) * 0.5f; }

    private:
        double generateWaveform(double currentPhase)
        {
            switch (shape)
            {
            case Waveform::Sine:
                return fastSinCycle(currentPhase);
            case Waveform::Triangle:
                if (currentPhase < 0.5)
                    return 4.0 * currentPhase - 1.0;
                else
                    return -4.0 * currentPhase + 3.0;
            case Waveform::Saw:
                return 2.0 * currentPhase - 1.0;
            case Waveform::Square:
                return (currentPhase < 0.5) ? 1.0 : -1.0;
            case Waveform::SampleAndHold:
                return currentSNHValue;
            default:
                return 0.0;
            }
        }

        double sampleRate = 44100.0;
        double phase = 0.0;
        double phaseIncrement = 0.0;
        double stereoOffset = 0.0;
        Waveform shape = Waveform::Sine;
        NoiseGenerator noiseGen;
        float currentSNHValue = 0.0f;
    };

    //==============================================================================
    // Enhanced Envelope Follower (Based on Doc 2 1.3)
    //==============================================================================
    class EnvelopeFollower
    {
    public:
        // Added Curve parameter (0.0 = Linear, 1.0 = Logarithmic)
        void setCurve(float curveAmount) { curve = juce::jlimit(0.0f, 1.0f, curveAmount); }

        void prepare(const juce::dsp::ProcessSpec& spec)
        {
            juce::dsp::ProcessSpec monoSpec = spec;
            monoSpec.numChannels = 1;
            follower.prepare(monoSpec);
            setAttackTime(10.0f);
            setReleaseTime(100.0f);
        }

        void reset() { follower.reset(); }
        void setAttackTime(float attackMs) { follower.setAttackTime(attackMs); }
        void setReleaseTime(float releaseMs) { follower.setReleaseTime(releaseMs); }

        float process(float input)
        {
            float rectified = std::abs(input);

            // Apply curve shaping before smoothing (Doc 2 1.3)
            if (curve > 0.01f)
            {
                // Approximate log curve using a power function.
                // Exponent maps from 1.0 (Linear) down to ~0.3 (Logarithmic).
                float exponent = juce::jmap(curve, 1.0f, 0.3f);
                rectified = std::pow(rectified, exponent);
            }

            // FIX: BallisticsFilter requires the channel index (0 for mono usage).
            return follower.processSample(0, rectified);
        }

    private:
        juce::dsp::BallisticsFilter<float> follower;
        float curve = 0.0f;
    };
}

================================================================================
// File: LUFSMeter.cpp
================================================================================

//================================================================================
// File: LUFSMeter.cpp
//================================================================================
#include "LUFSMeter.h"

LUFSMeter::LUFSMeter() = default;

void LUFSMeter::prepare(const juce::dsp::ProcessSpec& spec)
{
    // K-Weighting Filter Coefficients
    // Stage 1: High-shelf
    stage1Filter.coefficients = juce::dsp::IIR::Coefficients<float>::makeHighShelf(spec.sampleRate, 1500.0f, 0.5f, 4.0f);
    // Stage 2: High-pass
    stage2Filter.coefficients = juce::dsp::IIR::Coefficients<float>::makeHighPass(spec.sampleRate, 38.0f);

    stage1Filter.prepare(spec);
    stage2Filter.prepare(spec);
    weightedBuffer.setSize((int)spec.numChannels, (int)spec.maximumBlockSize);
    // Integration window setup
    momentarySamples = (int)(spec.sampleRate * momentaryIntegrationMs / 1000.0);

    reset();
}

void LUFSMeter::reset()
{
    stage1Filter.reset();
    stage2Filter.reset();
    momentaryBlockLoudness.clear();
    currentMomentaryLoudness = -144.0f;
}

void LUFSMeter::process(const juce::dsp::AudioBlock<float>& block)
{
    // Use a scoped copy of the block to avoid modifying the original
    juce::dsp::AudioBlock<float> weightedBlock(weightedBuffer);
    // Safety check: Ensure the subBlock size matches the input block size and buffer capacity
    auto numSamples = juce::jmin((size_t)weightedBuffer.getNumSamples(), block.getNumSamples());
    if (numSamples == 0) return;

    auto subBlock = weightedBlock.getSubBlock(0, numSamples);
    subBlock.copyFrom(block.getSubBlock(0, numSamples));

    applyKWeighting(subBlock);
    updateGatedLoudness(subBlock);
}

void LUFSMeter::applyKWeighting(juce::dsp::AudioBlock<float>& block)
{
    juce::dsp::ProcessContextReplacing<float> context(block);
    stage1Filter.process(context);
    stage2Filter.process(context);
}

void LUFSMeter::updateGatedLoudness(const juce::dsp::AudioBlock<float>& block)
{
    int numSamples = (int)block.getNumSamples();
    int numChannels = (int)block.getNumChannels();
    // Handle case where there are no channels
    if (numChannels == 0) return;
    for (int i = 0; i < numSamples; ++i)
    {
        double sumSquares = 0.0;
        for (int ch = 0; ch < numChannels; ++ch)
        {
            float sample = block.getSample((size_t)ch, (size_t)i);
            sumSquares += (double)(sample * sample);
        }
        // Calculate mean square for the sample across channels
        float avgSquare = (float)sumSquares / (float)numChannels;
        momentaryBlockLoudness.push_back(avgSquare);

        // Maintain the integration window size
        while (momentaryBlockLoudness.size() > (size_t)momentarySamples)
            momentaryBlockLoudness.pop_front();
    }

    // Calculate momentary loudness (400ms window)
    double momentarySum = 0.0;
    for (const auto& s : momentaryBlockLoudness) momentarySum += s;

    if (!momentaryBlockLoudness.empty() && momentarySum > 0.0)
    {
        // Calculate the mean square over the entire window
        float meanSquare = (float)(momentarySum / (double)momentaryBlockLoudness.size());
        // BS.1770 standard calculation (ensure log10 input is positive)
        currentMomentaryLoudness = -0.691f + 10.0f * std::log10(meanSquare + 1e-10f);
    }
    else
    {
        // Report silence if the buffer is empty or contains only silence.
        currentMomentaryLoudness = -144.0f;
    }
}

float LUFSMeter::getMomentaryLoudness() const { return currentMomentaryLoudness; }

================================================================================
// File: LUFSMeter.h
================================================================================

//================================================================================
// File: LUFSMeter.h
//================================================================================
#pragma once
#include <juce_dsp/juce_dsp.h>
#include <deque>

class LUFSMeter
{
public:
    LUFSMeter();
    void prepare(const juce::dsp::ProcessSpec& spec);
    void reset();
    void process(const juce::dsp::AudioBlock<float>& block);
    // Short-Term Loudness removed for efficiency
    float getMomentaryLoudness() const;
private:
    void applyKWeighting(juce::dsp::AudioBlock<float>& block);
    void updateGatedLoudness(const juce::dsp::AudioBlock<float>& block);

    using Filter = juce::dsp::IIR::Filter<float>;
    using FilterCoefs = juce::dsp::IIR::Coefficients<float>;

    // K-Weighting Filters as per BS.1770-5
    Filter stage1Filter; // High-shelf (head model)
    Filter stage2Filter; // High-pass

    // Buffer for K-weighted signal
    juce::AudioBuffer<float> weightedBuffer;
    // Integration management (Optimized for Momentary only)
    static constexpr int momentaryIntegrationMs = 400;
    int momentarySamples = 0;
    // Buffer storing the mean square values over the integration window
    std::deque<float> momentaryBlockLoudness;

    float currentMomentaryLoudness = -144.0f;
};

================================================================================
// File: PluginEditor.cpp
================================================================================

﻿// File: PluginEditor.cpp
//================================================================================
// File: PluginEditor.cpp
//================================================================================
#include "PluginProcessor.h"
#include "PluginEditor.h"

// A namespace for layout constants to keep the code clean and easy to modify.
namespace LayoutConstants
{
    // UPDATED: Increased header height to 120 to allow the Response knob to be larger and square.
    constexpr int HEADER_HEIGHT = 120; // Was 100
    // UPDATED: Increased bottom strip height to accommodate the Master Mix label.
    constexpr int BOTTOM_STRIP_HEIGHT = 60; // Was 40
    constexpr int ADD_ROW_BUTTON_HEIGHT = 40;
    constexpr int DEFAULT_SLOT_ROW_HEIGHT = 250;
    // ✅ UPDATED: Increased height to give knobs more room
    constexpr int WIDE_SLOT_ROW_HEIGHT = 350;
    constexpr int SLOT_MARGIN = 5;
    // This now represents the width of the CENTRAL area (the grid).
    constexpr int PLUGIN_WIDTH = 840;
    constexpr int NUM_COLS = 4;
    // NEW: Width for the side faders.
    constexpr int FADER_WIDTH = 50;
}

//==============================================================================
ModularMultiFxAudioProcessorEditor::ModuleInfo ModularMultiFxAudioProcessorEditor::getModuleInfo(int choice)
{
    // Choice 7 is ChromaTape, which occupies 3 horizontal slots.
    if (choice == 7)
        return { choice, 3 };
    return { choice, 1 };
}

//==============================================================================
// UPDATED: Constructor
ModularMultiFxAudioProcessorEditor::ModularMultiFxAudioProcessorEditor(ModularMultiFxAudioProcessor& p)
    : AudioProcessorEditor(&p), processorRef(p),
    // UPDATED: Initialize Faders and Knob
    inputGainFader(p.apvts, "INPUT_GAIN", "Input"),
    outputGainFader(p.apvts, "OUTPUT_GAIN", "Output"),
    responseTimeKnob(p.apvts, "SAG_RESPONSE", "Response")
{
    setLookAndFeel(&customLookAndFeel);
    // Listen for resize requests from the processor (e.g., when a module type changes)
    processorRef.editorResizeBroadcaster.addChangeListener(this);
    // NEW: Listen for OS Lock changes
    processorRef.osLockChangeBroadcaster.addChangeListener(this);

    // NEW: Set tooltip for Response Knob
    responseTimeKnob.setTooltip("Dictates how quickly the autogain applies volume compensation (ms). Lower values = fast response; higher values = slow response.");
    addAndMakeVisible(titleLabel);
    titleLabel.setText("TESSERA", juce::dontSendNotification);
    // JUCE 8 FIX (C4996): Use juce::FontOptions
    titleLabel.setFont(juce::FontOptions(24.0f));
    titleLabel.setJustificationType(juce::Justification::centred);
    titleLabel.setColour(juce::Label::textColourId, customLookAndFeel.textColour);
    addAndMakeVisible(subtitleLabel);
    subtitleLabel.setText("MULTIMODULAR FX AUDIO PLUGIN", juce::dontSendNotification);
    // JUCE 8 FIX (C4996): Use juce::FontOptions
    subtitleLabel.setFont(juce::FontOptions(12.0f));
    subtitleLabel.setJustificationType(juce::Justification::centred);
    subtitleLabel.setColour(juce::Label::textColourId, customLookAndFeel.textColour.withAlpha(0.6f));

    // NEW: OS Lock Warning Setup
    addAndMakeVisible(osLockWarningLabel);
    osLockWarningLabel.setText("ChromaTape Active: OS Rate locked to max 2x for stability. (Offline export uses Deluxe 8x).", juce::dontSendNotification);
    osLockWarningLabel.setJustificationType(juce::Justification::centredLeft);
    // Use a distinct color for the warning
    osLockWarningLabel.setColour(juce::Label::textColourId, juce::Colours::orange);

    // JUCE 8 FIX (C2664): Use .withItalic(true) instead of .withStyle(juce::Font::italic).
    osLockWarningLabel.setFont(juce::FontOptions(11.0f).withStyle("Italic"));

    osLockWarningLabel.setVisible(false); // Initially hidden

    // NEW: Oversampling Algorithm Setup
    addAndMakeVisible(oversamplingAlgoBox);
    if (auto* osAlgoParam = processorRef.apvts.getParameter("OVERSAMPLING_ALGO"))
    {
        oversamplingAlgoBox.addItemList(osAlgoParam->getAllValueStrings(), 1);
        oversamplingAlgoAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(processorRef.apvts, "OVERSAMPLING_ALGO", oversamplingAlgoBox);
    }

    // NEW: Oversampling Rate Setup
    addAndMakeVisible(oversamplingRateBox);
    if (auto* osRateParam = processorRef.apvts.getParameter("OVERSAMPLING_RATE"))
    {
        oversamplingRateBox.addItemList(osRateParam->getAllValueStrings(), 1);
        oversamplingRateAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(processorRef.apvts, "OVERSAMPLING_RATE", oversamplingRateBox);
    }


    // Auto-Gain Setup
    addAndMakeVisible(autoGainButton);
    autoGainButton.setButtonText("Auto-Gain");
    // Ensure the attachment links to the correct parameter ID
    autoGainAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ButtonAttachment>(processorRef.apvts, "SAG_ENABLE", autoGainButton);
    // UPDATED: Input/Output/Response Controls Setup (Self-managed attachments)
    addAndMakeVisible(inputGainFader);
    addAndMakeVisible(outputGainFader);
    addAndMakeVisible(responseTimeKnob);
    // Master Mix Setup
    addAndMakeVisible(masterMixLabel);
    masterMixLabel.setText("Master Mix", juce::dontSendNotification);
    masterMixLabel.setJustificationType(juce::Justification::centred);
    // Slightly dimmed text color for aesthetic
    masterMixLabel.setColour(juce::Label::textColourId, customLookAndFeel.textColour.withAlpha(0.7f));
    // JUCE 8 FIX (C4996): Use juce::FontOptions
    masterMixLabel.setFont(juce::FontOptions(14.0f));


    addAndMakeVisible(masterMixSlider);
    masterMixSlider.setSliderStyle(juce::Slider::LinearHorizontal);
    masterMixSlider.setTextBoxStyle(juce::Slider::NoTextBox, false, 0, 0);
    masterMixAttachment = std::make_unique<juce::AudioProcessorValueTreeState::SliderAttachment>(processorRef.apvts, "MASTER_MIX", masterMixSlider);

    addAndMakeVisible(addRowButton);
    addRowButton.onClick = [this]
        {
            int currentSlots = processorRef.visibleSlotCount.getValue();
            if (currentSlots < processorRef.maxSlots)
            {
                // Add a new row of 4 slots, ensuring we don't exceed the maximum.
                int newSlots = std::min(processorRef.maxSlots, currentSlots + LayoutConstants::NUM_COLS);
                processorRef.visibleSlotCount = newSlots;
                updateSlotsAndResize();
            }
        };
    // Initial UI setup
    updateSlotsAndResize();
    // NEW: Initial state update for OS controls
    updateOversamplingControlsState();

}

// UPDATED: Destructor
ModularMultiFxAudioProcessorEditor::~ModularMultiFxAudioProcessorEditor()
{
    setLookAndFeel(nullptr);
    processorRef.editorResizeBroadcaster.removeChangeListener(this);
    // NEW: Remove listener
    processorRef.osLockChangeBroadcaster.removeChangeListener(this);
}

//==============================================================================
void ModularMultiFxAudioProcessorEditor::paint(juce::Graphics& g)
{
    g.fillAll(customLookAndFeel.findColour(juce::ResizableWindow::backgroundColourId));
}

//==============================================================================
// UPDATED: changeListenerCallback
void ModularMultiFxAudioProcessorEditor::changeListenerCallback(juce::ChangeBroadcaster* source)
{
    // NEW: Handle OS Lock changes
    if (source == &processorRef.osLockChangeBroadcaster)
    {
        // This should already be on the message thread (called via callAsync from Processor).
        updateOversamplingControlsState();
        return;
    }

    if (source == &processorRef.editorResizeBroadcaster)
    {
        // ... (Existing resize logic) ...
        juce::Component::SafePointer<ModularMultiFxAudioProcessorEditor> safeThis(this);
        juce::MessageManager::callAsync([safeThis] {
            if (auto* editor = safeThis.getComponent())
            {
                editor->updateSlotsAndResize();
                // NEW: Also update controls state as module selection affects the lock
                editor->updateOversamplingControlsState();
            }
            });
    }
}

// Helper function to get parameter index robustly (handles compatibility issues)
int getParameterIndexRobust(juce::RangedAudioParameter* param)
{
    if (!param) return 0;

    // Preferred method: Use dynamic_cast to access AudioParameterChoice::getIndex()
    if (auto* choiceParam = dynamic_cast<juce::AudioParameterChoice*>(param))
    {
        return choiceParam->getIndex();
    }

    // Fallback: Manual calculation from normalized value.
    int numSteps = param->getNumSteps();
    if (numSteps > 1)
    {
        float normalizedValue = param->getValue();
        // Calculate index = round(normalizedValue * (N-1)).
        // Adding 0.5f before casting implements rounding.
        return static_cast<int>(normalizedValue * (float)(numSteps - 1) + 0.5f);
    }
    return 0;
}


// NEW HELPER FUNCTION: Update UI elements based on the lock status
void ModularMultiFxAudioProcessorEditor::updateOversamplingControlsState()
{
    // === FIX C2039 (getIndex): Helper lambda using the robust index retrieval ===
    // This replaces the reliance on param->getIndex() directly on the base pointer.

    auto syncComboBoxToParameter = [&](juce::ComboBox& box, juce::RangedAudioParameter* param)
        {
            if (param)
            {
                // Use the compatible helper function.
                int index = getParameterIndexRobust(param);
                // Set the ComboBox ID (IDs start at 1)
                box.setSelectedId(index + 1, juce::dontSendNotification);
            }
        };
    // ==================================================================================================

    auto* osRateParam = processorRef.apvts.getParameter("OVERSAMPLING_RATE");
    auto* osAlgoParam = processorRef.apvts.getParameter("OVERSAMPLING_ALGO");

    // Do not lock the UI if we are rendering offline (the user should see the high-quality settings being used).
    if (processorRef.isNonRealtime())
    {
        oversamplingRateBox.setEnabled(true);
        osLockWarningLabel.setVisible(false);

        // Manually sync the UI to the APVTS parameters (replaces missing sendInitialUpdate).
        syncComboBoxToParameter(oversamplingRateBox, osRateParam);
        syncComboBoxToParameter(oversamplingAlgoBox, osAlgoParam);
        return;
    }

    bool isLocked = processorRef.isOversamplingLocked();

    // Disable the rate box if locked. Algorithm box remains enabled.
    oversamplingRateBox.setEnabled(!isLocked);

    // Show/Hide the warning label
    osLockWarningLabel.setVisible(isLocked);

    // Ensure the UI reflects the effective state when locked
    if (isLocked)
    {
        // If locked, the effective rate is capped at 2x. We need to visually reflect this
        // without modifying the underlying parameter (so the user's choice is restored later).
        if (osRateParam)
        {
            // Rate Indices: 0=1x, 1=2x, 2=4x, ...

            // FIX C2039 (getIndex): Use the compatible helper function.
            int currentIndex = getParameterIndexRobust(osRateParam);

            if (currentIndex > 1) // If the user selection (parameter) is > 2x
            {
                // Visually set the (disabled) combo box to 2x (Index 1). IDs start at 1.
                oversamplingRateBox.setSelectedId(1 + 1, juce::dontSendNotification);
            }
            else
            {
                // If the user selection is 1x or 2x, show that selection.
                oversamplingRateBox.setSelectedId(currentIndex + 1, juce::dontSendNotification);
            }
        }
    }
    else
    {
        // When unlocked, ensure the combo box reflects the actual underlying parameter value.
        // Manually sync the ComboBox (replaces missing sendInitialUpdate).
        syncComboBoxToParameter(oversamplingRateBox, osRateParam);
        // It's also good practice to sync the Algo box when unlocking, just in case.
        syncComboBoxToParameter(oversamplingAlgoBox, osAlgoParam);
    }
}


// UPDATED: Modified to calculate the new total width including faders.
void ModularMultiFxAudioProcessorEditor::updateSlotsAndResize()
{
    int slotsToShow = processorRef.visibleSlotCount.getValue();
    // === FIX: Optimized Slot Management ===
    // 1. Add new slots if the count increased
    if (moduleSlots.size() < (size_t)slotsToShow)
    {
        for (int i = (int)moduleSlots.size(); i < slotsToShow; ++i)
        {
            // ModuleSlot now initializes synchronously in its constructor.
            moduleSlots.push_back(std::make_unique<ModuleSlot>(processorRef.apvts, i));
            addAndMakeVisible(*moduleSlots.back());
        }
    }
    // 2. Remove excess slots if the count decreased
    else if (moduleSlots.size() > (size_t)slotsToShow)
    {
        // This deletes the excess components safely.
        moduleSlots.resize(slotsToShow);
    }
    // ======================================

    // --- Calculate new window height based on dynamic content ---
    int totalSlotAreaHeight = 0;
    int currentSlotIndex = 0;
    while (currentSlotIndex < slotsToShow)
    {
        bool isWideModuleInRow = false;
        // Check all slots that start in this row to see if any are ChromaTape
        for (int i = 0; i < LayoutConstants::NUM_COLS; ++i)
        {
            int slotToCheck = currentSlotIndex + i;
            if (slotToCheck < slotsToShow)
            {
                // ... (Logic for checking ChromaTape remains the same) ...
                auto* param = processorRef.apvts.getRawParameterValue("SLOT_" + juce::String(slotToCheck + 1) + "_CHOICE");
                if (param)
                {
                    // Warning C4244 (Line 215): Conversion from float to int.
                    // This static_cast is safe and necessary for AudioParameterChoice.
                    auto choiceVal = param->load();
                    if (getModuleInfo(static_cast<int>(choiceVal)).choice == 7) // 7 is ChromaTape
                    {
                        isWideModuleInRow = true;
                        break;
                    }
                }
            }
        }

        totalSlotAreaHeight += isWideModuleInRow ? LayoutConstants::WIDE_SLOT_ROW_HEIGHT : LayoutConstants::DEFAULT_SLOT_ROW_HEIGHT;
        currentSlotIndex += LayoutConstants::NUM_COLS; // Advance to the start of the next row
    }

    // Calculate total height (Uses the updated BOTTOM_STRIP_HEIGHT automatically)
    int totalHeight = LayoutConstants::HEADER_HEIGHT
        + totalSlotAreaHeight
        + LayoutConstants::ADD_ROW_BUTTON_HEIGHT
        + LayoutConstants::BOTTOM_STRIP_HEIGHT;
    // NEW: Calculate total width (Center width + 2 * Fader width)
    int totalWidth = LayoutConstants::PLUGIN_WIDTH + (LayoutConstants::FADER_WIDTH * 2);
    // Handle addRowButton visibility (remains the same)
    addRowButton.setVisible(slotsToShow < processorRef.maxSlots);
    if (!addRowButton.isVisible())
    {
        totalHeight -= LayoutConstants::ADD_ROW_BUTTON_HEIGHT;
    }

    // === FIX: Ensure Layout Refresh ===
    // Check if the size is actually changing.
    bool sizeChanged = (getWidth() != totalWidth || getHeight() != totalHeight);
    // Set the new size, which will trigger resized() IF the size changed.
    setSize(totalWidth, totalHeight);
    // If the size didn't change (e.g., modules swapped but height is the same), 
    // we must manually call resized() to force the layout update.
    if (!sizeChanged) {
        resized();
    }
}

// UPDATED: resized (Adjust layout for the warning label)
void ModularMultiFxAudioProcessorEditor::resized()
{
    auto bounds = getLocalBounds();

    // === FIX: Revised Layout Strategy ===

    // 1. Carve out the side columns
    auto leftFaderColumn = bounds.removeFromLeft(LayoutConstants::FADER_WIDTH);
    auto rightFaderColumn = bounds.removeFromRight(LayoutConstants::FADER_WIDTH);

    // 2. Header Layout (Central Column)
    auto headerArea = bounds.removeFromTop(LayoutConstants::HEADER_HEIGHT).reduced(10, 2);

    // Divide header into top (title/combos), middle (warning), and bottom (Response knob)
    // UPDATED: Adjust heights to fit the warning label.
    auto headerTop = headerArea.removeFromTop(40);
    // NEW: Add space for the warning label (15px height)
    auto headerWarning = headerArea.removeFromTop(15);
    auto headerBottom = headerArea; // Response knob takes the rest

    // Top Row Layout
    auto osArea = headerTop.removeFromLeft(250).reduced(0, 8);
    oversamplingAlgoBox.setBounds(osArea.removeFromLeft(140));
    osArea.removeFromLeft(10);
    oversamplingRateBox.setBounds(osArea);

    // NEW: Layout the warning label below the OS boxes area.
    // We give it a wider area to fit the text.
    osLockWarningLabel.setBounds(headerWarning.removeFromLeft(550));

    // ... (Auto-Gain, Title/Subtitle layout) ...
    autoGainButton.setBounds(headerTop.removeFromRight(120).reduced(0, 8));
    auto titleBounds = headerTop;
    titleLabel.setBounds(titleBounds.removeFromTop(24));
    subtitleLabel.setBounds(titleBounds);

    // Bottom Row Layout (Response Knob Centered)
    // (FlexBox layout for responseTimeKnob remains the same, using the slightly reduced headerBottom height)
    juce::FlexBox knobFb;
    knobFb.justifyContent = juce::FlexBox::JustifyContent::center;
    knobFb.alignItems = juce::FlexBox::AlignItems::center;
    // Ensure the knob size adapts to the slightly reduced available height.
    float knobComponentSize = (float)headerBottom.getHeight();
    knobFb.items.add(juce::FlexItem(responseTimeKnob).withWidth(knobComponentSize).withHeight(knobComponentSize));
    knobFb.performLayout(headerBottom);


    // 3. Footer Layout (Central Column)
    auto bottomStrip = bounds.removeFromBottom(LayoutConstants::BOTTOM_STRIP_HEIGHT).reduced(20, 5);
    masterMixLabel.setBounds(bottomStrip.removeFromTop(20)); // Label on top
    masterMixSlider.setBounds(bottomStrip); // Slider below the label

    // 4. Add Row Button (Central Column)
    if (addRowButton.isVisible())
    {
        auto addRowArea = bounds.removeFromBottom(LayoutConstants::ADD_ROW_BUTTON_HEIGHT);
        addRowButton.setBounds(addRowArea.withSizeKeepingCentre(40, 30));
    }

    // 'bounds' now represents the main Slot Grid Area.
    // 5. Layout Faders (Aligning vertically with the Slot Grid Area)
    int contentStartY = bounds.getY();
    int contentHeight = bounds.getHeight();

    // Define the area for the fader components within their columns, aligned with the grid.
    // Apply horizontal padding (5px) and vertical padding (10px) relative to the grid area.
    auto leftFaderArea = leftFaderColumn
        .withY(contentStartY)
        .withHeight(contentHeight)
        .reduced(5, 10);
    auto rightFaderArea = rightFaderColumn
        .withY(contentStartY)
        .withHeight(contentHeight)
        .reduced(5, 10);
    inputGainFader.setBounds(leftFaderArea);
    outputGainFader.setBounds(rightFaderArea);

    // === END FIX ===


    // 6. Slot Grid Layout (Central Area)

    // FIX: Use the full central 'bounds' for the slotArea. Margins will be handled per slot.
    // This prevents double margins on the edges and ensures correct alignment with faders.
    // auto slotArea = bounds.reduced(LayoutConstants::SLOT_MARGIN); // OLD
    auto slotArea = bounds; // NEW


    const int numVisibleSlots = processorRef.visibleSlotCount.getValue();
    if (numVisibleSlots == 0 || moduleSlots.empty()) return;

    // Hide all slot components initially.
    for (auto& slot : moduleSlots)
    {
        slot->setVisible(false);
    }

    int currentSlotIndex = 0;
    while (currentSlotIndex < numVisibleSlots)
    {
        // 1. Determine the height for the current row
        bool isWideModuleInRow = false;
        for (int i = 0; i < LayoutConstants::NUM_COLS; ++i)
        {
            int slotToCheck = currentSlotIndex + i;
            if (slotToCheck < numVisibleSlots)
            {
                // ✅ FIX: Added a null check here as well for robustness.
                auto* param = processorRef.apvts.getRawParameterValue("SLOT_" + juce::String(slotToCheck + 1) + "_CHOICE");
                if (param)
                {
                    // Warning C4244: Safe conversion float->int for parameter choice.
                    auto choiceVal = param->load();
                    if (getModuleInfo(static_cast<int>(choiceVal)).choice == 7) // ChromaTape
                    {
                        isWideModuleInRow = true;
                        break;
                    }
                }
            }
        }
        const int currentRowHeight = isWideModuleInRow ? LayoutConstants::WIDE_SLOT_ROW_HEIGHT : LayoutConstants::DEFAULT_SLOT_ROW_HEIGHT;
        auto rowBounds = slotArea.removeFromTop(currentRowHeight);

        // 2. Lay out the modules within this row's bounds
        const float slotWidth = (float)rowBounds.getWidth() / LayoutConstants::NUM_COLS;
        int col = 0;
        while (col < LayoutConstants::NUM_COLS && currentSlotIndex < numVisibleSlots)
        {
            int choice = 0;
            // ✅ FIX: Added a null check for safety during layout.
            auto* param = processorRef.apvts.getRawParameterValue("SLOT_" + juce::String(currentSlotIndex + 1) + "_CHOICE");
            if (param)
            {
                // Warning C4244: Safe conversion float->int for parameter choice.
                choice = static_cast<int>(param->load());
            }
            auto info = getModuleInfo(choice);
            int slotsToUse = info.slotsUsed;

            // Constrain span to prevent wrapping past the end of the row
            if (col + slotsToUse > LayoutConstants::NUM_COLS)
                slotsToUse = LayoutConstants::NUM_COLS - col;

            // Constrain span to prevent going past the total number of visible slots
            if (currentSlotIndex + slotsToUse > numVisibleSlots)
                slotsToUse = numVisibleSlots - currentSlotIndex;

            // Calculate the bounds for this module based on how many slots it uses

            // === FIX for Alignment Issue ===
            // We calculate the absolute X coordinates. Using std::round improves precision for float-based grids.
            int startX = rowBounds.getX() + (int)std::round(col * slotWidth);
            int endX = rowBounds.getX() + (int)std::round((col + slotsToUse) * slotWidth);
            int width = endX - startX;

            // Create the rectangle using the calculated absolute coordinates.
            auto slotBounds = juce::Rectangle<int>(startX, rowBounds.getY(), width, rowBounds.getHeight())
                .reduced(LayoutConstants::SLOT_MARGIN);
            // Set the bounds for the primary slot component and make it visible
            if (currentSlotIndex < moduleSlots.size())
            {
                moduleSlots[currentSlotIndex]->setBounds(slotBounds);
                moduleSlots[currentSlotIndex]->setVisible(true);
            }

            // Advance our column and slot index counters by the number of slots consumed
            col += slotsToUse;
            currentSlotIndex += slotsToUse;
        }
    }
}

================================================================================
// File: PluginEditor.h
================================================================================

﻿// File: PluginEditor.h
//================================================================================
// File: PluginEditor.h
//================================================================================
#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include "PluginProcessor.h"
#include "UI/ModuleSlot.h"
// NEW: Include ParameterUIs for the knobs
#include "UI/ParameterUIs.h" 

class ModularMultiFxAudioProcessorEditor : public juce::AudioProcessorEditor,
    public juce::ChangeListener
{
public:
    explicit ModularMultiFxAudioProcessorEditor(ModularMultiFxAudioProcessor&);
    ~ModularMultiFxAudioProcessorEditor() override;

    void paint(juce::Graphics&) override;
    void resized() override;

    // UPDATED: Listener callback (Handles resize and OS lock changes)
    void changeListenerCallback(juce::ChangeBroadcaster* source) override;
private:
    // ✅ *** ADDED: Helper to get module info (e.g., how many slots it occupies) ***
    struct ModuleInfo { int choice; int slotsUsed = 1; };
    static ModuleInfo getModuleInfo(int choice);

    // ✅ *** ADDED: Helper to manage UI updates and window resizing ***
    void updateSlotsAndResize();

    // NEW: Helper function to update the state of OS controls
    void updateOversamplingControlsState();

    ModularMultiFxAudioProcessor& processorRef;
    CustomLookAndFeel customLookAndFeel;

    // ✅ *** UPDATED: Switched from std::array to std::vector for UI slots ***
    std::vector<std::unique_ptr<ModuleSlot>> moduleSlots;

    juce::Label titleLabel;
    juce::Label subtitleLabel;

    // ✅ *** ADDED: The "+" button to add more rows ***
    juce::TextButton addRowButton{ "+" };
    // Header Controls
    // UPDATED: Replaced single box with two boxes
    // juce::ComboBox oversamplingBox; // REMOVED
    juce::ComboBox oversamplingAlgoBox;
    juce::ComboBox oversamplingRateBox;

    // NEW: Label for OS Lock Warning
    juce::Label osLockWarningLabel;

    juce::ToggleButton autoGainButton;
    // UPDATED: Input/Output Gain Faders and Response Knob
    // These components manage their own attachments internally (see ParameterUIs.h).
    VerticalFaderWithAttachment inputGainFader;  // Changed from RotaryKnobWithLabels
    VerticalFaderWithAttachment outputGainFader; // Changed from RotaryKnobWithLabels
    RotaryKnobWithLabels responseTimeKnob;

    // NEW: Added label for the mix slider
    juce::Label masterMixLabel;
    juce::Slider masterMixSlider;

    // Attachments (Only needed for standard JUCE components)
    // UPDATED: Attachments for the new boxes
    // std::unique_ptr<...> oversamplingAttachment; // REMOVED
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> oversamplingAlgoAttachment;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> oversamplingRateAttachment;

    std::unique_ptr<juce::AudioProcessorValueTreeState::ButtonAttachment> autoGainAttachment;
    std::unique_ptr<juce::AudioProcessorValueTreeState::SliderAttachment> masterMixAttachment;

    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR(ModularMultiFxAudioProcessorEditor)
};

================================================================================
// File: PluginProcessor.cpp
================================================================================

﻿//================================================================================
// File: PluginProcessor.cpp
//================================================================================
#include "PluginProcessor.h"
#include "PluginEditor.h"
#include "FX_Modules/DistortionProcessor.h"
#include "FX_Modules/FilterProcessor.h"
#include "FX_Modules/ModulationProcessor.h"
#include "FX_Modules/AdvancedDelayProcessor.h"
#include "FX_Modules/ReverbProcessor.h"
#include "FX_Modules/AdvancedCompressorProcessor.h"
#include "FX_Modules/ChromaTapeProcessor.h"
// REMOVED: #include "FX_Modules/BBDCloudProcessor.h"
// REMOVED: #include "FX_Modules/FractureTubeProcessor.h"
#include "FX_Modules/MorphoCompProcessor.h"
#include "FX_Modules/PhysicalResonatorProcessor.h"
// NEW INCLUDE
#include "FX_Modules/SpectralAnimatorProcessor.h"

// FIX 1: Corrected PassThroughProcessor Implementation
class PassThroughProcessor : public juce::AudioProcessor
{
public:
    PassThroughProcessor()
        : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
            .withOutput("Output", juce::AudioChannelSet::stereo(), true)) {
    }
    void prepareToPlay(double, int) override {}
    void releaseResources() override {}
    void reset() override {}
    // Correct implementation: Clear unused channels, audio passes through implicitly.
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages) override
    {
        juce::ignoreUnused(midiMessages);
        juce::ScopedNoDenormals noDenormals;
        for (auto i = getTotalNumInputChannels(); i < getTotalNumOutputChannels(); ++i)
            buffer.clear(i, 0, buffer.getNumSamples());
    }
    const juce::String getName() const override {
        return "PassThrough";
    }
    juce::AudioProcessorEditor* createEditor() override {
        return nullptr;
    }
    bool hasEditor() const override {
        return false;
    }
    bool acceptsMidi() const override {
        return false;
    }
    bool producesMidi() const override {
        return false;
    }
    double getTailLengthSeconds() const override {
        return 0.0;
    }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override {
        return 0;
    }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override {
        return {};
    }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}
private:
    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR(PassThroughProcessor)
};
// FIX 2: Updated Constructor
ModularMultiFxAudioProcessor::ModularMultiFxAudioProcessor()
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true))
{
    activeContext = std::make_unique<ProcessingContextWrapper>();
    // UPDATED: Initialize pending and effective OS configuration
    auto defaultAlgo = apvts.getRawParameterValue("OVERSAMPLING_ALGO")->load();
    auto defaultRate = apvts.getRawParameterValue("OVERSAMPLING_RATE")->load();
    OversamplingAlgorithm initialAlgo = static_cast<OversamplingAlgorithm>(static_cast<int>(defaultAlgo));
    OversamplingRate initialRate = static_cast<OversamplingRate>(static_cast<int>(defaultRate));

    pendingOSAlgo.store(initialAlgo);
    pendingOSRate.store(initialRate);
    // Initialize effective configuration (will be properly set in the first processBlock call)
    effectiveOSAlgo.store(initialAlgo);
    effectiveOSRate.store(initialRate);


    visibleSlotCount.setValue(8);
    fxSlotNodes.resize(maxSlots);
    // ... (Listeners setup remains the same) ...
    for (int i = 0; i < maxSlots; ++i)
        apvts.addParameterListener("SLOT_" + juce::String(i + 1) + "_CHOICE", this);
    // UPDATED: Listen to new parameters
       // apvts.addParameterListener("OVERSAMPLING_CHOICE", this); // REMOVED
    apvts.addParameterListener("OVERSAMPLING_ALGO", this);
    apvts.addParameterListener("OVERSAMPLING_RATE", this);

    apvts.addParameterListener("SAG_ENABLE", this);
    apvts.addParameterListener("INPUT_GAIN", this);
    apvts.addParameterListener("OUTPUT_GAIN", this);
    apvts.addParameterListener("SAG_RESPONSE", this);
}

ModularMultiFxAudioProcessor::~ModularMultiFxAudioProcessor()
{
    for (int i = 0; i < maxSlots; ++i)
        apvts.removeParameterListener("SLOT_" + juce::String(i + 1) + "_CHOICE", this);
    // UPDATED: Remove listeners for new parameters
       // apvts.removeParameterListener("OVERSAMPLING_CHOICE", this); // REMOVED
    apvts.removeParameterListener("OVERSAMPLING_ALGO", this);
    apvts.removeParameterListener("OVERSAMPLING_RATE", this);

    apvts.removeParameterListener("SAG_ENABLE", this);
    // REMOVED: Deprecated SAG listeners

    // NEW: Remove listeners
    apvts.removeParameterListener("INPUT_GAIN", this);
    apvts.removeParameterListener("OUTPUT_GAIN", this);
    apvts.removeParameterListener("SAG_RESPONSE", this);
}

// FIX 2: Updated prepareToPlay to use the new context structure.
void ModularMultiFxAudioProcessor::prepareToPlay(double sampleRate, int samplesPerBlock) {

    // ✅ FIX G: Store the configuration
    preparedSampleRate = sampleRate;
    preparedMaxBlockSize = samplesPerBlock;

    double safeSampleRate = preparedSampleRate > 0 ? preparedSampleRate : 44100.0;
    int safeSamplesPerBlock = preparedMaxBlockSize > 0 ?
        preparedMaxBlockSize : 512;

    // Determine the required number of channels
    auto numChannels = juce::jmax(getTotalNumInputChannels(), getTotalNumOutputChannels());
    if (numChannels == 0) numChannels = 2; // Safety fallback

    // ✅ FIX D: Dynamic Oversampling Reconfiguration
    // If the channel count changes, we must force a graph update to recreate the OS engines.
    if (numChannels > 0 && currentOSChannels.load() != numChannels)
    {
        // setupOversamplingEngines removed.
        // FIX: Engine creation is dynamic in initiateGraphUpdate.
        currentOSChannels.store(numChannels);
        // Force graph update to pick up new channel count.
        isGraphDirty.store(true);
    }

    // Configure the active graph (initial configuration)
    if (activeContext && activeContext->graph)
        // Note: The actual sample rate and block size for the graph will be set in updateGraph based on OS settings.
        activeContext->graph->setPlayConfigDetails(getTotalNumInputChannels(), getTotalNumOutputChannels(), safeSampleRate, safeSamplesPerBlock);

    // Ensure buffers match the current configuration
    if (numChannels > 0)
    {
        dryBufferForMixing.setSize(numChannels, safeSamplesPerBlock);
        fadeBuffer.setSize(numChannels, safeSamplesPerBlock);
    }

    juce::dsp::ProcessSpec spec{ safeSampleRate, (juce::uint32)safeSamplesPerBlock, (juce::uint32)numChannels };
    // NEW: Prepare Gain Stages
    inputGainStage.prepare(spec);
    outputGainStage.prepare(spec);
    inputGainStage.setRampDurationSeconds(0.01);
    outputGainStage.setRampDurationSeconds(0.01);

    // REMOVED: Initialization of osEngines map.

    smartAutoGain.prepare(spec);
    updateSmartAutoGainParameters();
    updateGainStages();

    // We must ensure the graph is built correctly based on the pending profile.
    isGraphDirty.store(true);
    if (isGraphDirty.load())
    {
        initiateGraphUpdate();
        // In prepareToPlay, we want the configuration applied immediately without crossfade.
        if (fadeState.load() == FadeState::Fading) {
            fadeState.store(FadeState::Idle);
            previousContext.reset();
        }
    }
    reset();
}

// FIX 2: Updated releaseResources and reset
void ModularMultiFxAudioProcessor::releaseResources() {
    if (activeContext && activeContext->graph) activeContext->graph->releaseResources();
    if (previousContext && previousContext->graph) previousContext->graph->releaseResources();
    smartAutoGain.reset();
    inputGainStage.reset();
    outputGainStage.reset();
}

void ModularMultiFxAudioProcessor::reset() {
    if (activeContext && activeContext->graph) activeContext->graph->reset();
    if (previousContext && previousContext->graph) previousContext->graph->reset();
    smartAutoGain.reset();
    inputGainStage.reset();
    outputGainStage.reset();

    // UPDATED: Reset the oversampler owned by the context.
    if (activeContext && activeContext->oversampler) activeContext->oversampler->reset();
    if (previousContext && previousContext->oversampler) previousContext->oversampler->reset();
    // REMOVED: for (auto& pair : osEngines) ...

    fadeState.store(FadeState::Idle);
    fadeSamplesRemaining = 0;
}

// NEW HELPER FUNCTION
void ModularMultiFxAudioProcessor::updateGainStages() {
    // Ensure these parameters exist before accessing them.
 // Using getRawParameterValue for thread safety.
    if (auto* inputParam = apvts.getRawParameterValue("INPUT_GAIN"))
        inputGainStage.setGainDecibels(inputParam->load());
    if (auto* outputParam = apvts.getRawParameterValue("OUTPUT_GAIN"))
        outputGainStage.setGainDecibels(outputParam->load());
}

// UPDATED: New Signal Flow and Fixed Architecture (FIX 2)
void ModularMultiFxAudioProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages) {

    // NEW: Check and update configuration at the start of every block.
 // This handles changes in offline rendering status or module selections efficiently.
    updateOversamplingConfiguration();

    juce::ScopedNoDenormals noDenormals;
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();
    auto numSamples = buffer.getNumSamples();
    // ... (Buffer clearing, Input Gain, Dry Buffer Copy remains the same as original file) ...
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());
    juce::dsp::AudioBlock<float> mainBlock(buffer);
    auto mainSubBlock = mainBlock.getSubBlock(0, (size_t)numSamples);
    juce::dsp::ProcessContextReplacing<float> inputContext(mainSubBlock);
    inputGainStage.process(inputContext);
    if (dryBufferForMixing.getNumSamples() < numSamples || dryBufferForMixing.getNumChannels() < buffer.getNumChannels())
    {
        dryBufferForMixing.setSize(buffer.getNumChannels(), numSamples, false, true, true);
    }
    juce::dsp::AudioBlock<float> dryBlock(dryBufferForMixing);
    auto drySubBlock = dryBlock.getSubBlock(0, (size_t)numSamples);
    drySubBlock.copyFrom(mainSubBlock);
    // 3. Process Wet Path (Graph processing)

       // Check if configuration needs update.
    if (isGraphDirty.load())
    {
        initiateGraphUpdate();
    }

    // ✅ FIX 2: Process the context using its associated OS and dedicated buffer.
    auto processContext = [&](ProcessingContextWrapper* context, juce::AudioBuffer<float>& targetBuffer) {
        if (!context || !context->graph) return;
        auto* graph = context->graph.get();
        // UPDATED: Use the unique_ptr from the context.
        auto* oversampler = context->oversampler.get();
        auto& graphWorkBuffer = context->oversampledGraphBuffer;
        // Use the dedicated buffer

        if (oversampler != nullptr)
        {
            // 1. Upsample
            juce::dsp::AudioBlock<float> mainBlock(targetBuffer);
            auto upsampledBlock = oversampler->processSamplesUp(mainBlock);

            int requiredSamples = (int)upsampledBlock.getNumSamples();
            int numChannels = (int)upsampledBlock.getNumChannels();
            // 2. Safety check for buffer size (using the dedicated buffer)
            if (graphWorkBuffer.getNumSamples() < requiredSamples || graphWorkBuffer.getNumChannels() < numChannels)
            {
                // Fallback resize if updateGraph didn't size it correctly (should not happen).
                jassertfalse;
                graphWorkBuffer.setSize(numChannels, requiredSamples, false, true, true);
            }

            // 3. Create wrapper for the dedicated buffer.
            juce::AudioBuffer<float> graphBuffer(graphWorkBuffer.getArrayOfWritePointers(), numChannels, 0, requiredSamples);

            // 4. Copy input to dedicated buffer.
            juce::dsp::AudioBlock<float>(graphBuffer).copyFrom(upsampledBlock);
            // 5. Process the graph.
            graph->processBlock(graphBuffer, midiMessages);
            // 6. Copy output from dedicated buffer.
            upsampledBlock.copyFrom(juce::dsp::AudioBlock<float>(graphBuffer));

            // 7. Downsample.
            oversampler->processSamplesDown(mainBlock);
        }
        else
        {
            graph->processBlock(targetBuffer, midiMessages);
        }
        };

    if (fadeState.load() == FadeState::Fading && previousContext)
    {
        // (Copy input to fadeBuffer)
        for (int ch = 0; ch < totalNumInputChannels; ++ch)
        {
            if (ch < fadeBuffer.getNumChannels())
                fadeBuffer.copyFrom(ch, 0, buffer, ch, 0, numSamples);
        }

        // Process using the respective contexts
        processContext(previousContext.get(), fadeBuffer);
        processContext(activeContext.get(), buffer);

        int samplesToFade = std::min(numSamples, fadeSamplesRemaining);
        // ... (Crossfade mixing logic remains the same as original file) ...
        for (int i = 0; i < samplesToFade; ++i)
        {
            float fade = (float)(totalFadeSamples - (fadeSamplesRemaining - i)) / (float)totalFadeSamples;
            float gainIn = fade;
            float gainOut = 1.0f - fade;
            for (int ch = 0; ch < buffer.getNumChannels(); ++ch)
            {
                if (ch < fadeBuffer.getNumChannels()) {
                    float oldSample = fadeBuffer.getSample(ch, i) * gainOut;
                    float newSample = buffer.getSample(ch, i) * gainIn;
                    buffer.setSample(ch, i, oldSample + newSample);
                }
            }
        }

        fadeSamplesRemaining -= samplesToFade;
        if (fadeSamplesRemaining <= 0)
        {
            fadeState.store(FadeState::Idle);
            previousContext.reset(); // Release the old context and its buffer
        }
    }
    else
    {
        processContext(activeContext.get(), buffer);
    }

    // 4. SmartAutoGain processing ... (Rest of processBlock remains the same as original file) ...
    smartAutoGain.process(drySubBlock, mainSubBlock);
    juce::dsp::ProcessContextReplacing<float> outputContext(mainSubBlock);
    outputGainStage.process(outputContext);
    auto mixValue = apvts.getRawParameterValue("MASTER_MIX")->load();
    for (int ch = 0; ch < totalNumOutputChannels; ++ch)
    {
        if (ch < dryBufferForMixing.getNumChannels())
        {
            buffer.applyGain(ch, 0, numSamples, mixValue);
            buffer.addFrom(ch, 0, dryBufferForMixing, ch, 0, numSamples, 1.0f - mixValue);
        }
    }
}

// FIX 2: Updated getTailLengthSeconds
double ModularMultiFxAudioProcessor::getTailLengthSeconds() const {
    if (!activeContext || !activeContext->graph) return 0.0;
    double tail = activeContext->graph->getTailLengthSeconds();
    // UPDATED: Use the unique_ptr.
    auto* oversampler = activeContext->oversampler.get();
    if (oversampler != nullptr && oversampler->getOversamplingFactor() > 1.0)
        tail /= oversampler->getOversamplingFactor();
    return tail;
}

juce::AudioProcessorValueTreeState::ParameterLayout ModularMultiFxAudioProcessor::createParameterLayout() {
    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;

    // UPDATED: Added "Spectral Animator". Indices updated.
 // New indices: 0:Empty..9:Physical Resonator, 10:Spectral Animator
    auto fxChoices = juce::StringArray{ "Empty", "Distortion", "Filter", "Modulation", "Delay", "Reverb", "Compressor",
                                        "ChromaTape", "MorphoComp", "Physical Resonator", "Spectral Animator" };
    for (int i = 0; i < maxSlots; ++i)
    {
        auto slotId = "SLOT_" + juce::String(i + 1);
        params.push_back(std::make_unique<juce::AudioParameterChoice>(slotId + "_CHOICE", slotId + " FX", fxChoices, 0));

        auto slotPrefix = "SLOT_" + juce::String(i + 1) + "_";
        // ... (Existing module parameters remain the same - omitted for brevity) ...
        auto distortionTypes = juce::StringArray{ "Vintage Tube", "Op-Amp", "Germanium Fuzz" };
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "DISTORTION_DRIVE", "Drive", 0.0f, 24.0f, 0.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "DISTORTION_LEVEL", "Level", -24.0f, 24.0f, 0.0f));
        params.push_back(std::make_unique<juce::AudioParameterChoice>(slotPrefix + "DISTORTION_TYPE", "Type", distortionTypes, 0));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "DISTORTION_BIAS", "Bias", -1.0f, 1.0f, 0.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "DISTORTION_CHARACTER", "Character", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterChoice>(slotPrefix + "FILTER_PROFILE", "Profile", juce::StringArray{ "SVF", "Transistor Ladder", "Diode Ladder", "OTA" }, 0));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "FILTER_CUTOFF", "Cutoff", juce::NormalisableRange<float>(20.0f, 20000.0f, 0.0f, 0.25f), 1000.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "FILTER_RESONANCE", "Resonance", 0.1f, 10.0f, 1.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "FILTER_DRIVE", "Drive", 1.0f, 10.0f, 1.0f));
        params.push_back(std::make_unique<juce::AudioParameterChoice>(slotPrefix + "FILTER_TYPE", "SVF Type", juce::StringArray{ "Low-Pass", "Band-Pass", "High-Pass" }, 0));
        params.push_back(std::make_unique<juce::AudioParameterChoice>(slotPrefix + "MODULATION_MODE", "Mode", juce::StringArray{ "Chorus", "Flanger", "Vibrato", "Phaser" }, 0));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MODULATION_RATE", "Rate", 0.01f, 10.0f, 1.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MODULATION_DEPTH", "Depth", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MODULATION_FEEDBACK", "Feedback", -0.95f, 0.95f, 0.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MODULATION_MIX", "Mix", 0.0f, 1.0f, 0.5f));

        auto advDelayPrefix = slotPrefix + "ADVDELAY_";
        params.push_back(std::make_unique<juce::AudioParameterChoice>(advDelayPrefix + "MODE", "Mode", juce::StringArray{ "Tape", "BBD", "Digital" }, 0));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advDelayPrefix + "TIME", "Time (ms)", juce::NormalisableRange<float>(1.0f, 2000.0f, 0.1f, 0.5f), 500.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advDelayPrefix + "FEEDBACK", "Feedback", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advDelayPrefix + "MIX", "Mix", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advDelayPrefix + "COLOR", "Color", juce::NormalisableRange<float>(200.0f, 15000.0f, 0.0f, 0.3f), 5000.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advDelayPrefix + "WOW", "Wow", 0.0f, 1.0f, 0.2f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advDelayPrefix + "FLUTTER", "Flutter", 0.0f, 1.0f, 0.1f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advDelayPrefix + "AGE", "Age", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "REVERB_ROOM_SIZE", "Room Size", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "REVERB_DAMPING", "Damping", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "REVERB_MIX", "Mix", 0.0f, 1.0f, 0.3f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "REVERB_WIDTH", "Width", 0.0f, 1.0f, 1.0f));
        auto advCompPrefix = slotPrefix + "ADVCOMP_";
        params.push_back(std::make_unique<juce::AudioParameterChoice>(advCompPrefix + "TOPOLOGY", "Topology", juce::StringArray{ "VCA Clean", "FET Aggressive", "Opto Smooth" }, 0));
        params.push_back(std::make_unique<juce::AudioParameterChoice>(advCompPrefix + "DETECTOR", "Detector", juce::StringArray{ "Peak", "RMS" }, 0));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advCompPrefix + "THRESHOLD", "Threshold", -60.0f, 0.0f, -12.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advCompPrefix + "RATIO", "Ratio", 1.0f, 20.0f, 4.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advCompPrefix + "ATTACK", "Attack (ms)", juce::NormalisableRange<float>(0.1f, 500.0f, 0.0f, 0.3f), 20.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advCompPrefix + "RELEASE", "Release (ms)", juce::NormalisableRange<float>(10.0f, 2000.0f, 0.0f, 0.3f), 200.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(advCompPrefix + "MAKEUP", "Makeup Gain", 0.0f, 24.0f, 0.0f));
        auto ctPrefix = slotPrefix + "CT_";
        params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + "LOWMID_CROSS", "Low/Mid X-Over", juce::NormalisableRange<float>(50.0f, 1000.0f, 1.0f, 0.3f), 250.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + "MIDHIGH_CROSS", "Mid/High X-Over", juce::NormalisableRange<float>(1000.0f, 10000.0f, 1.0f, 0.3f), 3000.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + "SCRAPE_FLUTTER", "Scrape Flutter", 0.0f, 1.0f, 0.2f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + "CHAOS_AMOUNT", "Chaos Amount", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + "HISS_LEVEL", "Hiss Level (dB)", juce::NormalisableRange<float>(-120.0f, -40.0f, 0.1f), -120.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + "HUM_LEVEL", "Hum Level (dB)", juce::NormalisableRange<float>(-120.0f, -50.0f, 0.1f), -120.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + "HEADBUMP_FREQ", "Head Bump Freq", juce::NormalisableRange<float>(40.0f, 140.0f, 1.0f, 0.5f), 80.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + "HEADBUMP_GAIN", "Head Bump Gain (dB)", 0.0f, 6.0f, 3.0f));
        juce::StringArray bandNames = { "LOW", "MID", "HIGH" };
        for (const auto& band : bandNames)
        {
            params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + band + "_SATURATION", band + " Saturation", 0.0f, 12.0f, 0.0f));
            params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + band + "_WOW", band + " Wow", 0.0f, 1.0f, 0.0f));
            params.push_back(std::make_unique<juce::AudioParameterFloat>(ctPrefix + band + "_FLUTTER", band + " Flutter", 0.0f, 1.0f, 0.0f));
        }

        // MorphoComp Parameters (remain)
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MORPHO_AMOUNT", "Amount", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MORPHO_RESPONSE", "Response", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterChoice>(slotPrefix + "MORPHO_MODE", "Mode", juce::StringArray{ "Auto", "Manual" }, 0));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MORPHO_X", "Morph X", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MORPHO_Y", "Morph Y", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(slotPrefix + "MORPHO_MIX", "Mix", 0.0f, 1.0f, 1.0f));

        // Physical Resonator Parameters (UPDATED)
        auto physResPrefix = slotPrefix + "PHYSRES_";
        // UPDATED: Model choices changed to match the request: "Modal", "Sympathetic", "String"
        params.push_back(std::make_unique<juce::AudioParameterChoice>(physResPrefix + "MODEL", "Model", juce::StringArray{ "Modal", "Sympathetic", "String" }, 0));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "TUNE", "Tune", juce::NormalisableRange<float>(20.0f, 5000.0f, 0.0f, 0.25f), 220.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "STRUCTURE", "Structure", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "BRIGHTNESS", "Brightness", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "DAMPING", "Damping", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "POSITION", "Position", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "EXCITE_TYPE", "Excite Type", 0.0f, 1.0f, 0.8f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "SENSITIVITY", "Sensitivity", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "MIX", "Mix", 0.0f, 1.0f, 1.0f));
        // NEW: Excitation Engine Advanced Parameters (ADSR and Noise Type)
        params.push_back(std::make_unique<juce::AudioParameterChoice>(physResPrefix + "NOISE_TYPE", "Noise Type", juce::StringArray{ "White", "Pink" }, 0));
        // ADSR times in seconds. Using logarithmic scale (0.3f skew factor) for time parameters.
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "ATTACK", "Attack", juce::NormalisableRange<float>(0.001f, 1.0f, 0.0f, 0.3f), 0.001f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "DECAY", "Decay", juce::NormalisableRange<float>(0.01f, 2.0f, 0.0f, 0.3f), 0.05f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "SUSTAIN", "Sustain", 0.0f, 1.0f, 0.0f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(physResPrefix + "RELEASE", "Release", juce::NormalisableRange<float>(0.01f, 2.0f, 0.0f, 0.3f), 0.01f));
        // NEW: Spectral Animator Parameters (Using prefix SPECANIM_)
        auto specAnimPrefix = slotPrefix + "SPECANIM_";
        params.push_back(std::make_unique<juce::AudioParameterChoice>(specAnimPrefix + "MODE", "Mode", juce::StringArray{ "Pitch", "Formant" }, 0));
        // Pitch (Hz): 50Hz to 2000Hz (Logarithmic scale)
        params.push_back(std::make_unique<juce::AudioParameterFloat>(specAnimPrefix + "PITCH", "Pitch (Hz)", juce::NormalisableRange<float>(50.0f, 2000.0f, 0.1f, 0.3f), 440.0f));
        // Formant X/Y (0-1)
        params.push_back(std::make_unique<juce::AudioParameterFloat>(specAnimPrefix + "FORMANT_X", "Formant X (Back/Front)", 0.0f, 1.0f, 0.5f));
        params.push_back(std::make_unique<juce::AudioParameterFloat>(specAnimPrefix + "FORMANT_Y", "Formant Y (Close/Open)", 0.0f, 1.0f, 0.5f));
        // Morph (0-1)
        params.push_back(std::make_unique<juce::AudioParameterFloat>(specAnimPrefix + "MORPH", "Morph", 0.0f, 1.0f, 1.0f));
        // Transient Preservation (0-1)
        params.push_back(std::make_unique<juce::AudioParameterFloat>(specAnimPrefix + "TRANSIENT_PRESERVE", "Transients", 0.0f, 1.0f, 0.8f));
    }

    // Global Parameters (remain)
    params.push_back(std::make_unique<juce::AudioParameterChoice>("OVERSAMPLING_ALGO", "OS Algorithm", juce::StringArray{ "Live (IIR)", "HQ (FIR)", "Deluxe (FIR)" }, 1));
    params.push_back(std::make_unique<juce::AudioParameterChoice>("OVERSAMPLING_RATE", "OS Rate", juce::StringArray{ "1x (Off)", "2x", "4x", "8x", "16x" }, 2));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("MASTER_MIX", "Master Mix", 0.0f, 1.0f, 1.0f));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("INPUT_GAIN", "Input Gain", juce::NormalisableRange<float>(-24.0f, 24.0f, 0.1f), 0.0f));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("OUTPUT_GAIN", "Output Gain", juce::NormalisableRange<float>(-24.0f, 24.0f, 0.1f), 0.0f));
    params.push_back(std::make_unique<juce::AudioParameterBool>("SAG_ENABLE", "Auto-Gain", false));
    params.push_back(std::make_unique<juce::AudioParameterFloat>("SAG_RESPONSE", "Response (ms)",
        juce::NormalisableRange<float>(20.0f, 500.0f, 1.0f, 0.5f), 50.0f));
    return { params.begin(), params.end() };
}
// ... (getStateInformation, setStateInformation, checkForChromaTapeUsage, updateOversamplingConfiguration, initiateGraphUpdate, updateGraph remain the same)
void ModularMultiFxAudioProcessor::getStateInformation(juce::MemoryBlock& destData) {
    auto state = apvts.copyState();
    state.setProperty("visibleSlotCount", visibleSlotCount.getValue(), nullptr);
    std::unique_ptr<juce::XmlElement> xml(state.createXml());
    copyXmlToBinary(*xml, destData);
}

void ModularMultiFxAudioProcessor::setStateInformation(const void* data, int sizeInBytes) {
    std::unique_ptr<juce::XmlElement> xmlState(getXmlFromBinary(data, sizeInBytes));
    if (xmlState != nullptr)
        if (xmlState->hasTagName(apvts.state.getType()))
        {
            apvts.replaceState(juce::ValueTree::fromXml(*xmlState));
            visibleSlotCount.setValue(apvts.state.getProperty("visibleSlotCount", 8));
        }
}

// NEW HELPER FUNCTION: Check if ChromaTape (Choice 7) is active in any visible slot.
bool ModularMultiFxAudioProcessor::checkForChromaTapeUsage() const
{
    int numVisible = visibleSlotCount.getValue();
    for (int i = 0; i < numVisible; ++i)
    {
        auto choiceParamId = "SLOT_" + juce::String(i + 1) + "_CHOICE";
        auto* choiceParam = apvts.getRawParameterValue(choiceParamId);
        if (choiceParam != nullptr && static_cast<int>(choiceParam->load()) == 7)
        {
            return true;
        }
    }
    return false;
}

// NEW HELPER FUNCTION: Centralized logic for determining OS settings.
void ModularMultiFxAudioProcessor::updateOversamplingConfiguration()
{
    OversamplingAlgorithm newAlgo = pendingOSAlgo.load();
    OversamplingRate newRate = pendingOSRate.load();
    bool shouldLock = false;
    if (isNonRealtime())
    {
        newAlgo = OversamplingAlgorithm::Deluxe;
        newRate = OversamplingRate::x8;
    }
    else if (checkForChromaTapeUsage())
    {
        shouldLock = true;
        if (newRate > OversamplingRate::x2)
        {
            newRate = OversamplingRate::x2;
        }
    }

    bool configChanged = (effectiveOSAlgo.load() != newAlgo || effectiveOSRate.load() != newRate);
    bool lockStatusChanged = (oversamplingLockActive.load() != shouldLock);

    if (configChanged)
    {
        effectiveOSAlgo.store(newAlgo);
        effectiveOSRate.store(newRate);
        isGraphDirty.store(true);
    }

    if (lockStatusChanged)
    {
        oversamplingLockActive.store(shouldLock);
        juce::MessageManager::callAsync([this] {
            if (this != nullptr) {
                osLockChangeBroadcaster.sendChangeMessage();
            }
            });
    }
}

// FIX 2: Updated initiateGraphUpdate
void ModularMultiFxAudioProcessor::initiateGraphUpdate() {
    if (previousContext)
    {
        if (previousContext->graph) previousContext->graph->releaseResources();
        previousContext.reset();
    }

    previousContext = std::move(activeContext);
    activeContext = std::make_unique<ProcessingContextWrapper>();

    OversamplingAlgorithm newAlgo = effectiveOSAlgo.load();
    OversamplingRate newRate = effectiveOSRate.load();
    int numChannels = currentOSChannels.load();
    if (numChannels == 0) {
        numChannels = juce::jmax(getTotalNumInputChannels(), getTotalNumOutputChannels());
        if (numChannels == 0) numChannels = 2;
    }

    if (numChannels > 0)
    {
        activeContext->oversampler = createOversamplingEngine(newRate, newAlgo, numChannels);
    }

    if (activeContext->oversampler)
    {
        if (preparedMaxBlockSize > 0)
        {
            activeContext->oversampler->initProcessing(preparedMaxBlockSize);
        }
        activeContext->oversampler->reset();
    }

    if (updateGraph())
    {
        if (getSampleRate() > 0 && previousContext)
        {
            int fadeSamples = (int)(getSampleRate() * crossfadeDurationMs / 1000.0);
            totalFadeSamples = std::max(1, fadeSamples);
            fadeSamplesRemaining = totalFadeSamples;
            fadeState.store(FadeState::Fading);
        }
        isGraphDirty.store(false);
        int totalLatency = 0;
        if (activeContext->oversampler)
            totalLatency = (int)activeContext->oversampler->getLatencyInSamples();
        setLatencySamples(totalLatency);
    }
}

// FIX 1 & 2: Updated updateGraph
bool ModularMultiFxAudioProcessor::updateGraph() {
    if (preparedSampleRate <= 0 || preparedMaxBlockSize <= 0) {
        return false;
    }

    if (!activeContext || !activeContext->graph) return false;
    int numChannels = currentOSChannels.load();
    if (numChannels == 0) {
        numChannels = juce::jmax(getTotalNumInputChannels(), getTotalNumOutputChannels());
        if (numChannels == 0) numChannels = 2;
    }

    activeContext->graph->clear();
    double graphSampleRate = preparedSampleRate;
    int graphBlockSize = preparedMaxBlockSize;
    if (activeContext->oversampler)
    {
        graphSampleRate *= activeContext->oversampler->getOversamplingFactor();
        graphBlockSize = (int)((double)preparedMaxBlockSize * activeContext->oversampler->getOversamplingFactor());
    }

    if (numChannels > 0 && activeContext->oversampler)
    {
        activeContext->oversampledGraphBuffer.setSize(numChannels, graphBlockSize);
    }
    else
    {
        activeContext->oversampledGraphBuffer.setSize(0, 0);
    }

    activeContext->graph->setPlayConfigDetails(numChannels, numChannels, graphSampleRate, graphBlockSize);
    inputNode = activeContext->graph->addNode(std::make_unique<juce::AudioProcessorGraph::AudioGraphIOProcessor>(juce::AudioProcessorGraph::AudioGraphIOProcessor::audioInputNode));
    outputNode = activeContext->graph->addNode(std::make_unique<juce::AudioProcessorGraph::AudioGraphIOProcessor>(juce::AudioProcessorGraph::AudioGraphIOProcessor::audioOutputNode));
    auto connectNodes = [&](juce::AudioProcessorGraph::Node* sourceNode, juce::AudioProcessorGraph::Node* destNode) {
        if (!sourceNode || !destNode) return;
        for (int ch = 0; ch < numChannels; ++ch)
        {
            if (activeContext->graph->canConnect({ { sourceNode->nodeID, ch }, { destNode->nodeID, ch } }))
            {
                activeContext->graph->addConnection({ { sourceNode->nodeID, ch }, { destNode->nodeID, ch } });
            }
        }
        };
    juce::AudioProcessorGraph::Node* lastNode = inputNode.get();
    bool moduleAdded = false;

    int numVisible = visibleSlotCount.getValue();
    const int numCols = 4;
    int slotsConsumed = 0;
    for (int i = 0; i < numVisible; i += slotsConsumed)
    {
        slotsConsumed = 1;
        auto choiceParamId = "SLOT_" + juce::String(i + 1) + "_CHOICE";
        auto* choiceParam = apvts.getRawParameterValue(choiceParamId);
        int choice = (choiceParam != nullptr) ? static_cast<int>(choiceParam->load()) : 0;

        if (choice == 7) {
            slotsConsumed = 3;
        }

        int currentCol = i % numCols;
        if (currentCol + slotsConsumed > numCols)
        {
            slotsConsumed = std::max(1, numCols - currentCol);
        }

        if (i + slotsConsumed > numVisible)
        {
            slotsConsumed = numVisible - i;
        }

        if (slotsConsumed <= 0) break;
        if (choice > 0)
        {
            fxSlotNodes[i] = activeContext->graph->addNode(createProcessorForChoice(choice, i));
            if (fxSlotNodes[i])
            {
                connectNodes(lastNode, fxSlotNodes[i].get());
                lastNode = fxSlotNodes[i].get();
                moduleAdded = true;
            }

            for (int j = 1; j < slotsConsumed; ++j)
            {
                if (i + j < maxSlots) {
                    fxSlotNodes[i + j] = nullptr;
                }
            }
        }
        else
        {
            for (int j = 0; j < slotsConsumed; ++j)
            {
                if (i + j < maxSlots) {
                    fxSlotNodes[i + j] = nullptr;
                }
            }
        }
    }

    if (!moduleAdded)
    {
        auto wireNode = activeContext->graph->addNode(std::make_unique<PassThroughProcessor>());
        if (wireNode)
        {
            connectNodes(lastNode, wireNode.get());
            lastNode = wireNode.get();
        }
    }

    connectNodes(lastNode, outputNode.get());
    activeContext->graph->prepareToPlay(graphSampleRate, graphBlockSize);
    for (auto node : activeContext->graph->getNodes())
    {
        if (node != nullptr && node->getProcessor() != nullptr)
            node->getProcessor()->enableAllBuses();
    }

    return true;
}

std::unique_ptr<juce::AudioProcessor> ModularMultiFxAudioProcessor::createProcessorForChoice(int choice, int slotIndex) {
    switch (choice)
    {
    case 1: return std::make_unique<DistortionProcessor>(apvts, slotIndex);
    case 2: return std::make_unique<FilterProcessor>(apvts, slotIndex);
    case 3: return std::make_unique<ModulationProcessor>(apvts, slotIndex);
    case 4: return std::make_unique<AdvancedDelayProcessor>(apvts, slotIndex);
    case 5: return std::make_unique<ReverbProcessor>(apvts, slotIndex);
    case 6: return std::make_unique<AdvancedCompressorProcessor>(apvts, slotIndex);
    case 7: return std::make_unique<ChromaTapeProcessor>(apvts, slotIndex);
        // REMOVED: Case 8 (BBDCloud)
               // REMOVED: Case 9 (FractureTube)
    case 8: return std::make_unique<MorphoCompProcessor>(apvts, slotIndex);
        // Renumbered from 10
    case 9: return std::make_unique<PhysicalResonatorProcessor>(apvts, slotIndex);
        // Renumbered from 11
               // NEW CASE
    case 10: return std::make_unique<SpectralAnimatorProcessor>(apvts, slotIndex);
    default: return nullptr;
    }
}

void ModularMultiFxAudioProcessor::parameterChanged(const juce::String& parameterID, float newValue) {
    if (parameterID.endsWith("_CHOICE") && parameterID.startsWith("SLOT_"))
    {
        isGraphDirty.store(true);
        editorResizeBroadcaster.sendChangeMessage();
    }

    if (parameterID == "OVERSAMPLING_ALGO")
    {
        OversamplingAlgorithm newAlgo = static_cast<OversamplingAlgorithm>(static_cast<int>(newValue));
        pendingOSAlgo.store(newAlgo);
    }
    else if (parameterID == "OVERSAMPLING_RATE")
    {
        OversamplingRate newRate = static_cast<OversamplingRate>(static_cast<int>(newValue));
        pendingOSRate.store(newRate);
    }

    if (parameterID.startsWith("SAG_"))
        updateSmartAutoGainParameters();
    if (parameterID == "INPUT_GAIN" || parameterID == "OUTPUT_GAIN")
        updateGainStages();
}

void ModularMultiFxAudioProcessor::updateSmartAutoGainParameters() {
    if (auto* pEnable = apvts.getRawParameterValue("SAG_ENABLE"))
        smartAutoGain.setEnabled(pEnable->load() > 0.5f);
    if (auto* pResponse = apvts.getRawParameterValue("SAG_RESPONSE"))
    {
        smartAutoGain.setResponseTime(pResponse->load());
    }
}

std::unique_ptr<juce::dsp::Oversampling<float>> ModularMultiFxAudioProcessor::createOversamplingEngine(OversamplingRate rate, OversamplingAlgorithm algo, int numChannels)
{
    if (numChannels <= 0 || rate == OversamplingRate::x1)
        return nullptr;
    int stages = 0;
    switch (rate)
    {
    case OversamplingRate::x2: stages = 1; break;
    case OversamplingRate::x4: stages = 2; break;
    case OversamplingRate::x8: stages = 3; break;
    case OversamplingRate::x16: stages = 4; break;
    default: return nullptr;
    }

    juce::dsp::Oversampling<float>::FilterType filterType;
    bool useLinearPhase = true;
    switch (algo)
    {
    case OversamplingAlgorithm::Live:
        filterType = juce::dsp::Oversampling<float>::filterHalfBandPolyphaseIIR;
        useLinearPhase = false;
        break;
    case OversamplingAlgorithm::HQ:
    case OversamplingAlgorithm::Deluxe:
        filterType = juce::dsp::Oversampling<float>::filterHalfBandFIREquiripple;
        useLinearPhase = true;
        break;
    }

    return std::make_unique<juce::dsp::Oversampling<float>>(
        (size_t)numChannels,
        stages,
        filterType,
        useLinearPhase
    );
}

juce::AudioProcessorEditor* ModularMultiFxAudioProcessor::createEditor() {
    return new ModularMultiFxAudioProcessorEditor(*this);
}

juce::AudioProcessor* JUCE_CALLTYPE createPluginFilter() {
    return new ModularMultiFxAudioProcessor();
}

================================================================================
// File: PluginProcessor.h
================================================================================

﻿// File: PluginProcessor.h
#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>
#include "SmartAutoGain.h"

#if JucePlugin_Build_VST3
#define JucePlugin_Vst3Category "Fx"
#endif

class ModularMultiFxAudioProcessorEditor;

// NEW: Define Oversampling Configuration Enums
enum class OversamplingAlgorithm
{
    Live,    // Polyphase IIR (Fast, Non-Linear Phase)
    HQ,      // FIR Equiripple (Standard, Linear Phase)
    Deluxe   // FIR Equiripple (High Quality, Linear Phase)
};

enum class OversamplingRate
{
    x1,  // Off
    x2,
    x4,
    x8,
    x16
};

// FIX Issue 2: Structure to hold a graph, its oversampler, and its dedicated buffer
struct ProcessingContextWrapper {
    std::unique_ptr<juce::AudioProcessorGraph> graph = std::make_unique<juce::AudioProcessorGraph>();
    // UPDATED: Now owns the oversampler instance for this context.
    std::unique_ptr<juce::dsp::Oversampling<float>> oversampler;
    // Dedicated buffer for this context's oversampled processing.
    juce::AudioBuffer<float> oversampledGraphBuffer;
};

class ModularMultiFxAudioProcessor : public juce::AudioProcessor,
    public juce::AudioProcessorValueTreeState::Listener
{
public:
    ModularMultiFxAudioProcessor();
    ~ModularMultiFxAudioProcessor() override;
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;
    // ... (Boilerplate methods omitted for brevity, remain the same as original) ...
    juce::AudioProcessorEditor* createEditor() override;
    bool hasEditor() const override { return true; }
    const juce::String getName() const override { return JucePlugin_Name; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    double getTailLengthSeconds() const override;
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int index) override { juce::ignoreUnused(index); }
    const juce::String getProgramName(int index) override { juce::ignoreUnused(index); return {}; }
    void changeProgramName(int index, const juce::String& newName) override { juce::ignoreUnused(index, newName); }
    void getStateInformation(juce::MemoryBlock& destData) override;
    void setStateInformation(const void* data, int sizeInBytes) override;
    void parameterChanged(const juce::String& parameterID, float newValue) override;

    // NEW: Public method for the Editor to check the lock status
    bool isOversamplingLocked() const { return oversamplingLockActive.load(); }

    // NEW: Broadcaster for OS Lock changes (distinct from editorResizeBroadcaster)
    juce::ChangeBroadcaster osLockChangeBroadcaster;

    static constexpr int maxSlots = 16;
    juce::Value visibleSlotCount;
    juce::ChangeBroadcaster editorResizeBroadcaster;


    juce::AudioProcessorValueTreeState::ParameterLayout createParameterLayout();
    juce::AudioProcessorValueTreeState apvts{ *this, nullptr, "Parameters", createParameterLayout() };
private:
    // ✅ FIX G: Store maximum block size and sample rate for reliable graph configuration
    double preparedSampleRate = 0.0;
    int preparedMaxBlockSize = 0;

    bool updateGraph();
    void initiateGraphUpdate();
    // NEW: Helper functions for centralized OS management
    void updateOversamplingConfiguration();
    bool checkForChromaTapeUsage() const;
    std::unique_ptr<juce::AudioProcessor> createProcessorForChoice(int choice, int slotIndex);
    void updateSmartAutoGainParameters();
    void updateGainStages();

    // UPDATED: Helper to create a specific engine instance dynamically.
    std::unique_ptr<juce::dsp::Oversampling<float>> createOversamplingEngine(OversamplingRate rate, OversamplingAlgorithm algo, int numChannels);

    // REMOVED: setupOversamplingEngines() and osEngines map.

    // UPDATED: Atomics to track the desired configuration (User's UI selection).
    std::atomic<OversamplingAlgorithm> pendingOSAlgo;
    std::atomic<OversamplingRate> pendingOSRate;

    // NEW: Atomics to track the effective configuration (After applying locks/overrides).
    std::atomic<OversamplingAlgorithm> effectiveOSAlgo;
    std::atomic<OversamplingRate> effectiveOSRate;

    // NEW: Atomic to track the lock status
    std::atomic<bool> oversamplingLockActive{ false };

    // ✅ FIX D: Track the number of channels currently configured (used for dynamic reconfiguration detection)
    std::atomic<int> currentOSChannels{ 0 };
    SmartAutoGain smartAutoGain;

    // NEW: Input and Output Gain Stages for integrated gain staging
    juce::dsp::Gain<float> inputGainStage;
    juce::dsp::Gain<float> outputGainStage;
    // === FIX N: Delay line for Dry Path Latency Compensation ===
    // REMOVED: No longer needed as the new AutoGain is zero-latency.
    // ===========================================================

    // ✅ UPDATED: Dual Graph System for Crossfading (Now using Context Wrapper)
    std::unique_ptr<ProcessingContextWrapper> activeContext;
    // Holds the previous context during crossfade
    std::unique_ptr<ProcessingContextWrapper> previousContext;
    // ✅ NEW: Crossfade Management
    enum class FadeState { Idle, Fading };
    std::atomic<FadeState> fadeState{ FadeState::Idle };
    juce::AudioBuffer<float> fadeBuffer; // Buffer for the previous graph output
    int fadeSamplesRemaining = 0;
    int totalFadeSamples = 0;
    static constexpr double crossfadeDurationMs = 10.0; // 10ms crossfade


    // These pointers are now relative to the *activeContext->graph* during updateGraph()
    juce::AudioProcessorGraph::Node::Ptr inputNode;
    juce::AudioProcessorGraph::Node::Ptr outputNode;
    std::vector<juce::AudioProcessorGraph::Node::Ptr> fxSlotNodes;
    std::atomic<bool> isGraphDirty{ true };

    juce::AudioBuffer<float> dryBufferForMixing;
    // ✅ FIX E: Removed global oversampledGraphBuffer, now managed within ProcessingContextWrapper.

    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR(ModularMultiFxAudioProcessor)
};

================================================================================
// File: SmartAutoGain.cpp
================================================================================

﻿//================================================================================
// File: SmartAutoGain.cpp
//================================================================================
#include "SmartAutoGain.h"

SmartAutoGain::SmartAutoGain() {}

void SmartAutoGain::prepare(const juce::dsp::ProcessSpec& spec) {
    sampleRate = spec.sampleRate;
    inputLoudnessMeter.prepare(spec);
    wetLoudnessMeter.prepare(spec);
    // Fast 10ms fade for enable/disable transitions
    enabledSmoother.reset(spec.sampleRate, 0.01);
    // Initialize gain smoother with the current response time
    setResponseTime(responseTimeMs);

    reset();
}

void SmartAutoGain::reset() {
    inputLoudnessMeter.reset();
    wetLoudnessMeter.reset();

    enabledSmoother.setCurrentAndTargetValue(enabled ? 1.0f : 0.0f);
    gainSmoother.setCurrentAndTargetValue(1.0f); // Start with unity gain
}

// New implementation of the core differential logic
void SmartAutoGain::process(const juce::dsp::AudioBlock<float>& dryBlock, juce::dsp::AudioBlock<float>& wetBlock) {

    // Update bypass smoother target
    enabledSmoother.setTargetValue(enabled ? 1.0f : 0.0f);
    // --- BYPASS LOGIC ---
    // If completely disabled and the fade-out is finished, do nothing.
    if (!enabled && !enabledSmoother.isSmoothing() && enabledSmoother.getCurrentValue() < 1e-6f)
    {
        // Ensure gain smoother resets to unity if we bypass, just in case.
        if (gainSmoother.getCurrentValue() != 1.0f)
            gainSmoother.setCurrentAndTargetValue(1.0f);
        return;
    }

    // Ensure block sizes match for safety
    // === FIX C4267: Use int for sample count to address warnings ===
    int numSamples = (int)juce::jmin(dryBlock.getNumSamples(), wetBlock.getNumSamples());
    // ===============================================================

    if (numSamples == 0) return;

    // getSubBlock requires size_t for the length argument.
    auto drySubBlock = dryBlock.getSubBlock(0, (size_t)numSamples);
    auto wetSubBlock = wetBlock.getSubBlock(0, (size_t)numSamples);
    // 1. Analyze both dry and wet signals (Always analyze to keep meters updated)
    inputLoudnessMeter.process(drySubBlock);
    wetLoudnessMeter.process(wetSubBlock);
    // 2. Calculate loudness delta
    float dryLufs = inputLoudnessMeter.getMomentaryLoudness();
    float wetLufs = wetLoudnessMeter.getMomentaryLoudness();
    // Define a noise floor to prevent extreme gain with silent input
    constexpr float silenceThresholdLufs = -70.0f;
    float targetGain = 1.0f;

    if (dryLufs > silenceThresholdLufs && wetLufs > silenceThresholdLufs)
    {
        // Calculate the difference: Gain needed = Dry LUFS - Wet LUFS
        float loudnessDeltaDb = dryLufs - wetLufs;
        // Clamp the correction to a reasonable range (e.g., +/- 24dB) for safety
        loudnessDeltaDb = juce::jlimit(-24.0f, 24.0f, loudnessDeltaDb);
        // Convert dB difference to linear gain factor
        targetGain = juce::Decibels::decibelsToGain(loudnessDeltaDb);
    }

    // 3. Set the target for the gain smoother
    gainSmoother.setTargetValue(targetGain);
    // 4. Apply the smoothed gain to the wet block
    // We combine the auto-gain value with the bypass fade value for smooth transitions.
    // We must process per-sample if either the gain smoother OR the bypass smoother is active.
    if (gainSmoother.isSmoothing() || enabledSmoother.isSmoothing())
    {
        // === FIX C4267: Use int for channel count and loop indices ===
        int numChannels = (int)wetSubBlock.getNumChannels();
        for (int i = 0; i < numSamples; ++i)
        {
            // Get the current auto-gain value (multiplicative smoothing)
            float autoGain = gainSmoother.getNextValue();
            // Get the current bypass fade value (linear smoothing: 1.0=active, 0.0=bypassed)
            float bypassMix = enabledSmoother.getNextValue();
            // Calculate the final applied gain: Interpolate between unity (1.0) and autoGain.
            // When bypassMix is 1.0, finalGain = autoGain.
            // When bypassMix is 0.0, finalGain = 1.0.
            float finalGain = (autoGain * bypassMix) + (1.0f * (1.0f - bypassMix));
            for (int ch = 0; ch < numChannels; ++ch)
            {
                // Use int indices (ch, i) as required by the compiler in this context.
                wetSubBlock.setSample(ch, i, wetSubBlock.getSample(ch, i) * finalGain);
            }
        }
        // ===============================================================
    }
    else if (enabled)
    {
        // Optimization: If fully enabled and gain is settled, we can use the faster block-based operation.
        // Since we checked isSmoothing() == false, we know the gain is constant.
        // === FIX C2665: SmoothedValue::applyGain does not accept AudioBlock. ===
        // Use AudioBlock::multiplyBy() instead.
        // OLD: gainSmoother.applyGain(wetSubBlock, (int)numSamples);
        wetSubBlock.multiplyBy(gainSmoother.getCurrentValue());
        // =======================================================================
    }
}

void SmartAutoGain::setEnabled(bool isEnabled) {
    enabled = isEnabled;
    // Target value update is handled at the start of the process loop
}

// New Control Implementation
void SmartAutoGain::setResponseTime(float timeMs) {
    // Enforce a practical range (e.g., 10ms min, 1000ms max)
    responseTimeMs = juce::jlimit(10.0f, 1000.0f, timeMs);
    // Update the smoother's ramp length based on the new time (converted to seconds)
    if (sampleRate > 0)
        gainSmoother.reset(sampleRate, responseTimeMs / 1000.0);
}

================================================================================
// File: SmartAutoGain.h
================================================================================

//================================================================================
// File: SmartAutoGain.h
//================================================================================
#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>
#include "LUFSMeter.h"

/**
 * State-of-the-Art Auto-Gain System based on differential Momentary LUFS matching.
 */
class SmartAutoGain
{
public:
    SmartAutoGain();

    void prepare(const juce::dsp::ProcessSpec& spec);
    void reset();
    // New Unified process method: Analyzes dry, analyzes wet, and applies gain to wetBlock.
    void process(const juce::dsp::AudioBlock<float>& dryBlock, juce::dsp::AudioBlock<float>& wetBlock);
    // The new architecture has zero latency.
    int getLatencyInSamples() const { return 0; }

    void setEnabled(bool isEnabled);
    // New Control: Allows user adjustment of the smoothing speed.
    void setResponseTime(float timeMs);
private:
    // Removed all inner classes (AnalysisEngine, DualPathProcessor, DynamicEQ, TruePeakLimiter)

    bool enabled = false;
    double sampleRate = 44100.0;

    // Meters for input (dry) and output (wet) signals
    LUFSMeter inputLoudnessMeter;
    LUFSMeter wetLoudnessMeter;
    // Smoother for the enable/disable bypass fade (Linear is fine for bypass mixing)
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> enabledSmoother;
    // Gain smoother using Multiplicative smoothing (Psychoacoustically correct for gain changes)
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Multiplicative> gainSmoother;
    float responseTimeMs = 50.0f; // Default response time (50ms)
};

================================================================================
// File: DSP_Helpers/InterpolatedCircularBuffer.h
================================================================================

//================================================================================
// File: DSP_Helpers/InterpolatedCircularBuffer.h
//================================================================================
#pragma once
#include <juce_dsp/juce_dsp.h>
#include <cmath>
#include <algorithm>

// Implements Cubic interpolation.
class InterpolatedCircularBuffer
{
public:
    void prepare(const juce::dsp::ProcessSpec& spec, int sizeInSamples)
    {
        // Add margins for interpolation safety at boundaries
        buffer.setSize((int)spec.numChannels, sizeInSamples + INTERP_MARGIN * 2);
        bufferSize = sizeInSamples;
        numChannels = (int)spec.numChannels;
        writePos = INTERP_MARGIN; // Start writing after the initial margin
        reset();
    }

    void reset()
    {
        buffer.clear();
        writePos = INTERP_MARGIN;
        if (bufferSize > 0)
        {
            updateMargins();
        }
    }

    // Write block into the circular buffer
    void write(const juce::dsp::AudioBlock<float>& block)
    {
        int numSamples = (int)block.getNumSamples();
        int blockChannels = (int)block.getNumChannels();

        for (int i = 0; i < numSamples; ++i)
        {
            for (int ch = 0; ch < numChannels; ++ch)
            {
                if (ch < blockChannels)
                    buffer.setSample(ch, writePos, block.getSample(ch, i));
            }

            writePos++;

            // Handle wraparound and update margins
            if (writePos >= bufferSize + INTERP_MARGIN)
            {
                writePos = INTERP_MARGIN;
                updateMargins();
            }
        }
    }

    // Read interpolated sample at a fractional position (relative to logical buffer bounds [0, bufferSize))
    float read(int channel, float fractionalPosition)
    {
        if (channel >= numChannels || bufferSize == 0) return 0.0f;

        // Ensure position is within logical bounds [0, bufferSize) using fmod
        fractionalPosition = std::fmod(fractionalPosition, (float)bufferSize);
        if (fractionalPosition < 0.0f) fractionalPosition += (float)bufferSize;

        // Adjust position relative to the physical start (INTERP_MARGIN)
        float physicalPosition = fractionalPosition + INTERP_MARGIN;

        const float* data = buffer.getReadPointer(channel);

        // Cubic Interpolation
        int i0 = (int)std::floor(physicalPosition);
        float fraction = physicalPosition - (float)i0;

        // Indices are safe because of the margins
        float ym1 = data[i0 - 1];
        float y0 = data[i0];
        float y1 = data[i0 + 1];
        float y2 = data[i0 + 2];

        // Optimized Cubic interpolation formula
        float c0 = y0;
        float c1 = 0.5f * (y1 - ym1);
        float c2 = ym1 - 2.5f * y0 + 2.0f * y1 - 0.5f * y2;
        float c3 = 0.5f * (y2 - ym1) + 1.5f * (y0 - y1);

        return ((c3 * fraction + c2) * fraction + c1) * fraction + c0;
    }

    int getSize() const { return bufferSize; }

    // FIX: Added getNumChannels accessor required by FractureTubeProcessor
    int getNumChannels() const { return numChannels; }

    // Returns the current write position relative to the logical start (0)
    int getWritePosition() const
    {
        return writePos - INTERP_MARGIN;
    }

private:
    // Updates the margins by copying data from the opposite end of the buffer.
    void updateMargins()
    {
        // Copy end of logical buffer to beginning margin
        for (int ch = 0; ch < numChannels; ++ch)
        {
            buffer.copyFrom(ch, 0, buffer, ch, bufferSize, INTERP_MARGIN);
        }
        // Copy beginning of logical buffer to end margin
        for (int ch = 0; ch < numChannels; ++ch)
        {
            buffer.copyFrom(ch, bufferSize + INTERP_MARGIN, buffer, ch, INTERP_MARGIN, INTERP_MARGIN);
        }
    }

    juce::AudioBuffer<float> buffer;
    int bufferSize = 0;
    int writePos = 0;
    int numChannels = 0;
    static constexpr int INTERP_MARGIN = 4;
};

================================================================================
// File: DSP_Helpers/SpectralAnalyzer.cpp
================================================================================

//================================================================================
// File: DSP_Helpers/SpectralAnalyzer.cpp
//================================================================================
#include "SpectralAnalyzer.h"

SpectralAnalyzer::SpectralAnalyzer()
    : fft(FFT_ORDER),
    // JUCE 8: Initialize using the WindowingMethod enum.
    window(FFT_SIZE, juce::dsp::WindowingFunction<float>::WindowingMethod::hann)
{
}

void SpectralAnalyzer::prepare(const juce::dsp::ProcessSpec& spec)
{
    sampleRate = spec.sampleRate;
    // Initialize buffers
    inputFIFO.resize(FFT_SIZE, 0.0f);
    fftData.resize(FFT_SIZE * 2, 0.0f); // JUCE requires 2*N for real-only FFT

    // Initialize smoothing (e.g., 30ms response time)
    smoothedCentroid.reset(spec.sampleRate, 0.03);

    reset();
}

void SpectralAnalyzer::reset() {
    fifoIndex = 0;
    std::fill(inputFIFO.begin(), inputFIFO.end(), 0.0f);
    smoothedCentroid.setCurrentAndTargetValue(0.5f); // Start neutral
}

// FIX: Removed process(block) and replaced with processSample(monoSample)
// void SpectralAnalyzer::process(const juce::dsp::AudioBlock<float>& block) { ... } // REMOVED

// NEW IMPLEMENTATION: Process sample-by-sample
void SpectralAnalyzer::processSample(float monoSample) {
    // Safety check for buffer size
    if (fifoIndex >= (int)inputFIFO.size())
    {
        // Advance smoother anyway to maintain timing.
        smoothedCentroid.getNextValue();
        return;
    }

    // Push sample into FIFO
    inputFIFO[fifoIndex] = monoSample;
    fifoIndex++;

    // Check if a frame is ready
    if (fifoIndex == FFT_SIZE)
    {
        processFrame();
        // Shift FIFO for overlap (OLA implementation)
        // Ensure inputFIFO is large enough before copying (safety check)
        if ((int)inputFIFO.size() >= FFT_SIZE)
        {
            std::copy(inputFIFO.begin() + HOP_SIZE, inputFIFO.end(), inputFIFO.begin());
        }
        fifoIndex = FFT_SIZE - HOP_SIZE; // Corrected index after shift
    }

    // CRITICAL: Advance the smoother sample-by-sample for accurate control signal timing
    smoothedCentroid.getNextValue();
}

// Blueprint 1.2: Spectral Centroid Calculation
void SpectralAnalyzer::processFrame() {
    // 1. Copy FIFO to FFT buffer and apply window
    std::copy(inputFIFO.begin(), inputFIFO.end(), fftData.begin());
    window.multiplyWithWindowingTable(fftData.data(), FFT_SIZE);

    // 2. Perform Forward FFT
    fft.performRealOnlyForwardTransform(fftData.data());

    // 3. Calculate Spectral Centroid
    float weightedSum = 0.0f;
    float totalSum = 0.0f;
    int numBins = FFT_SIZE / 2 + 1;
    float nyquist = (float)sampleRate * 0.5f;

    for (int i = 1; i < numBins; ++i) // Start from bin 1 (skip DC)
    {
        float real, imag;
        // Unpack JUCE format
        if (i == FFT_SIZE / 2) { real = fftData[1]; imag = 0.0f; } // Nyquist
        else { real = fftData[2 * i]; imag = fftData[2 * i + 1]; }

        float magnitude = std::sqrt(real * real + imag * imag);

        // Calculate frequency of the bin
        float freq = (float)i * (float)sampleRate / (float)FFT_SIZE;

        weightedSum += magnitude * freq;
        totalSum += magnitude;
    }

    // 4. Normalize and set target
    if (totalSum > 1e-6f)
    {
        float centroidFreq = weightedSum / totalSum;
        // Normalize centroid relative to Nyquist
        float normalizedCentroid = centroidFreq / nyquist;
        smoothedCentroid.setTargetValue(juce::jlimit(0.0f, 1.0f, normalizedCentroid));
    }
}


================================================================================
// File: DSP_Helpers/SpectralAnalyzer.h
================================================================================

//================================================================================
// File: DSP_Helpers/SpectralAnalyzer.h
//================================================================================
#pragma once
#include <juce_dsp/juce_dsp.h>
#include <vector>
#include <algorithm>
#include <cmath>

class SpectralAnalyzer
{
public:
    // Configuration: FFT size 512 provides a good balance of time/frequency resolution and efficiency.
    static constexpr int FFT_ORDER = 9;
    static constexpr int FFT_SIZE = 1 << FFT_ORDER;
    static constexpr int HOP_SIZE = FFT_SIZE / 2; // 50% overlap

    SpectralAnalyzer();

    void prepare(const juce::dsp::ProcessSpec& spec);
    void reset();

    // FIX: Changed interface to process sample-by-sample
    // void process(const juce::dsp::AudioBlock<float>& block); // REMOVED
    void processSample(float monoSample);

    // Returns the current smoothed spectral centroid (0.0 = low/dark, 1.0 = high/bright).
    float getSpectralCentroid() const { return smoothedCentroid.getCurrentValue(); }
private:
    void processFrame();

    double sampleRate = 44100.0;
    juce::dsp::FFT fft;
    juce::dsp::WindowingFunction<float> window;

    // Buffering for OLA (Mono analysis)
    std::vector<float> inputFIFO;
    std::vector<float> fftData;
    int fifoIndex = 0;

    // Output smoothing (Linear smoothing is appropriate for control signals)
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedCentroid;
};


================================================================================
// File: DSP_Helpers/TransientDetector.cpp
================================================================================

//================================================================================
// File: DSP_Helpers/TransientDetector.cpp
//================================================================================
#include "TransientDetector.h"

TransientDetector::TransientDetector()
    : fft(FFT_ORDER),
    // FIX: Use the correct JUCE 8 syntax with the WindowingMethod enum.
    window(FFT_SIZE, juce::dsp::WindowingFunction<float>::WindowingMethod::hann)
{
}

void TransientDetector::prepare(const juce::dsp::ProcessSpec& spec)
{
    // Initialize buffers
    inputFIFO.resize(FFT_SIZE, 0.0f);
    fftData.resize(FFT_SIZE * 2, 0.0f); // JUCE requires 2*N for real-only FFT
    int numBins = FFT_SIZE / 2 + 1;
    currentMagnitudes.resize(numBins, 0.0f);
    previousMagnitudes.resize(numBins, 0.0f);

    // Initialize smoothing (e.g., 20ms response time for smooth control signal)
    smoothedFlux.reset(spec.sampleRate, 0.02);

    reset();
}

void TransientDetector::reset()
{
    fifoIndex = 0;
    std::fill(inputFIFO.begin(), inputFIFO.end(), 0.0f);
    std::fill(previousMagnitudes.begin(), previousMagnitudes.end(), 0.0f);
    smoothedFlux.setCurrentAndTargetValue(0.0f);
}

// FIX: Removed process(block) and replaced with processSample(monoSample)
// void TransientDetector::process(const juce::dsp::AudioBlock<float>& block) { ... } // REMOVED

// NEW IMPLEMENTATION: Process sample-by-sample
void TransientDetector::processSample(float monoSample)
{
    // Safety check for buffer size
    if (fifoIndex >= (int)inputFIFO.size())
    {
        // Advance smoother anyway to maintain timing.
        smoothedFlux.getNextValue();
        return;
    }

    // Push sample into FIFO
    inputFIFO[fifoIndex] = monoSample;
    fifoIndex++;

    // Check if a frame is ready
    if (fifoIndex == FFT_SIZE)
    {
        processFrame();
        // Shift FIFO for overlap
        // Ensure inputFIFO is large enough before copying (safety check)
        if ((int)inputFIFO.size() >= FFT_SIZE)
        {
            std::copy(inputFIFO.begin() + HOP_SIZE, inputFIFO.end(), inputFIFO.begin());
        }
        fifoIndex = FFT_SIZE - HOP_SIZE; // Corrected index after shift
    }

    // CRITICAL: Advance the smoother sample-by-sample for accurate control signal generation
    smoothedFlux.getNextValue();
}

void TransientDetector::processFrame() {
    // 1. Copy FIFO to FFT buffer and apply window
    std::copy(inputFIFO.begin(), inputFIFO.end(), fftData.begin());
    window.multiplyWithWindowingTable(fftData.data(), FFT_SIZE);

    // 2. Perform Forward FFT
    fft.performRealOnlyForwardTransform(fftData.data());

    // 3. Calculate Magnitudes and Flux
    float flux = 0.0f;
    int numBins = FFT_SIZE / 2 + 1;

    for (int i = 0; i < numBins; ++i)
    {
        float real, imag;
        // Unpack JUCE format
        if (i == 0) { real = fftData[0]; imag = 0.0f; } // DC
        else if (i == FFT_SIZE / 2) { real = fftData[1]; imag = 0.0f; } // Nyquist
        else { real = fftData[2 * i]; imag = fftData[2 * i + 1]; }

        float magnitude = std::sqrt(real * real + imag * imag);
        currentMagnitudes[i] = magnitude;

        // Calculate flux (rectified difference)
        float diff = magnitude - previousMagnitudes[i];
        if (diff > 0)
            flux += diff;
    }

    // 4. Normalize and set target for smoothing
    // Normalization factor is empirical. Tuned for responsiveness.
    float normalizedFlux = juce::jlimit(0.0f, 1.0f, flux / 5.0f);
    smoothedFlux.setTargetValue(normalizedFlux);

    // 5. Update previous magnitudes
    std::copy(currentMagnitudes.begin(), currentMagnitudes.end(), previousMagnitudes.begin());
}


================================================================================
// File: DSP_Helpers/TransientDetector.h
================================================================================

//================================================================================
// File: DSP_Helpers/TransientDetector.h
//================================================================================
#pragma once
#include <juce_dsp/juce_dsp.h>
#include <vector>
#include <algorithm>
#include <cmath>

/**
 * TransientDetector using Spectral Flux method.
 */
class TransientDetector
{
public:
    // Configuration: FFT size 512 (Order 9). 50% overlap.
    static constexpr int FFT_ORDER = 9;
    static constexpr int FFT_SIZE = 1 << FFT_ORDER;
    static constexpr int HOP_SIZE = FFT_SIZE / 2;

    TransientDetector();

    void prepare(const juce::dsp::ProcessSpec& spec);
    void reset();

    /**
     * Process a single mono sample. This advances the internal state and the smoother.
     */
    void processSample(float monoSample);

    /**
     * Returns the current smoothed transient detection value (0.0 to 1.0).
     */
    float getTransientValue() const { return smoothedFlux.getCurrentValue(); }

    /**
     * Returns the latency introduced by the STFT process (equal to the Hop Size).
     */
    int getLatencyInSamples() const { return HOP_SIZE; }

private:
    void processFrame();

    // DSP Components
    juce::dsp::FFT fft;
    juce::dsp::WindowingFunction<float> window;

    // Buffering (Mono)
    std::vector<float> inputFIFO;
    std::vector<float> fftData;
    std::vector<float> currentMagnitudes;
    std::vector<float> previousMagnitudes;
    int fifoIndex = 0;

    // Output smoothing
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedFlux;
};

================================================================================
// File: FX_Modules/AdvancedCompressorProcessor.cpp
================================================================================

// File: FX_Modules/AdvancedCompressorProcessor.cpp
#include "AdvancedCompressorProcessor.h"

AdvancedCompressorProcessor::AdvancedCompressorProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_ADVCOMP_";
    topologyParamId = slotPrefix + "TOPOLOGY";
    detectorParamId = slotPrefix + "DETECTOR";
    thresholdParamId = slotPrefix + "THRESHOLD";
    ratioParamId = slotPrefix + "RATIO";
    attackParamId = slotPrefix + "ATTACK";
    releaseParamId = slotPrefix + "RELEASE";
    makeupParamId = slotPrefix + "MAKEUP";
}

void AdvancedCompressorProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    currentSampleRate = sampleRate;
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };

    peakDetector.prepare(spec);
    peakDetector.setAttackTime(0.1f); // Fast ballistics for the detector itself
    peakDetector.setReleaseTime(5.0f);

    envelopeSmoother.prepare(spec);
    makeupGain.prepare(spec);
    colorationStage.prepare(spec);

    // Initialize RMS averages
    rmsAverages.resize(spec.numChannels, 0.0f);
    // Calculate alpha for RMS moving average (Blueprint 3.2.1)
    if (sampleRate > 0)
        rmsAlpha = std::exp(-1.0f / (float)(sampleRate * rmsWindowTimeMs / 1000.0f));

    reset();
}

void AdvancedCompressorProcessor::reset()
{
    peakDetector.reset();
    envelopeSmoother.reset();
    makeupGain.reset();
    std::fill(rmsAverages.begin(), rmsAverages.end(), 0.0f);
}

void AdvancedCompressorProcessor::releaseResources() {}

// RMS calculation using Exponential Moving Average (EMA)
float AdvancedCompressorProcessor::calculateRMS(int channel, float input)
{
    if (channel >= (int)rmsAverages.size()) return 0.0f;

    float squaredInput = input * input;
    // EMA: avg = alpha * avg + (1 - alpha) * input^2
    rmsAverages[channel] = rmsAlpha * rmsAverages[channel] + (1.0f - rmsAlpha) * squaredInput;
    return std::sqrt(rmsAverages[channel]);
}

// Gain calculation (Hard Knee implementation)
float AdvancedCompressorProcessor::calculateGainDb(float detectorDb, float thresholdDb, float ratio)
{
    if (detectorDb > thresholdDb)
    {
        return (thresholdDb - detectorDb) * (1.0f - (1.0f / ratio));
    }
    return 0.0f;
}

// Configures characteristics based on the selected topology (Blueprint 3.3)
void AdvancedCompressorProcessor::configureTopology(Topology topology, float attackMs, float releaseMs)
{
    switch (topology)
    {
    case Topology::VCA_Clean:
        // VCA: Fast, clean (Blueprint 3.3.1)
        envelopeSmoother.setAttackTime(attackMs);
        envelopeSmoother.setReleaseTime(releaseMs);
        colorationStage.functionToUse = [](float x) { return x; }; // Transparent
        break;
    case Topology::FET_Aggressive:
        // FET: Ultra-fast attack, aggressive coloration (Blueprint 3.3.2)
        envelopeSmoother.setAttackTime(juce::jmax(0.1f, attackMs * 0.5f)); // Faster attack
        envelopeSmoother.setReleaseTime(releaseMs);
        // FET coloration profile approximation
        colorationStage.functionToUse = [](float x) { return std::tanh(x * 1.5f); };
        break;
    case Topology::Opto_Smooth:
        // Opto: Slower attack, smoother release (Blueprint 3.3.3)
        envelopeSmoother.setAttackTime(juce::jmax(10.0f, attackMs * 1.5f)); // Inherently slower attack
        envelopeSmoother.setReleaseTime(releaseMs * 1.2f);
        // Opto/Tube coloration approximation
        colorationStage.functionToUse = [](float x) { return std::tanh(x * 0.8f); };
        break;
    }
}

void AdvancedCompressorProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&)
{
    juce::ScopedNoDenormals noDenormals;
    // P1 Boilerplate
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    // 1. Get parameters (Safety check omitted for brevity)
    // Ensure parameters exist before accessing them
    if (!mainApvts.getRawParameterValue(thresholdParamId) || !mainApvts.getRawParameterValue(ratioParamId) ||
        !mainApvts.getRawParameterValue(attackParamId) || !mainApvts.getRawParameterValue(releaseParamId) ||
        !mainApvts.getRawParameterValue(makeupParamId) || !mainApvts.getRawParameterValue(topologyParamId) ||
        !mainApvts.getRawParameterValue(detectorParamId))
    {
        return;
    }

    float thresholdDb = mainApvts.getRawParameterValue(thresholdParamId)->load();
    float ratio = mainApvts.getRawParameterValue(ratioParamId)->load();
    float attackMs = mainApvts.getRawParameterValue(attackParamId)->load();
    float releaseMs = mainApvts.getRawParameterValue(releaseParamId)->load();
    float makeupDb = mainApvts.getRawParameterValue(makeupParamId)->load();
    auto topology = static_cast<Topology>(static_cast<int>(mainApvts.getRawParameterValue(topologyParamId)->load()));
    auto detectorMode = static_cast<DetectorMode>(static_cast<int>(mainApvts.getRawParameterValue(detectorParamId)->load()));

    // 2. Configure based on topology
    configureTopology(topology, attackMs, releaseMs);
    makeupGain.setGainDecibels(makeupDb);

    int numSamples = buffer.getNumSamples();
    int numChannels = buffer.getNumChannels();

    // Process loop: Sample outer, Channel inner
    for (int i = 0; i < numSamples; ++i)
    {
        // Process channels independently
        for (int ch = 0; ch < numChannels; ++ch)
        {
            float inputSample = buffer.getSample(ch, i);

            // --- DETECTOR STAGE (Blueprint 3.2.1) ---
            float detectorValue = 0.0f;
            if (detectorMode == DetectorMode::Peak)
            {
                // BallisticsFilter requires the channel index (ch)
                detectorValue = peakDetector.processSample(ch, std::abs(inputSample));
            }
            else // RMS
            {
                detectorValue = calculateRMS(ch, inputSample);
            }

            float detectorDb = juce::Decibels::gainToDecibels(detectorValue + 1e-9f);

            // --- GAIN COMPUTER ---
            float targetGainDb = calculateGainDb(detectorDb, thresholdDb, ratio);

            // --- ENVELOPE STAGE (Blueprint 3.2.2) ---
            // Smooth the gain changes. BallisticsFilter requires the channel index (ch).
            float smoothedGainDb = envelopeSmoother.processSample(ch, targetGainDb);
            float linearGain = juce::Decibels::decibelsToGain(smoothedGainDb);

            // --- APPLY GAIN & COLORATION ---
            float processedSample = inputSample * linearGain;

            // Apply coloration based on topology (WaveShaper takes 1 arg)
            processedSample = colorationStage.processSample(processedSample);

            // Apply makeup gain
            // FIX: dsp::Gain::processSample takes only 1 argument (the sample value).
            // The previous implementation incorrectly passed the channel index 'ch'.
            processedSample = makeupGain.processSample(processedSample);

            buffer.setSample(ch, i, processedSample);
        }
    }
}

================================================================================
// File: FX_Modules/AdvancedCompressorProcessor.h
================================================================================

// File: FX_Modules/AdvancedCompressorProcessor.h
#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>
#include "../DSPUtils.h"

class AdvancedCompressorProcessor : public juce::AudioProcessor
{
public:
    // Topology selection (Blueprint 3.3)
    enum class Topology { VCA_Clean, FET_Aggressive, Opto_Smooth };
    // Detector Modes (Blueprint 3.2.1)
    enum class DetectorMode { Peak, RMS };

    AdvancedCompressorProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~AdvancedCompressorProcessor() override = default;

    const juce::String getName() const override { return "Advanced Compressor"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    // Standard JUCE Boilerplate
    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    double getTailLengthSeconds() const override { return 0.5; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}
private:
    // --- Detector Stage (Blueprint 3.2.1) ---
    juce::dsp::BallisticsFilter<float> peakDetector;

    // RMS detector implementation (Exponential Moving Average)
    float calculateRMS(int channel, float input);
    std::vector<float> rmsAverages;
    float rmsWindowTimeMs = 10.0f;
    float rmsAlpha = 0.99f;

    // --- Gain Computer ---
    float calculateGainDb(float detectorDb, float thresholdDb, float ratio);

    // --- Envelope Stage (Blueprint 3.2.2) ---
    juce::dsp::BallisticsFilter<float> envelopeSmoother;

    // --- Coloration stages (Blueprint 3.3) ---
    juce::dsp::WaveShaper<float> colorationStage;
    juce::dsp::Gain<float> makeupGain;

    // --- Parameters and State ---
    double currentSampleRate = 44100.0;

    void configureTopology(Topology topology, float attackMs, float releaseMs);

    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String topologyParamId, detectorParamId, thresholdParamId, ratioParamId, attackParamId, releaseParamId, makeupParamId;
};

================================================================================
// File: FX_Modules/AdvancedDelayProcessor.cpp
================================================================================

// File: FX_Modules/AdvancedDelayProcessor.cpp
#include "AdvancedDelayProcessor.h"

AdvancedDelayProcessor::AdvancedDelayProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_ADVDELAY_";
    modeParamId = slotPrefix + "MODE";
    timeParamId = slotPrefix + "TIME";
    feedbackParamId = slotPrefix + "FEEDBACK";
    mixParamId = slotPrefix + "MIX";
    colorParamId = slotPrefix + "COLOR";
    wowParamId = slotPrefix + "WOW";
    flutterParamId = slotPrefix + "FLUTTER";
    ageParamId = slotPrefix + "AGE";

    // Configure tape saturator (Blueprint 2.2.2)
    tapeSaturator.functionToUse = [](float x) { return std::tanh(x * 1.5f) * 0.9f; };
}

void AdvancedDelayProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    currentSampleRate = sampleRate;
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };

    delayLine.prepare(spec);
    delayLine.setMaximumDelayInSamples(static_cast<int>(sampleRate * 2.0));

    // Initialize Modulation Sources (Blueprint 2.2.1)
    wowLFO.prepare(spec);
    wowLFO.setWaveform(DSPUtils::LFO::Waveform::Sine);
    wowLFO.setFrequency(0.8f);

    flutterLFO.prepare(spec);
    flutterLFO.setWaveform(DSPUtils::LFO::Waveform::Triangle);
    flutterLFO.setFrequency(8.0f);

    noiseSource.setType(DSPUtils::NoiseGenerator::NoiseType::Pink);

    tapeFilters.prepare(spec);
    smoothedTimeMs.reset(sampleRate, 0.05);

    reset();
}

void AdvancedDelayProcessor::reset()
{
    delayLine.reset();
    wowLFO.reset();
    flutterLFO.reset();
    tapeFilters.reset();
    if (mainApvts.getRawParameterValue(timeParamId))
    {
        smoothedTimeMs.setCurrentAndTargetValue(mainApvts.getRawParameterValue(timeParamId)->load());
    }
}

void AdvancedDelayProcessor::releaseResources() {}

void AdvancedDelayProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&)
{
    juce::ScopedNoDenormals noDenormals;
    // P1 Boilerplate
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    // Safety check for parameters
    if (!mainApvts.getRawParameterValue(modeParamId) || !mainApvts.getRawParameterValue(timeParamId))
        return;

    auto mode = static_cast<DelayMode>(static_cast<int>(mainApvts.getRawParameterValue(modeParamId)->load()));
    smoothedTimeMs.setTargetValue(mainApvts.getRawParameterValue(timeParamId)->load());

    // Note: BBD mode (Blueprint 2.3) requires distinct filtering/companding.
    // For this implementation, Tape and BBD share the core logic in processTapeMode.
    if (mode == DelayMode::Digital)
    {
        processDigitalMode(buffer);
    }
    else
    {
        processTapeMode(buffer);
    }
}

// Implementation of the Tape Echo model (Blueprint 2.2)
void AdvancedDelayProcessor::processTapeMode(juce::AudioBuffer<float>& buffer)
{
    // Get Parameters (Safety check omitted for brevity, but essential)
    float feedback = mainApvts.getRawParameterValue(feedbackParamId)->load();
    float mix = mainApvts.getRawParameterValue(mixParamId)->load();
    float color = mainApvts.getRawParameterValue(colorParamId)->load();
    float wowDepth = mainApvts.getRawParameterValue(wowParamId)->load();
    float flutterDepth = mainApvts.getRawParameterValue(flutterParamId)->load();
    float age = mainApvts.getRawParameterValue(ageParamId)->load();

    // Configure Filters (Blueprint 2.2.2)
    tapeFilters.setType(juce::dsp::StateVariableTPTFilterType::lowpass);
    // Age slightly reduces the cutoff frequency
    float effectiveCutoff = color * (1.0f - age * 0.3f);
    tapeFilters.setCutoffFrequency(effectiveCutoff);

    int numSamples = buffer.getNumSamples();
    int numChannels = buffer.getNumChannels();

    // Process loop: Sample outer, Channel inner
    for (int i = 0; i < numSamples; ++i)
    {
        // 1. Calculate Modulation (Blueprint 2.2.1)
        // Scaled to max deviation in milliseconds (e.g., Wow 5ms, Flutter 1ms)
        float wowModMs = wowLFO.getNextBipolar() * wowDepth * 5.0f;
        float flutterModMs = flutterLFO.getNextBipolar() * flutterDepth * 1.0f;
        // Noise modulation based on age (scrape flutter/wear)
        float noiseModMs = noiseSource.getNextSample() * age * 0.5f;

        float totalModMs = wowModMs + flutterModMs + noiseModMs;

        // 2. Calculate Delay Time
        float currentTimeMs = smoothedTimeMs.getNextValue();
        float delayMs = juce::jmax(1.0f, currentTimeMs + totalModMs); // Ensure positive delay
        float delayInSamples = (float)(currentSampleRate * delayMs / 1000.0);
        delayInSamples = juce::jmin(delayInSamples, (float)delayLine.getMaximumDelayInSamples() - 1.0f);

        for (int ch = 0; ch < numChannels; ++ch)
        {
            float inputSample = buffer.getSample(ch, i);

            // 3. Read from Delay Line (Modulated)
            float delayedSample = delayLine.popSample(ch, delayInSamples, true);

            // 4. Apply Tape Degradation (Inside the feedback loop) (Blueprint 2.2.2)
            float processedWetSignal = delayedSample;

            // Apply Saturation
            processedWetSignal = tapeSaturator.processSample(processedWetSignal);

            // Apply Filtering
            processedWetSignal = tapeFilters.processSample(ch, processedWetSignal);

            // 5. Write to Delay Line (Feedback loop)
            float inputToDelay = inputSample + processedWetSignal * feedback;
            delayLine.pushSample(ch, inputToDelay);

            // 6. Mix Output
            float outputSample = (inputSample * (1.0f - mix)) + (processedWetSignal * mix);
            buffer.setSample(ch, i, outputSample);
        }
    }
}

void AdvancedDelayProcessor::processDigitalMode(juce::AudioBuffer<float>& buffer)
{
    // Implementation for clean digital delay (omitted for brevity)
    juce::ignoreUnused(buffer);
}

================================================================================
// File: FX_Modules/AdvancedDelayProcessor.h
================================================================================

// File: FX_Modules/AdvancedDelayProcessor.h
#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>
#include "../DSPUtils.h"

class AdvancedDelayProcessor : public juce::AudioProcessor
{
public:
    enum class DelayMode { Tape, BBD, Digital };

    AdvancedDelayProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~AdvancedDelayProcessor() override = default;

    const juce::String getName() const override { return "Advanced Delay"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    // Standard JUCE Boilerplate
    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    double getTailLengthSeconds() const override { return 5.0; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}
private:
    void processTapeMode(juce::AudioBuffer<float>& buffer);
    void processDigitalMode(juce::AudioBuffer<float>& buffer);

    // --- Core Components ---
    // Upgraded interpolation (Blueprint 2.2.1)
    juce::dsp::DelayLine<float, juce::dsp::DelayLineInterpolationTypes::Lagrange3rd> delayLine;
    double currentSampleRate = 44100.0;

    // --- Tape Mode Components (Blueprint 2.2) ---
    DSPUtils::LFO wowLFO;
    DSPUtils::LFO flutterLFO;
    DSPUtils::NoiseGenerator noiseSource;

    juce::dsp::WaveShaper<float> tapeSaturator;
    juce::dsp::StateVariableTPTFilter<float> tapeFilters;

    // --- Parameters ---
    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String modeParamId, timeParamId, feedbackParamId, mixParamId, colorParamId, wowParamId, flutterParamId, ageParamId;

    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedTimeMs;
};

================================================================================
// File: FX_Modules/BBDGranularEngine.cpp
================================================================================

//================================================================================
// File: FX_Modules/BBDGranularEngine.cpp
//================================================================================
#include "BBDGranularEngine.h"

BBDGranularEngine::BBDGranularEngine()
{
    auto timeSeed = static_cast<std::uintptr_t>(juce::Time::currentTimeMillis());
    auto addressSeed = reinterpret_cast<std::uintptr_t>(this);
    randomEngine.seed(static_cast<unsigned int>(timeSeed ^ addressSeed));
    noiseGen.setType(DSPUtils::NoiseGenerator::NoiseType::Pink);
}

void BBDGranularEngine::prepare(const juce::dsp::ProcessSpec& spec, const Config& newConfig, int maxBufferSizeSamples)
{
    sampleRate = spec.sampleRate;
    numChannels = (int)spec.numChannels;
    config = newConfig;

    captureBuffer.prepare(spec, maxBufferSizeSamples);

    grains.resize(MAX_GRAINS);
    juce::dsp::ProcessSpec monoSpec = spec;
    monoSpec.numChannels = 1;

    for (auto& grain : grains)
    {
        grain.filterL.prepare(monoSpec);
        grain.filterR.prepare(monoSpec);
        grain.filterL.setType(juce::dsp::StateVariableTPTFilterType::lowpass);
        grain.filterR.setType(juce::dsp::StateVariableTPTFilterType::lowpass);
    }

    reset();
}

void BBDGranularEngine::reset()
{
    captureBuffer.reset();
    for (auto& grain : grains)
    {
        grain.isActive = false;
        grain.filterL.reset();
        grain.filterR.reset();
    }
    samplesUntilNextGrain = 0.0f;
}

void BBDGranularEngine::capture(const juce::dsp::AudioBlock<float>& inputBlock)
{
    captureBuffer.write(inputBlock);
}

float BBDGranularEngine::Grain::applyTukeyWindow(float phase)
{
    const float alpha = 0.5f;
    if (phase < alpha / 2.0f)
        return 0.5f * (1.0f + std::cos(juce::MathConstants<float>::twoPi / alpha * (phase - alpha / 2.0f)));
    if (phase > 1.0f - alpha / 2.0f)
        return 0.5f * (1.0f + std::cos(juce::MathConstants<float>::twoPi / alpha * (phase - 1.0f + alpha / 2.0f)));
    return 1.0f;
}

void BBDGranularEngine::spawnGrain(float timeMs, float spread, float age)
{
    for (auto& grain : grains)
    {
        if (!grain.isActive)
        {
            grain.isActive = true;

            float durationMs = juce::jmap(distribution(randomEngine), config.minDurationMs, config.maxDurationMs);
            grain.durationSamples = static_cast<int>(sampleRate * durationMs / 1000.0);
            grain.grainPhase = 0.0f;

            float baseDelaySamples = (float)(sampleRate * timeMs / 1000.0);
            float jitter = (distribution(randomEngine) * 2.0f - 1.0f) * spread * baseDelaySamples * 0.5f;
            float actualDelaySamples = juce::jmax(10.0f, baseDelaySamples + jitter);

            int bufferSize = captureBuffer.getSize();
            if (bufferSize == 0) { grain.isActive = false; return; }

            grain.bufferReadPosition = (float)captureBuffer.getWritePosition() - actualDelaySamples;

            float normalizedTime = actualDelaySamples / (float)(sampleRate * 0.05);
            grain.pitchRatio = 1.0f / normalizedTime;
            grain.pitchRatio = juce::jlimit(0.1f, 5.0f, grain.pitchRatio);

            float baseCutoff = config.baseCutoffHz;
            baseCutoff *= (1.0f - age * 0.7f);

            float nyquist = (float)sampleRate * 0.5f;
            float aaCutoff = nyquist;

            if (grain.pitchRatio > 1.0f)
            {
                aaCutoff = nyquist / grain.pitchRatio;
            }
            else if (grain.pitchRatio < 1.0f)
            {
                aaCutoff = nyquist * grain.pitchRatio;
            }

            float cutoff = juce::jmin(baseCutoff, aaCutoff * 0.95f);
            cutoff = juce::jlimit(50.0f, nyquist - 50.0f, cutoff);

            grain.filterL.setCutoffFrequency(cutoff);
            grain.filterR.setCutoffFrequency(cutoff);
            grain.filterL.setResonance(0.707f);
            grain.filterR.setResonance(0.707f);
            grain.filterL.reset();
            grain.filterR.reset();

            grain.noiseLevel = age * config.noiseAmount;
            grain.amplitude = 0.7f + distribution(randomEngine) * 0.3f;
            grain.pan = distribution(randomEngine);

            return;
        }
    }
}

void BBDGranularEngine::process(juce::dsp::AudioBlock<float>& outputBlock, float density, float timeMs, float spread, float age)
{
    juce::ScopedNoDenormals noDenormals;

    int numSamples = (int)outputBlock.getNumSamples();
    float spawnRateHz = juce::jmap(density, 0.0f, config.spawnRateHzMax);
    if (spawnRateHz < 0.1f) spawnRateHz = 0.1f;
    float spawnIntervalSamples = (float)sampleRate / spawnRateHz;

    for (int i = 0; i < numSamples; ++i)
    {
        samplesUntilNextGrain -= 1.0f;
        if (samplesUntilNextGrain <= 0.0f)
        {
            spawnGrain(timeMs, spread, age);
            samplesUntilNextGrain += spawnIntervalSamples * (0.7f + distribution(randomEngine) * 0.6f);
        }

        for (auto& grain : grains)
        {
            if (grain.isActive)
            {
                float phase = grain.grainPhase / (float)grain.durationSamples;
                if (phase >= 1.0f)
                {
                    grain.isActive = false;
                    continue;
                }

                float window = Grain::applyTukeyWindow(phase);
                float gainL = window * std::cos(grain.pan * juce::MathConstants<float>::halfPi);
                float gainR = window * std::sin(grain.pan * juce::MathConstants<float>::halfPi);

                float sampleL = 0.0f, sampleR = 0.0f;

                if (numChannels > 0)
                    sampleL = captureBuffer.read(0, grain.bufferReadPosition);
                if (numChannels > 1)
                    sampleR = captureBuffer.read(1, grain.bufferReadPosition);
                else
                    sampleR = sampleL;

                sampleL += noiseGen.getNextSample() * grain.noiseLevel;
                sampleR += noiseGen.getNextSample() * grain.noiseLevel;

                float drive = config.saturationDrive * (1.0f + age * 0.5f);
                sampleL = DSPUtils::fastTanh(sampleL * drive);
                sampleR = DSPUtils::fastTanh(sampleR * drive);

                // JUCE 8 FIX (C2660): Pass channel index 0 as required by JUCE 8 API for mono filters.
                sampleL = grain.filterL.processSample(0, sampleL);
                sampleR = grain.filterR.processSample(0, sampleR);

                outputBlock.addSample(0, i, sampleL * gainL * grain.amplitude);
                if (numChannels > 1)
                    outputBlock.addSample(1, i, sampleR * gainR * grain.amplitude);

                grain.grainPhase += 1.0f;
                grain.bufferReadPosition += grain.pitchRatio;
            }
        }
    }
}

================================================================================
// File: FX_Modules/BBDGranularEngine.h
================================================================================

//================================================================================
// File: FX_Modules/BBDGranularEngine.h
//================================================================================
#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>
#include <random>
#include <vector>
#include <cmath> // Added for std::cos
#include "../DSP_Helpers/InterpolatedCircularBuffer.h"
#include "../DSPUtils.h" // Required for NoiseGenerator and fastTanh
class BBDGranularEngine
{
public:
    // OPTIMIZATION: Set MAX_GRAINS to 64. This provides a good balance of density and performance
    // given the reduced spawn rates configured in BBDCloudProcessor.cpp.
    static constexpr int MAX_GRAINS = 64;

    // Configuration structure (remains the same)
    struct Config
    {
        float minDurationMs = 10.0f;
        float maxDurationMs = 100.0f;
        float baseCutoffHz = 5000.0f;
        float saturationDrive = 1.2f;
        float spawnRateHzMax = 500.0f;
        float noiseAmount = 0.05f;
    };

    BBDGranularEngine();
    void prepare(const juce::dsp::ProcessSpec& spec, const Config& newConfig, int maxBufferSizeSamples);
    void reset();
    void capture(const juce::dsp::AudioBlock<float>& inputBlock);
    void process(juce::dsp::AudioBlock<float>& outputBlock, float density, float timeMs, float spread, float age);

private:
    void spawnGrain(float timeMs, float spread, float age);

    struct Grain
    {
        bool isActive = false;
        int durationSamples = 0;
        float grainPhase = 0.0f; // 0.0 to 1.0
        float bufferReadPosition = 0.0f;

        // Stochastic Parameters
        float amplitude = 1.0f;
        float pan = 0.5f; // 0=L, 1=R

        // Per-Grain DSP (BBD Emulation)

        // ARTIFACT FIX: Upgraded from FirstOrderTPTFilter (6dB/oct) to StateVariableTPTFilter (12dB/oct).
        // Steeper filtering is essential for anti-aliasing in BBD emulation.
        // OLD: juce::dsp::FirstOrderTPTFilter<float> filterL, filterR;
        juce::dsp::StateVariableTPTFilter<float> filterL, filterR;

        float pitchRatio = 1.0f;
        float noiseLevel = 0.0f;

        static float applyTukeyWindow(float phase);
    };

    // --- Members ---
    double sampleRate = 44100.0;
    int numChannels = 2;
    Config config;
    InterpolatedCircularBuffer captureBuffer;
    std::vector<Grain> grains;

    // Spawning control
    float samplesUntilNextGrain = 0.0f;

    // Randomization
    std::minstd_rand randomEngine;
    std::uniform_real_distribution<float> distribution{ 0.0f, 1.0f };
    DSPUtils::NoiseGenerator noiseGen;
};

================================================================================
// File: FX_Modules/ChromaTapeProcessor.cpp
================================================================================

//================================================================================
// File: FX_Modules/ChromaTapeProcessor.cpp
//================================================================================
#include "ChromaTapeProcessor.h"

// Constructor remains unchanged
ChromaTapeProcessor::ChromaTapeProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    // Parameter ID assignments (Unchanged)
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_CT_";
    saturationParamIds[0] = slotPrefix + "LOW_SATURATION";
    saturationParamIds[1] = slotPrefix + "MID_SATURATION";
    saturationParamIds[2] = slotPrefix + "HIGH_SATURATION";

    wowParamIds[0] = slotPrefix + "LOW_WOW";
    wowParamIds[1] = slotPrefix + "MID_WOW";
    wowParamIds[2] = slotPrefix + "HIGH_WOW";

    flutterParamIds[0] = slotPrefix + "LOW_FLUTTER";
    flutterParamIds[1] = slotPrefix + "MID_FLUTTER";
    flutterParamIds[2] = slotPrefix + "HIGH_FLUTTER";

    lowMidCrossoverParamId = slotPrefix + "LOWMID_CROSS";
    midHighCrossoverParamId = slotPrefix + "MIDHIGH_CROSS";

    // NEW: Assign IDs for new parameters
    scrapeParamId = slotPrefix + "SCRAPE_FLUTTER";
    chaosParamId = slotPrefix + "CHAOS_AMOUNT";
    hissParamId = slotPrefix + "HISS_LEVEL";
    humParamId = slotPrefix + "HUM_LEVEL";
    headBumpFreqParamId = slotPrefix + "HEADBUMP_FREQ";
    headBumpGainParamId = slotPrefix + "HEADBUMP_GAIN";
}

ChromaTapeProcessor::~ChromaTapeProcessor()
{
}

// Updated prepareToPlay
void ChromaTapeProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };
    juce::dsp::ProcessSpec monoSpec = spec;
    monoSpec.numChannels = 1;

    // 1. Prepare Bands
    for (int i = 0; i < NUM_BANDS; ++i)
    {
        auto& band = bands[i];
        band.saturator.prepare(spec);

        // NEW: Initialize Hysteresis State (Blueprint 2.3)
        band.hysteresis_last_input.resize(spec.numChannels, 0.0f);

        // NEW: Initialize EQ Stages (Blueprint 2.2, 2.4)
        band.headBumpFilters.resize(spec.numChannels);
        for (auto& filter : band.headBumpFilters) {
            filter.prepare(monoSpec);
        }

        band.dynamicHfFilter.prepare(spec);
        band.hfEnvelope.prepare(spec);

        if (i == HIGH)
        {
            band.dynamicHfFilter.setType(juce::dsp::StateVariableTPTFilterType::lowpass);
            band.hfEnvelope.setAttackTime(5.0f);
            band.hfEnvelope.setReleaseTime(50.0f);
        }

        // --- Modulation Initialization ---
        int maxDelaySamples = (int)(sampleRate * 0.030) + 2; // 30ms max delay
        band.delayLine.prepare(spec);
        band.delayLine.setMaximumDelayInSamples(maxDelaySamples);

        band.wowLFO.prepare(spec);
        band.flutterLFO.prepare(spec);
        band.wowLFO.setFrequency(1.0f);
        band.flutterLFO.setFrequency(15.0f);

        band.wowLFO.setStereoOffset(0.2f);
        band.flutterLFO.setStereoOffset(0.15f);

        // Noise/Smoothing setup
        band.noiseGen.setType(DSPUtils::NoiseGenerator::NoiseType::White);
        band.noiseFilter.prepare(monoSpec); // Use monoSpec (control signal)

        // OPTIMIZATION FIX: Initialize Stereo Mod Smoothers
        band.modSmoothers.resize(spec.numChannels);
        for (auto& smoother : band.modSmoothers)
        {
            smoother.prepare(monoSpec); // Prepare individual instances with monoSpec
            smoother.setCutoffFrequency(100.0f); // Example smoothing frequency
        }

        // Scrape Flutter Setup
        band.scrapeNoiseFilter.prepare(monoSpec); // Use monoSpec (control signal)
        band.scrapeNoiseFilter.setType(juce::dsp::StateVariableTPTFilterType::bandpass);
        band.scrapeNoiseFilter.setCutoffFrequency(3000.0f);
        band.scrapeNoiseFilter.setResonance(0.5f);

        // Initialize Parameter Smoothers
        band.smoothedWowDepth.reset(sampleRate, 0.05);
        band.smoothedFlutterDepth.reset(sampleRate, 0.05);
        band.smoothedSaturationDb.reset(sampleRate, 0.05);
    }

    // 2. Prepare Crossover Network
    crossover.prepare(spec);

    // 3. Prepare Noise/Hum
    hissGenerator.setType(DSPUtils::NoiseGenerator::NoiseType::Pink);
    hissShapingFilters.resize(spec.numChannels);
    auto hissCoeffs = juce::dsp::IIR::Coefficients<float>::makeHighShelf(sampleRate, 4000.0f, 0.5f, 6.0f);
    for (auto& filter : hissShapingFilters) {
        filter.prepare(monoSpec);
        *filter.coefficients = *hissCoeffs;
    }

    humOscillator.prepare(spec);
    humOscillator.setFrequency(60.0f);
    humHarmonicOscillator.prepare(spec);
    humHarmonicOscillator.setFrequency(180.0f);

    // 4. OPTIMIZATION FIX: Initialize Global Parameter Smoothers
    double smoothingTime = 0.05; // 50ms smoothing
    smoothedScrape.reset(sampleRate, smoothingTime);
    smoothedChaos.reset(sampleRate, smoothingTime);
    smoothedHissLevel.reset(sampleRate, smoothingTime);
    smoothedHumLevel.reset(sampleRate, smoothingTime);

    reset();
}

void ChromaTapeProcessor::releaseResources()
{
    reset();
}

// Updated reset
void ChromaTapeProcessor::reset()
{
    for (auto& band : bands)
    {
        band.saturator.reset();
        band.delayLine.reset();
        band.wowLFO.reset();
        band.flutterLFO.reset();
        band.noiseFilter.reset();

        // OPTIMIZATION FIX: Reset Stereo Mod Smoothers
        for (auto& smoother : band.modSmoothers)
        {
            smoother.reset();
        }

        for (auto& filter : band.headBumpFilters) filter.reset();
        band.dynamicHfFilter.reset();
        band.hfEnvelope.reset();
        std::fill(band.hysteresis_last_input.begin(), band.hysteresis_last_input.end(), 0.0f);
        band.scrapeNoiseFilter.reset();
        band.chaos_state = 0.5f;

        band.smoothedWowDepth.setCurrentAndTargetValue(band.smoothedWowDepth.getTargetValue());
        band.smoothedFlutterDepth.setCurrentAndTargetValue(band.smoothedFlutterDepth.getTargetValue());
        band.smoothedSaturationDb.setCurrentAndTargetValue(band.smoothedSaturationDb.getTargetValue());
    }

    crossover.reset();
    for (auto& filter : hissShapingFilters) filter.reset();
    humOscillator.reset();
    humHarmonicOscillator.reset();

    // OPTIMIZATION FIX: Reset Global Smoothers
    smoothedScrape.setCurrentAndTargetValue(smoothedScrape.getTargetValue());
    smoothedChaos.setCurrentAndTargetValue(smoothedChaos.getTargetValue());
    smoothedHissLevel.setCurrentAndTargetValue(smoothedHissLevel.getTargetValue());
    smoothedHumLevel.setCurrentAndTargetValue(smoothedHumLevel.getTargetValue());
}

// Constants
const float MAX_GAIN_LINEAR = 4.0f;
const float LOW_ASYMMETRY = 0.7f;
const float MID_ASYMMETRY_OFFSET = 0.1f;
const float HIGH_ASYMMETRY = 0.1f;

static float calculateInternalDrive(float saturationDb)
{
    if (saturationDb <= 0.01f) return 0.0f;
    float driveLinear = juce::Decibels::decibelsToGain(saturationDb);
    float internalDrive = (driveLinear - 1.0f) / (MAX_GAIN_LINEAR - 1.0f);
    return juce::jlimit(0.0f, 1.0f, internalDrive);
}

// Updated updateParameters
void ChromaTapeProcessor::updateParameters()
{
    // Added safety checks for parameter existence
    if (!mainApvts.getRawParameterValue(lowMidCrossoverParamId) || !mainApvts.getRawParameterValue(midHighCrossoverParamId)) return;

    float lowMidCross = mainApvts.getRawParameterValue(lowMidCrossoverParamId)->load();
    float midHighCross = mainApvts.getRawParameterValue(midHighCrossoverParamId)->load();
    crossover.setCrossoverFrequencies(lowMidCross, midHighCross);

    for (int i = 0; i < NUM_BANDS; ++i)
    {
        // Added safety checks
        if (mainApvts.getRawParameterValue(saturationParamIds[i]))
            bands[i].smoothedSaturationDb.setTargetValue(mainApvts.getRawParameterValue(saturationParamIds[i])->load());
        if (mainApvts.getRawParameterValue(wowParamIds[i]))
            bands[i].smoothedWowDepth.setTargetValue(mainApvts.getRawParameterValue(wowParamIds[i])->load());
        if (mainApvts.getRawParameterValue(flutterParamIds[i]))
            bands[i].smoothedFlutterDepth.setTargetValue(mainApvts.getRawParameterValue(flutterParamIds[i])->load());
    }

    // OPTIMIZATION FIX: Update Global Smoothers (Read APVTS once per block)
    if (mainApvts.getRawParameterValue(scrapeParamId))
        smoothedScrape.setTargetValue(mainApvts.getRawParameterValue(scrapeParamId)->load());
    if (mainApvts.getRawParameterValue(chaosParamId))
        smoothedChaos.setTargetValue(mainApvts.getRawParameterValue(chaosParamId)->load());

    if (mainApvts.getRawParameterValue(hissParamId)) {
        float hissDb = mainApvts.getRawParameterValue(hissParamId)->load();
        smoothedHissLevel.setTargetValue(juce::Decibels::decibelsToGain(hissDb));
    }
    if (mainApvts.getRawParameterValue(humParamId)) {
        float humDb = mainApvts.getRawParameterValue(humParamId)->load();
        smoothedHumLevel.setTargetValue(juce::Decibels::decibelsToGain(humDb));
    }

    // Check sample rate validity before calculating coefficients
    if (!bands[LOW].headBumpFilters.empty() && getSampleRate() > 0 && mainApvts.getRawParameterValue(headBumpFreqParamId) && mainApvts.getRawParameterValue(headBumpGainParamId))
    {
        float headBumpFreq = mainApvts.getRawParameterValue(headBumpFreqParamId)->load();
        float headBumpGain = mainApvts.getRawParameterValue(headBumpGainParamId)->load();
        auto headBumpCoeffs = juce::dsp::IIR::Coefficients<float>::makePeakFilter(getSampleRate(), headBumpFreq, 0.7f, juce::Decibels::decibelsToGain(headBumpGain));
        for (auto& filter : bands[LOW].headBumpFilters) {
            *filter.coefficients = *headBumpCoeffs;
        }
    }
}

// Updated processBlock
void ChromaTapeProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&)
{
    juce::ScopedNoDenormals noDenormals;
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    int numSamples = buffer.getNumSamples();
    int numChannels = buffer.getNumChannels();

    // 1. Update Parameters
    updateParameters();

    // 2. Split into bands
    crossover.processBlock(buffer);

    // 3. Process each band
    std::array<juce::AudioBuffer<float>*, NUM_BANDS> bandBuffers = {
        &crossover.getLowBand(), &crossover.getMidBand(), &crossover.getHighBand()
    };

    // Main Processing Loop
    for (int sample = 0; sample < numSamples; ++sample)
    {
        // OPTIMIZATION FIX: Advance global smoothers once per sample frame
        smoothedScrape.getNextValue();
        smoothedChaos.getNextValue();

        for (int i = 0; i < NUM_BANDS; ++i)
        {
            bands[i].smoothedSaturationDb.getNextValue();
            bands[i].smoothedWowDepth.getNextValue();
            bands[i].smoothedFlutterDepth.getNextValue();

            updateModulation(i);

            processBand(i, sample, numChannels, *bandBuffers[i]);
        }
    }

    // 4. Sum bands back into output buffer
    buffer.clear();
    for (int i = 0; i < NUM_BANDS; ++i)
    {
        auto* bandBuffer = bandBuffers[i];
        for (int ch = 0; ch < numChannels; ++ch)
        {
            if (ch < bandBuffer->getNumChannels())
            {
                buffer.addFrom(ch, 0, *bandBuffer, ch, 0, numSamples);
            }
        }
    }

    // 5. Inject Hiss (Blueprint IV.1)
    if (smoothedHissLevel.getTargetValue() > 1e-6f && hissShapingFilters.size() == (size_t)numChannels)
    {
        for (int sample = 0; sample < numSamples; ++sample)
        {
            float currentHissLevel = smoothedHissLevel.getNextValue();
            float noise = hissGenerator.getNextSample();

            for (int ch = 0; ch < numChannels; ++ch)
            {
                // CONFIRMED: IIR::Filter prepared with monoSpec uses 1 argument.
                float hissSample = hissShapingFilters[ch].processSample(noise) * currentHissLevel;
                buffer.addSample(ch, sample, hissSample);
            }
        }
    }
    else if (smoothedHissLevel.isSmoothing())
    {
        smoothedHissLevel.skip(numSamples);
    }
}

// The Core Processing Logic (Optimized Structure)
void ChromaTapeProcessor::processBand(int bandIdx, int sample, int numChannels, juce::AudioBuffer<float>& buffer)
{
    auto& band = bands[bandIdx];
    float saturationDb = band.smoothedSaturationDb.getCurrentValue();
    float internalDrive = calculateInternalDrive(saturationDb);

    float hum = 0.0f;
    if (bandIdx == LOW)
    {
        float currentHumLevel = smoothedHumLevel.getNextValue();
        hum = (humOscillator.getNextBipolar() + humHarmonicOscillator.getNextBipolar() * 0.5f) * currentHumLevel;
    }

    constexpr int MAX_CHANNELS = 2;
    std::array<float, MAX_CHANNELS> sat_outputs;
    int activeChannels = juce::jmin(numChannels, MAX_CHANNELS);

    // === Stages 1 & 2: EQ and Saturation (Per Channel) ===
    for (int ch = 0; ch < activeChannels; ++ch)
    {
        float input = buffer.getSample(ch, sample);

        if (bandIdx == LOW)
        {
            input += hum;
            if (ch < (int)band.headBumpFilters.size())
            {
                // CONFIRMED: IIR::Filter prepared with monoSpec uses 1 argument.
                input = band.headBumpFilters[ch].processSample(input);
            }
        }

        float sat_out = input;
        if (internalDrive > 0.0f)
        {
            band.saturator.setDrive(internalDrive);

            if (bandIdx == LOW)
            {
                band.saturator.setAsymmetry(LOW_ASYMMETRY);
            }
            else if (bandIdx == MID)
            {
                if (ch < (int)band.hysteresis_last_input.size())
                {
                    if (input > band.hysteresis_last_input[ch])
                        band.saturator.setAsymmetry(MID_ASYMMETRY_OFFSET);
                    else
                        band.saturator.setAsymmetry(-MID_ASYMMETRY_OFFSET);

                    band.hysteresis_last_input[ch] = input;
                }
            }
            else
            {
                band.saturator.setAsymmetry(HIGH_ASYMMETRY);
            }

            sat_out = band.saturator.processSample(ch, input);

            if (saturationDb > 1e-6f) {
                sat_out *= (1.0f / juce::Decibels::decibelsToGain(saturationDb));
            }
        }

        sat_outputs[ch] = sat_out;
    }

    // === Stage 2.5: Calculate Envelope (OPTIMIZATION: Once per frame) ===
    if (bandIdx == HIGH)
    {
        float maxAbsSat = 0.0f;
        for (int ch = 0; ch < activeChannels; ++ch)
        {
            maxAbsSat = juce::jmax(maxAbsSat, std::abs(sat_outputs[ch]));
        }

        float envelope = band.hfEnvelope.process(maxAbsSat);
        float cutoffHz = juce::jmap(juce::jlimit(0.0f, 0.5f, envelope), 0.0f, 0.5f, 20000.0f, 6000.0f);
        band.dynamicHfFilter.setCutoffFrequency(cutoffHz);
    }

    // === Stages 3 & 4: Post-Filtering and Modulation (Per Channel) ===
    for (int ch = 0; ch < activeChannels; ++ch)
    {
        float processed_sample = sat_outputs[ch];

        if (bandIdx == HIGH)
        {
            processed_sample = band.dynamicHfFilter.processSample(ch, processed_sample);
        }

        float mod_out = applyModulation(bandIdx, ch, processed_sample);
        buffer.setSample(ch, sample, mod_out);
    }
}

// Blueprint III - Update LFOs, Chaos, and Noise (Once per frame per band)
void ChromaTapeProcessor::updateModulation(int bandIdx)
{
    auto& band = bands[bandIdx];

    band.chaos_state = band.CHAOS_R * band.chaos_state * (1.0f - band.chaos_state);

    float chaosAmount = smoothedChaos.getCurrentValue();

    if (chaosAmount > 0.001f)
    {
        float chaos_bipolar = (band.chaos_state * 2.0f - 1.0f) * chaosAmount;
        float wowFreq = 1.0f * (1.0f + chaos_bipolar * 0.2f);
        float flutterFreq = 15.0f * (1.0f + chaos_bipolar * 0.2f);
        band.wowLFO.setFrequency(wowFreq);
        band.flutterLFO.setFrequency(flutterFreq);
    }

    band.currentWow = band.wowLFO.getNextStereoSample();
    band.currentFlutter = band.flutterLFO.getNextStereoSample();

    float noise = band.noiseGen.getNextSample();

    // FIX: TPT and SVT filters require the channel index (0 for mono).
    band.currentFilteredNoise = band.noiseFilter.processSample(0, noise);
    band.currentScrapeNoise = band.scrapeNoiseFilter.processSample(0, noise);
}

// Blueprint III - Calculate and Apply Delay (Optimized)
float ChromaTapeProcessor::applyModulation(int bandIdx, int channel, float inputSample)
{
    auto& band = bands[bandIdx];
    float sr = (float)getSampleRate();

    const float MAX_WOW_MS = 10.0f;
    const float MAX_FLUTTER_MS = 2.0f;
    const float MAX_SCRAPE_MS = 0.5f;
    const float BASE_DELAY_MS = 15.0f;

    float wowDepth = band.smoothedWowDepth.getCurrentValue();
    float flutterDepth = band.smoothedFlutterDepth.getCurrentValue();
    float scrapeDepth = smoothedScrape.getCurrentValue();

    float wowMod = (channel == 0) ? band.currentWow.first : band.currentWow.second;
    float periodicFlutter = (channel == 0) ? band.currentFlutter.first : band.currentFlutter.second;

    float wowModMs = wowMod * wowDepth * MAX_WOW_MS * 0.5f;
    float flutterModMs = (periodicFlutter * 0.7f + band.currentFilteredNoise * 0.3f) * flutterDepth * MAX_FLUTTER_MS * 0.5f;
    float scrapeModMs = band.currentScrapeNoise * scrapeDepth * MAX_SCRAPE_MS;

    float rawModulationMs = BASE_DELAY_MS + wowModMs + flutterModMs + scrapeModMs;

    float smoothedDelayMs = rawModulationMs;
    if (channel < (int)band.modSmoothers.size())
    {
        // FIX: FirstOrderTPTFilter requires the channel index (0 for mono).
        smoothedDelayMs = band.modSmoothers[channel].processSample(0, rawModulationMs);
    }

    float delaySamples = smoothedDelayMs * sr / 1000.0f;
    delaySamples = juce::jmax(0.1f, juce::jmin(delaySamples, (float)band.delayLine.getMaximumDelayInSamples() - 1.0f));

    band.delayLine.pushSample(channel, inputSample);
    return band.delayLine.popSample(channel, delaySamples, true);
}


// Crossover Network Implementation
void ChromaTapeProcessor::CrossoverNetwork::prepare(const juce::dsp::ProcessSpec& spec)
{
    lowMidLowpass.prepare(spec);
    lowMidHighpass.prepare(spec);
    midHighLowpass.prepare(spec);
    midHighHighpass.prepare(spec);

    lowMidLowpass.setType(juce::dsp::LinkwitzRileyFilterType::lowpass);
    lowMidHighpass.setType(juce::dsp::LinkwitzRileyFilterType::highpass);
    midHighLowpass.setType(juce::dsp::LinkwitzRileyFilterType::lowpass);
    midHighHighpass.setType(juce::dsp::LinkwitzRileyFilterType::highpass);

    int numChannels = (int)spec.numChannels;
    int maxSamples = (int)spec.maximumBlockSize;

    lowBand.setSize(numChannels, maxSamples);
    midBand.setSize(numChannels, maxSamples);
    highBand.setSize(numChannels, maxSamples);
}

void ChromaTapeProcessor::CrossoverNetwork::reset()
{
    lowMidLowpass.reset();
    lowMidHighpass.reset();
    midHighLowpass.reset();
    midHighHighpass.reset();
}

void ChromaTapeProcessor::CrossoverNetwork::setCrossoverFrequencies(float lowMid, float midHigh)
{
    midHigh = juce::jmax(lowMid + 20.0f, midHigh);

    lowMidLowpass.setCutoffFrequency(lowMid);
    lowMidHighpass.setCutoffFrequency(lowMid);
    midHighLowpass.setCutoffFrequency(midHigh);
    midHighHighpass.setCutoffFrequency(midHigh);
}

void ChromaTapeProcessor::CrossoverNetwork::processBlock(juce::AudioBuffer<float>& buffer)
{
    int numChannels = buffer.getNumChannels();
    int numSamples = buffer.getNumSamples();

    // Ensure buffers are correctly sized
    lowBand.setSize(numChannels, numSamples, false, false, true);
    midBand.setSize(numChannels, numSamples, false, false, true);
    highBand.setSize(numChannels, numSamples, false, false, true);

    // Process Low Band
    lowBand.makeCopyOf(buffer);
    juce::dsp::AudioBlock<float> lowBlock(lowBand);
    juce::dsp::ProcessContextReplacing<float> lowContext(lowBlock);
    lowMidLowpass.process(lowContext);

    // Process High Band (initially contains input signal)
    highBand.makeCopyOf(buffer);
    juce::dsp::AudioBlock<float> highBlock(highBand);
    juce::dsp::ProcessContextReplacing<float> highContext(highBlock);
    lowMidHighpass.process(highContext); // highBand now contains frequencies > lowMid

    // Process Mid Band (copy from the partially filtered highBand)
    midBand.makeCopyOf(highBand);
    juce::dsp::AudioBlock<float> midBlock(midBand);
    juce::dsp::ProcessContextReplacing<float> midContext(midBlock);
    midHighLowpass.process(midContext); // midBand now contains frequencies between lowMid and midHigh

    // Finalize High Band
    midHighHighpass.process(highContext); // highBand now contains frequencies > midHigh
}

================================================================================
// File: FX_Modules/ChromaTapeProcessor.h
================================================================================

//================================================================================
// File: FX_Modules/ChromaTapeProcessor.h (REVISED)
//================================================================================
#pragma once
#include <JuceHeader.h>
#include "../DSPUtils.h"
// CHANGED: Include the optimized saturation model
#include "TapeSaturation.h"

class ChromaTapeProcessor : public juce::AudioProcessor
{
public:
    ChromaTapeProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~ChromaTapeProcessor() override;

    const juce::String getName() const override { return "ChromaTape"; }

    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    // Boilerplate methods (unchanged)
    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    double getTailLengthSeconds() const override { return 0.5; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    static constexpr int NUM_BANDS = 3;
    enum BandIndex { LOW = 0, MID = 1, HIGH = 2 };

    //==============================================================================
    // Revised TapeBand Structure (Optimized)
    //==============================================================================
    struct TapeBand
    {
        // --- Saturation & Core ---
        TapeDSP::OptimizedTapeSaturator saturator;
        juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedSaturationDb;

        // NEW (Blueprint II.3): State for Mid Band hysteresis model (per channel)
        std::vector<float> hysteresis_last_input;

        // NEW (Blueprint II.2, II.4): EQ Stages

        // Low Band: IIR Peak Filter for Head Bump. We need per-channel instances.
        using EQFilter = juce::dsp::IIR::Filter<float>;
        std::vector<EQFilter> headBumpFilters;

        // High Band: TPT LPF for Dynamic HF Loss.
        juce::dsp::StateVariableTPTFilter<float> dynamicHfFilter;
        DSPUtils::EnvelopeFollower hfEnvelope;

        // --- Mechanical Degradation Stage (Wow & Flutter) ---
        juce::dsp::DelayLine<float, juce::dsp::DelayLineInterpolationTypes::Linear> delayLine;
        DSPUtils::LFO wowLFO;
        DSPUtils::LFO flutterLFO;
        DSPUtils::NoiseGenerator noiseGen;
        juce::dsp::FirstOrderTPTFilter<float> noiseFilter; // Mono control signal filter

        // OPTIMIZATION FIX: Modulation smoother must be stereo.
        std::vector<juce::dsp::FirstOrderTPTFilter<float>> modSmoothers;

        // Scrape Flutter (Mono control signal filter)
        juce::dsp::StateVariableTPTFilter<float> scrapeNoiseFilter;

        // NEW (Blueprint III.3): Chaotic Modulator
        float chaos_state{ 0.5f };
        static constexpr float CHAOS_R = 3.9f; // Logistic map parameter for chaos

        // Parameter smoothing (smoothedWowDepth, smoothedFlutterDepth remain)
        juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedWowDepth;
        juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedFlutterDepth;

        // Storage for stereo modulation values (LFOs)
        std::pair<float, float> currentWow = { 0.0f, 0.0f };
        std::pair<float, float> currentFlutter = { 0.0f, 0.0f };

        // OPTIMIZATION FIX: Storage for noise components (advanced once per frame)
        float currentFilteredNoise = 0.0f;
        float currentScrapeNoise = 0.0f;
    };

    std::array<TapeBand, NUM_BANDS> bands;

    // Crossover Network (Structure unchanged)
    struct CrossoverNetwork
    {
        juce::dsp::LinkwitzRileyFilter<float> lowMidLowpass;
        juce::dsp::LinkwitzRileyFilter<float> lowMidHighpass;
        juce::dsp::LinkwitzRileyFilter<float> midHighLowpass;
        juce::dsp::LinkwitzRileyFilter<float> midHighHighpass;

        juce::AudioBuffer<float> lowBand, midBand, highBand;

        void prepare(const juce::dsp::ProcessSpec& spec);
        void reset();
        void setCrossoverFrequencies(float lowMid, float midHigh);
        void processBlock(juce::AudioBuffer<float>& buffer);

        juce::AudioBuffer<float>& getLowBand() { return lowBand; }
        juce::AudioBuffer<float>& getMidBand() { return midBand; }
        juce::AudioBuffer<float>& getHighBand() { return highBand; }
    };

    CrossoverNetwork crossover;

    // NEW (Blueprint IV): Noise and Hum Generators
    DSPUtils::NoiseGenerator hissGenerator;
    // Hiss shaping (High Shelf). Need per-channel instances.
    std::vector<juce::dsp::IIR::Filter<float>> hissShapingFilters;

    DSPUtils::LFO humOscillator;
    DSPUtils::LFO humHarmonicOscillator;

    // OPTIMIZATION FIX: Global Parameter Smoothers
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedScrape;
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedChaos;
    // Use Multiplicative smoothing for gain levels (Hiss/Hum)
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Multiplicative> smoothedHissLevel;
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Multiplicative> smoothedHumLevel;

    juce::AudioProcessorValueTreeState& mainApvts;
    std::array<juce::String, NUM_BANDS> saturationParamIds;
    std::array<juce::String, NUM_BANDS> wowParamIds;
    std::array<juce::String, NUM_BANDS> flutterParamIds;
    juce::String lowMidCrossoverParamId, midHighCrossoverParamId;

    // NEW: Parameter IDs
    juce::String scrapeParamId, chaosParamId, hissParamId, humParamId;
    juce::String headBumpFreqParamId, headBumpGainParamId;

    // NEW: Helper methods for the refactored processing
    void updateParameters();
    void processBand(int bandIdx, int sample, int numChannels, juce::AudioBuffer<float>& buffer);
    void updateModulation(int bandIdx);
    float applyModulation(int bandIdx, int channel, float inputSample);
};

================================================================================
// File: FX_Modules/CompressorProcessor.cpp
================================================================================

#include "CompressorProcessor.h"

CompressorProcessor::CompressorProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_";
    typeParamId = slotPrefix + "COMP_TYPE";
    thresholdParamId = slotPrefix + "COMP_THRESHOLD";
    ratioParamId = slotPrefix + "COMP_RATIO";
    attackParamId = slotPrefix + "COMP_ATTACK";
    releaseParamId = slotPrefix + "COMP_RELEASE";
    makeupParamId = slotPrefix + "COMP_MAKEUP";
}

void CompressorProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };
    compressor.prepare(spec);
    makeupGain.prepare(spec);
    reset();
}

void CompressorProcessor::releaseResources()
{
    reset();
}

void CompressorProcessor::reset()
{
    compressor.reset();
    makeupGain.reset();
}

void CompressorProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&)
{
    juce::ScopedNoDenormals noDenormals;

    // === FIX P1: Add standard boilerplate ===
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    // Clear any output channels that didn't contain input data
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());
    // ========================================

    auto type = static_cast<int>(mainApvts.getRawParameterValue(typeParamId)->load());

    compressor.setThreshold(mainApvts.getRawParameterValue(thresholdParamId)->load());
    compressor.setRatio(mainApvts.getRawParameterValue(ratioParamId)->load());
    compressor.setAttack(mainApvts.getRawParameterValue(attackParamId)->load());
    compressor.setRelease(mainApvts.getRawParameterValue(releaseParamId)->load());
    makeupGain.setGainDecibels(mainApvts.getRawParameterValue(makeupParamId)->load());

    juce::dsp::AudioBlock<float> block(buffer);
    juce::dsp::ProcessContextReplacing<float> context(block);
    compressor.process(context);
    makeupGain.process(context);

    if (type == 1) // FET
    {
        for (int channel = 0; channel < buffer.getNumChannels(); ++channel)
        {
            auto* channelData = buffer.getWritePointer(channel);
            for (int i = 0; i < buffer.getNumSamples(); ++i)
                channelData[i] = std::tanh(channelData[i] * 1.2f);
        }
    }
}

================================================================================
// File: FX_Modules/CompressorProcessor.h
================================================================================

#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>

class CompressorProcessor : public juce::AudioProcessor
{
public:
    CompressorProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~CompressorProcessor() override = default;

    const juce::String getName() const override { return "Compressor"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }

    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    double getTailLengthSeconds() const override { return 0.0; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    juce::dsp::Compressor<float> compressor;
    juce::dsp::Gain<float> makeupGain;

    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String typeParamId, thresholdParamId, ratioParamId, attackParamId, releaseParamId, makeupParamId;
};

================================================================================
// File: FX_Modules/DelayProcessor.cpp
================================================================================

//================================================================================
// File: FX_Modules/DelayProcessor.cpp
//================================================================================
#include "DelayProcessor.h"

DelayProcessor::DelayProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_";
    typeParamId = slotPrefix + "DELAY_TYPE";
    timeParamId = slotPrefix + "DELAY_TIME";
    feedbackParamId = slotPrefix + "DELAY_FEEDBACK";
    mixParamId = slotPrefix + "DELAY_MIX";
    dampingParamId = slotPrefix + "DELAY_DAMPING";
}

void DelayProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };
    delayLine.prepare(spec);
    delayLine.setMaximumDelayInSamples(static_cast<int>(sampleRate * 2.0));
    feedbackFilter.prepare(spec);
    feedbackFilter.setType(juce::dsp::StateVariableTPTFilterType::lowpass);
    reset();
}

void DelayProcessor::releaseResources()
{
    reset();
}

void DelayProcessor::reset()
{
    delayLine.reset();
    feedbackFilter.reset();
}


// Replace processBlock entirely:
void DelayProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages) {
    // FIX P1: Boilerplate
    juce::ScopedNoDenormals noDenormals;
    // FIX C4100
    juce::ignoreUnused(midiMessages);
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());
    // Get parameters
    auto type = static_cast<int>(mainApvts.getRawParameterValue(typeParamId)->load());
    float time = mainApvts.getRawParameterValue(timeParamId)->load();
    float feedback = mainApvts.getRawParameterValue(feedbackParamId)->load();
    float mix = mainApvts.getRawParameterValue(mixParamId)->load();
    float damping = mainApvts.getRawParameterValue(dampingParamId)->load();

    float delaySamples = (float)(getSampleRate() * time / 1000.0);
    feedbackFilter.setCutoffFrequency(damping);
    // FIX P3: Corrected feedback loop
    for (int channel = 0; channel < buffer.getNumChannels(); ++channel)
    {
        // ✅ FINAL FIX: The filter was correctly prepared for stereo, so we just need to process each channel.
        // The previous check was incorrect because StateVariableTPTFilter *does not* have getNumChannels().
        auto* channelData = buffer.getWritePointer(channel);
        for (int i = 0; i < buffer.getNumSamples(); ++i)
        {
            float inputSample = channelData[i];
            // 1. Get the delayed sample
            float delayedSample = delayLine.popSample(channel, delaySamples, true);
            // 2. Apply damping filter to the delayed signal
            float filteredDelayedSample = feedbackFilter.processSample(channel, delayedSample);
            // 3. Apply saturation if analog mode
            if (type == 1) // Analog BBD
            {
                filteredDelayedSample = std::tanh(filteredDelayedSample);
            }

            // 4. Calculate feedback amount
            float feedbackSample = filteredDelayedSample * feedback;
            // 5. Calculate input to the delay line
            float inputToDelay = inputSample + feedbackSample;
            // 6. Push into the delay line
            delayLine.pushSample(channel, inputToDelay);
            // 7. Calculate output mix (Use the processed signal)
            channelData[i] = (inputSample * (1.0f - mix)) + (filteredDelayedSample * mix);
        }
    }
}

================================================================================
// File: FX_Modules/DelayProcessor.h
================================================================================

#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>

class DelayProcessor : public juce::AudioProcessor
{
public:
    DelayProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~DelayProcessor() override = default;

    const juce::String getName() const override { return "Delay"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    double getTailLengthSeconds() const override { return 2.0; }

    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    juce::dsp::DelayLine<float, juce::dsp::DelayLineInterpolationTypes::Linear> delayLine;
    juce::dsp::StateVariableTPTFilter<float> feedbackFilter;
    // float lastFeedbackOutput[2] = { 0.0f, 0.0f }; // REMOVE THIS LINE

    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String typeParamId, timeParamId, feedbackParamId, mixParamId, dampingParamId;
};

================================================================================
// File: FX_Modules/DistortionProcessor.cpp
================================================================================

﻿//================================================================================
// File: FX_Modules/DistortionProcessor.cpp (CORRECTED)
//================================================================================

#include "DistortionProcessor.h"

// FIX: Removed incorrect initialization of ProcessorDuplicator from the initializer list.
// Initialization must rely on prepareToPlay where the actual sample rate is known.
DistortionProcessor::DistortionProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
    // REMOVED:
    // inputDCBlocker(juce::dsp::IIR::Coefficients<float>::makeHighPass(44100.0, 20.0f)),
    // outputDCBlocker(juce::dsp::IIR::Coefficients<float>::makeHighPass(44100.0, 20.0f))
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_";
    driveParamId = slotPrefix + "DISTORTION_DRIVE";
    levelParamId = slotPrefix + "DISTORTION_LEVEL";
    typeParamId = slotPrefix + "DISTORTION_TYPE";
    biasParamId = slotPrefix + "DISTORTION_BIAS";
    characterParamId = slotPrefix + "DISTORTION_CHARACTER";
}

// The rest of the DistortionProcessor.cpp file remains the same as your provided version,
// as the prepareToPlay implementation was already handling initialization correctly.

void DistortionProcessor::prepareToPlay(double sampleRate, int samplesPerBlock) {
    auto numChannels = (juce::uint32)getTotalNumInputChannels();
    if (numChannels == 0) numChannels = 2;

    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, numChannels };

    preGain.prepare(spec);
    postGain.prepare(spec);
    preGain.setRampDurationSeconds(0.01);
    postGain.setRampDurationSeconds(0.01);

    // === FIX: Initialize the ProcessorDuplicator for DC Blocking (High-pass at 20Hz) ===
    inputDCBlocker.prepare(spec);
    outputDCBlocker.prepare(spec);

    if (sampleRate > 0)
    {
        // Calculate coefficients (returns a ReferenceCountedPointer)
        auto dcBlockerCoeffs = juce::dsp::IIR::Coefficients<float>::makeHighPass(sampleRate, 20.0f);
        // Assign to the shared state of the ProcessorDuplicator
        *inputDCBlocker.state = *dcBlockerCoeffs;
        *outputDCBlocker.state = *dcBlockerCoeffs;
    }
    // =====================================================================================

    double smoothingTime = 0.05;
    smoothedBias.reset(sampleRate, smoothingTime);
    smoothedCharacter.reset(sampleRate, smoothingTime);

    inputFollower.prepare(spec);
    inputFollower.setAttackTime(5.0f);
    inputFollower.setReleaseTime(50.0f);

    localOversampler = std::make_unique<juce::dsp::Oversampling<float>>(
        static_cast<size_t>(numChannels), 2, juce::dsp::Oversampling<float>::filterHalfBandFIREquiripple, true);
    localOversampler->initProcessing(static_cast<size_t>(samplesPerBlock));

    reset();
}

void DistortionProcessor::releaseResources() {
    reset();
}

void DistortionProcessor::reset() {
    preGain.reset();
    postGain.reset();
    // === FIX: Reset the ProcessorDuplicators ===
    inputDCBlocker.reset();
    outputDCBlocker.reset();
    // ===========================================
    inputFollower.reset();
    if (localOversampler)
        localOversampler->reset();
    smoothedBias.setCurrentAndTargetValue(0.0f);
    smoothedCharacter.setCurrentAndTargetValue(0.5f);
}

float DistortionProcessor::processTube(float x, float bias, float dynamicBias) {
    float effectiveBias = bias * 0.5f + (dynamicBias * 0.3f);
    float y = x + effectiveBias;
    if (y > 0)
        return std::tanh(y * 0.9f);
    else
        return std::tanh(y * 1.4f);
}

float DistortionProcessor::processOpAmp(float x, float character) {
    float soft = std::tanh(x * 1.5f);
    float hard = x / (std::abs(x) + 0.6f) * 0.8f;
    return juce::jmap(character, hard, soft);
}

float DistortionProcessor::processGermanium(float x, float stability) {
    float gateThreshold = juce::jmap(stability, 0.08f, 0.001f);
    if (std::abs(x) < gateThreshold) return x * 0.1f;
    float positiveDrive = 1.8f;
    float negativeDrive = juce::jmap(stability, 0.7f, 1.3f);
    if (x > 0)
        return (1.0f - std::exp(-x * positiveDrive)) * 0.85f;
    else
        return (-1.0f + std::exp(std::abs(x) * negativeDrive)) * 0.85f;
}

void DistortionProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&) {
    juce::ScopedNoDenormals noDenormals;

    // === FIX P1: Add standard boilerplate ===
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    // Clear any output channels that didn't contain input data
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());
    // ========================================

    auto type = static_cast<Algo>(static_cast<int>(mainApvts.getRawParameterValue(typeParamId)->load()));
    preGain.setGainDecibels(mainApvts.getRawParameterValue(driveParamId)->load());
    postGain.setGainDecibels(mainApvts.getRawParameterValue(levelParamId)->load());
    smoothedBias.setTargetValue(mainApvts.getRawParameterValue(biasParamId)->load());
    smoothedCharacter.setTargetValue(mainApvts.getRawParameterValue(characterParamId)->load());

    juce::dsp::AudioBlock<float> block(buffer);
    juce::dsp::ProcessContextReplacing<float> context(block);

    inputDCBlocker.process(context);
    preGain.process(context);

    auto oversampledBlock = localOversampler->processSamplesUp(block);

    float currentBias = 0.0f;
    float currentCharacter = 0.0f;

    // === FIX (C4267): Explicitly cast dimensions to int and use int for loop indices ===
    int numOversampledSamples = (int)oversampledBlock.getNumSamples();
    int numChannels = (int)oversampledBlock.getNumChannels();

    for (int i = 0; i < numOversampledSamples; ++i)
    {
        currentBias = smoothedBias.getNextValue();
        currentCharacter = smoothedCharacter.getNextValue();
        float currentDynamicBias = 0.0f;

        for (int channel = 0; channel < numChannels; ++channel)
        {
            // Arguments are now int, resolving warnings
            float inputSample = oversampledBlock.getSample(channel, i);

            if (channel == 0)
                currentDynamicBias = inputFollower.process(inputSample);

            float outputSample = inputSample;
            switch (type)
            {
            case Algo::VintageTube:
                outputSample = processTube(inputSample, currentBias, currentDynamicBias);
                break;
            case Algo::OpAmp:
                outputSample = processOpAmp(inputSample, currentCharacter);
                break;
            case Algo::GermaniumFuzz:
                outputSample = processGermanium(inputSample, currentCharacter);
                break;
            }
            // Arguments are now int, resolving warnings
            oversampledBlock.setSample(channel, i, outputSample);
        }
    }
    // =====================================================================================

    localOversampler->processSamplesDown(block);
    outputDCBlocker.process(context);
    postGain.process(context);
}

================================================================================
// File: FX_Modules/DistortionProcessor.h
================================================================================

﻿#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>
#include "../DSPUtils.h"

class DistortionProcessor : public juce::AudioProcessor
{
public:
    DistortionProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~DistortionProcessor() override = default;

    const juce::String getName() const override { return "Distortion"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    double getTailLengthSeconds() const override { return 0.0; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    enum class Algo { VintageTube, OpAmp, GermaniumFuzz };

    juce::dsp::Gain<float> preGain;
    juce::dsp::Gain<float> postGain;

    // === FIX (C2039): Replace DCBlocker with ProcessorDuplicator for robust multi-channel filtering ===
    using DCFilter = juce::dsp::IIR::Filter<float>;
    using DCFilterState = juce::dsp::IIR::Coefficients<float>;
    juce::dsp::ProcessorDuplicator<DCFilter, DCFilterState> inputDCBlocker;
    juce::dsp::ProcessorDuplicator<DCFilter, DCFilterState> outputDCBlocker;
    // ===================================================================================================

    std::unique_ptr<juce::dsp::Oversampling<float>> localOversampler;
    DSPUtils::EnvelopeFollower inputFollower;

    float processTube(float x, float bias, float dynamicBias);
    float processOpAmp(float x, float character);
    float processGermanium(float x, float stability);

    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String driveParamId, levelParamId, typeParamId, biasParamId, characterParamId;
    // Smoothed values for parameters not handled by dsp::Gain
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedBias;
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedCharacter;
};

================================================================================
// File: FX_Modules/FilterProcessor.cpp
================================================================================

#include "FilterProcessor.h"

FilterProcessor::FilterProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_";
    cutoffParamId = slotPrefix + "FILTER_CUTOFF";
    resonanceParamId = slotPrefix + "FILTER_RESONANCE";
    driveParamId = slotPrefix + "FILTER_DRIVE";
    typeParamId = slotPrefix + "FILTER_TYPE";
    profileParamId = slotPrefix + "FILTER_PROFILE";
}

void FilterProcessor::prepareToPlay(double sampleRate, int samplesPerBlock) {
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };
    svfFilter.prepare(spec);
    ladderFilter.prepare(spec);
    reset();
}

void FilterProcessor::releaseResources() {
    reset();
}

void FilterProcessor::reset() {
    svfFilter.reset();
    ladderFilter.reset();
}

void FilterProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&) {
    juce::ScopedNoDenormals noDenormals;

    // === FIX P1: Add standard boilerplate ===
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    // Clear any output channels that didn't contain input data
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());
    // ========================================

    auto profile = static_cast<Profile>(static_cast<int>(mainApvts.getRawParameterValue(profileParamId)->load()));
    juce::dsp::AudioBlock<float> block(buffer);
    juce::dsp::ProcessContextReplacing<float> context(block);

    float rawResonance = mainApvts.getRawParameterValue(resonanceParamId)->load();

    switch (profile)
    {
    case svfProfile:
        svfFilter.setCutoffFrequency(mainApvts.getRawParameterValue(cutoffParamId)->load());
        svfFilter.setResonance(rawResonance);
        svfFilter.setType(static_cast<juce::dsp::StateVariableTPTFilterType>(static_cast<int>(mainApvts.getRawParameterValue(typeParamId)->load())));
        svfFilter.process(context);
        break;

    case transistorLadder:
    {
        ladderFilter.setMode(juce::dsp::LadderFilterMode::LPF24);
        ladderFilter.setCutoffFrequencyHz(mainApvts.getRawParameterValue(cutoffParamId)->load());
        float ladderResonance = juce::jlimit(0.0f, 1.0f, rawResonance / 10.0f);
        ladderFilter.setResonance(ladderResonance);
        ladderFilter.setDrive(mainApvts.getRawParameterValue(driveParamId)->load());
        ladderFilter.process(context);
        break;
    }
    case diodeLadder:
    {
        ladderFilter.setMode(juce::dsp::LadderFilterMode::LPF12);
        ladderFilter.setCutoffFrequencyHz(mainApvts.getRawParameterValue(cutoffParamId)->load());
        float ladderResonanceDiode = juce::jlimit(0.0f, 1.0f, rawResonance / 10.0f);
        ladderFilter.setResonance(ladderResonanceDiode);
        ladderFilter.setDrive(mainApvts.getRawParameterValue(driveParamId)->load());
        ladderFilter.process(context);
        break;
    }
    case ota:
        svfFilter.setType(juce::dsp::StateVariableTPTFilterType::lowpass);
        svfFilter.setCutoffFrequency(mainApvts.getRawParameterValue(cutoffParamId)->load());
        svfFilter.setResonance(rawResonance);
        svfFilter.process(context);
        break;
    }
}

================================================================================
// File: FX_Modules/FilterProcessor.h
================================================================================

#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>

class FilterProcessor : public juce::AudioProcessor
{
public:
    FilterProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~FilterProcessor() override = default;

    const juce::String getName() const override { return "Filter"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    double getTailLengthSeconds() const override { return 0.0; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

    enum Profile { svfProfile, transistorLadder, diodeLadder, ota };

private:
    juce::dsp::StateVariableTPTFilter<float> svfFilter;
    juce::dsp::LadderFilter<float> ladderFilter;

    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String cutoffParamId, resonanceParamId, driveParamId, typeParamId, profileParamId;
};

================================================================================
// File: FX_Modules/ModulationProcessor.cpp
================================================================================

#include "ModulationProcessor.h"

ModulationProcessor::ModulationProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_";
    modeParamId = slotPrefix + "MODULATION_MODE";
    rateParamId = slotPrefix + "MODULATION_RATE";
    depthParamId = slotPrefix + "MODULATION_DEPTH";
    feedbackParamId = slotPrefix + "MODULATION_FEEDBACK";
    mixParamId = slotPrefix + "MODULATION_MIX";
}

void ModulationProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };
    chorus.prepare(spec);
    phaser.prepare(spec);
    reset();
}

void ModulationProcessor::releaseResources()
{
    reset();
}

void ModulationProcessor::reset()
{
    chorus.reset();
    phaser.reset();
}

void ModulationProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&)
{
    juce::ScopedNoDenormals noDenormals;

    // === FIX P1: Add standard boilerplate ===
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    // Clear any output channels that didn't contain input data
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());
    // ========================================

    auto mode = static_cast<ModType>(static_cast<int>(mainApvts.getRawParameterValue(modeParamId)->load()));
    float rate = mainApvts.getRawParameterValue(rateParamId)->load();
    float depth = mainApvts.getRawParameterValue(depthParamId)->load();
    float feedback = mainApvts.getRawParameterValue(feedbackParamId)->load();
    float mix = mainApvts.getRawParameterValue(mixParamId)->load();

    juce::dsp::AudioBlock<float> block(buffer);
    juce::dsp::ProcessContextReplacing<float> context(block);

    if (mode == Phaser)
    {
        phaser.setRate(rate);
        phaser.setDepth(depth);
        phaser.setFeedback(feedback);
        phaser.setMix(mix);
        phaser.process(context);
    }
    else
    {
        chorus.setRate(rate);
        chorus.setDepth(depth);
        chorus.setFeedback(feedback);
        chorus.setMix(mode == Vibrato ? 1.0f : mix);
        chorus.setCentreDelay(mode == Flanger ? 2.0f : 10.0f);
        chorus.process(context);
    }
}

================================================================================
// File: FX_Modules/ModulationProcessor.h
================================================================================

#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>

class ModulationProcessor : public juce::AudioProcessor
{
public:
    ModulationProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~ModulationProcessor() override = default;

    const juce::String getName() const override { return "Modulation"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    double getTailLengthSeconds() const override { return 0.0; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    juce::dsp::Chorus<float> chorus;
    juce::dsp::Phaser<float> phaser;

    enum ModType { Chorus, Flanger, Vibrato, Phaser };

    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String modeParamId, rateParamId, depthParamId, feedbackParamId, mixParamId;
};

================================================================================
// File: FX_Modules/MorphoCompProcessor.cpp
================================================================================

#include "MorphoCompProcessor.h"
// REMOVED: Internal SignalAnalyzer implementation.

MorphoCompProcessor::MorphoCompProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_";
    amountParamId = slotPrefix + "MORPHO_AMOUNT";
    responseParamId = slotPrefix + "MORPHO_RESPONSE";
    modeParamId = slotPrefix + "MORPHO_MODE";
    morphXParamId = slotPrefix + "MORPHO_X";
    morphYParamId = slotPrefix + "MORPHO_Y";
    mixParamId = slotPrefix + "MORPHO_MIX";
}

void MorphoCompProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };

    // UPDATED: Prepare the new analyzers
    spectralAnalyzer.prepare(spec);
    transientDetector.prepare(spec);

    compressor.prepare(spec);
    saturator.prepare(spec);

    // Initial smoothing time (will be updated dynamically in processBlock)
    morphXSmoother.reset(sampleRate, 0.1);
    morphYSmoother.reset(sampleRate, 0.1);

    // NEW: Report latency introduced by the analyzers.
    // The latency is determined by the hop size of the analyzers (e.g., 256 samples).
    setLatencySamples(transientDetector.getLatencyInSamples());

    reset();
}

void MorphoCompProcessor::releaseResources() {
    reset();
}

void MorphoCompProcessor::reset() {
    // UPDATED: Reset the new analyzers
    spectralAnalyzer.reset();
    transientDetector.reset();

    compressor.reset();
    saturator.reset();
    morphXSmoother.setCurrentAndTargetValue(0.5f);
    morphYSmoother.setCurrentAndTargetValue(0.5f);
}

template <typename T>
T bilinearInterp(T c00, T c10, T c01, T c11, float tx, float ty)
{
    T a = c00 * (1.0f - tx) + c10 * tx;
    T b = c01 * (1.0f - tx) + c11 * tx;
    return a * (1.0f - ty) + b * ty;
}

void MorphoCompProcessor::updateCompressorAndSaturation(float amount, float response, float morphX, float morphY)
{
    float attackFactor = bilinearInterp(Topologies::VCA.attackFactor, Topologies::FET.attackFactor,
        Topologies::Opto.attackFactor, Topologies::VariMu.attackFactor, morphX, morphY);
    float releaseFactor = bilinearInterp(Topologies::VCA.releaseFactor, Topologies::FET.releaseFactor,
        Topologies::Opto.releaseFactor, Topologies::VariMu.releaseFactor, morphX, morphY);
    float ratioFactor = bilinearInterp(Topologies::VCA.ratioFactor, Topologies::FET.ratioFactor,
        Topologies::Opto.ratioFactor, Topologies::VariMu.ratioFactor, morphX, morphY);
    float saturationDrive = bilinearInterp(Topologies::VCA.saturationDrive, Topologies::FET.saturationDrive,
        Topologies::Opto.saturationDrive, Topologies::VariMu.saturationDrive, morphX, morphY);

    float baseThreshold = juce::jmap(amount, 0.0f, -40.0f);
    float baseRatio = juce::jmap(amount, 1.5f, 8.0f);

    float baseAttack = std::pow(10.0f, juce::jmap(response, 2.0f, 0.0f));
    float baseRelease = std::pow(10.0f, juce::jmap(response, 3.0f, 1.5f));

    compressor.setThreshold(baseThreshold);
    compressor.setRatio(juce::jlimit(1.0f, 20.0f, baseRatio * ratioFactor));
    compressor.setAttack(juce::jlimit(0.1f, 500.0f, baseAttack * attackFactor));
    compressor.setRelease(juce::jlimit(5.0f, 2000.0f, baseRelease * releaseFactor));

    currentSaturationDrive = 1.0f + saturationDrive;

    if (morphX > 0.5f && morphY < 0.5f) saturator.functionToUse = Topologies::FET.saturationFunc;
    else if (morphX < 0.5f && morphY > 0.5f) saturator.functionToUse = Topologies::Opto.saturationFunc;
    else if (morphX > 0.5f && morphY > 0.5f) saturator.functionToUse = Topologies::VariMu.saturationFunc;
    else saturator.functionToUse = Topologies::VCA.saturationFunc;
}

void MorphoCompProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&) {
    juce::ScopedNoDenormals noDenormals;

    // P1 Boilerplate
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    int numSamples = buffer.getNumSamples();
    int numChannels = totalNumInputChannels;

    // 1. Run Analysis (Sample-by-sample)
    // We must run the analysis sample-by-sample to update the analyzer states correctly over time.
    for (int i = 0; i < numSamples; ++i)
    {
        // Calculate mono sum
        float monoSample = 0.0f;
        for (int ch = 0; ch < numChannels; ++ch)
        {
            monoSample += buffer.getSample(ch, i);
        }
        if (numChannels > 0)
            monoSample /= (float)numChannels;

        // Process analysis using the refactored sample-based interface
        spectralAnalyzer.processSample(monoSample);
        transientDetector.processSample(monoSample);
    }


    // 2. Get Parameters and Analysis Results
    float amount = mainApvts.getRawParameterValue(amountParamId)->load();
    float response = mainApvts.getRawParameterValue(responseParamId)->load();
    bool autoMorph = mainApvts.getRawParameterValue(modeParamId)->load() > 0.5f; // 0=Auto, 1=Manual - Corrected logic
    float mix = mainApvts.getRawParameterValue(mixParamId)->load();

    float targetX, targetY;
    if (autoMorph)
    {
        // Get analysis results. Since we ran them through the whole block,
        // these return the state at the END of the block (which is fine for setting the target).
        targetX = transientDetector.getTransientValue();
        // Invert centroid (Low centroid = High Y, more 'Opto/VariMu')
        targetY = 1.0f - spectralAnalyzer.getSpectralCentroid();
    }
    else
    {
        targetX = mainApvts.getRawParameterValue(morphXParamId)->load();
        targetY = mainApvts.getRawParameterValue(morphYParamId)->load();
    }

    // 3. Configure Smoothing
    // FIX: Dynamic Smoothing Time
    // Auto mode needs moderate smoothing (200ms), Manual mode needs fast smoothing (50ms).
    double smoothingTime = autoMorph ? 0.2 : 0.05;

    // Update the smoother's ramp length dynamically.
    if (getSampleRate() > 0)
    {
        morphXSmoother.reset(getSampleRate(), smoothingTime);
        morphYSmoother.reset(getSampleRate(), smoothingTime);
    }

    morphXSmoother.setTargetValue(targetX);
    morphYSmoother.setTargetValue(targetY);

    // 4. Synchronize Smoothers and Update Parameters
    // FIX: Correct Smoother Synchronization (Required for block processing)
    // Advance the smoother once to get the starting value for the block.
    float currentX = morphXSmoother.getNextValue();
    float currentY = morphYSmoother.getNextValue();

    // Skip the remaining samples in the block to keep the smoother synchronized.
    if (numSamples > 1)
    {
        morphXSmoother.skip(numSamples - 1);
        morphYSmoother.skip(numSamples - 1);
    }

    // Update compressor parameters based on the smoothed position
    updateCompressorAndSaturation(amount, response, currentX, currentY);

    // 5. Audio Processing (Block-wise)
    juce::dsp::AudioBlock<float> block(buffer);

    juce::AudioBuffer<float> dryBuffer;
    if (mix < 1.0f) dryBuffer.makeCopyOf(buffer);

    juce::dsp::ProcessContextReplacing<float> context(block);
    compressor.process(context);

    if (currentSaturationDrive > 1.01f)
    {
        block.multiplyBy(currentSaturationDrive);
        saturator.process(context);
        block.multiplyBy(1.0f / currentSaturationDrive);
    }

    if (mix < 1.0f)
    {
        for (int ch = 0; ch < buffer.getNumChannels(); ++ch)
        {
            if (ch < dryBuffer.getNumChannels())
            {
                buffer.addFrom(ch, 0, dryBuffer, ch, 0, numSamples, 1.0f - mix);
                buffer.applyGain(ch, 0, numSamples, mix);
            }
        }
    }
}


================================================================================
// File: FX_Modules/MorphoCompProcessor.h
================================================================================

#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>
#include "../DSPUtils.h"
// NEW: Include the robust analysis helpers
#include "../DSP_Helpers/SpectralAnalyzer.h"
#include "../DSP_Helpers/TransientDetector.h"

// REMOVED: Internal flawed SignalAnalyzer class definition.

// [TopologyParams struct and Topologies namespace - Identical to input, omitted for brevity]
struct TopologyParams
{
    float attackFactor;
    float releaseFactor;
    float ratioFactor;
    float saturationDrive;
    float (*saturationFunc)(float);
};

namespace Topologies
{
    static float vcaSaturation(float x) { return std::tanh(x); }
    static float fetSaturation(float x) { return x / (std::abs(x) + 0.7f); }
    static float optoSaturation(float x) { return std::tanh(x * 0.8f); }
    static float varimuSaturation(float x) { return std::tanh(x * 1.5f); }

    const TopologyParams VCA = { 1.0f, 1.0f, 1.0f, 0.5f, vcaSaturation };
    const TopologyParams FET = { 0.2f, 0.8f, 1.5f, 1.5f, fetSaturation };
    const TopologyParams Opto = { 2.0f, 1.5f, 0.8f, 0.2f, optoSaturation };
    const TopologyParams VariMu = { 1.5f, 2.0f, 0.9f, 1.0f, varimuSaturation };
}


class MorphoCompProcessor : public juce::AudioProcessor
{
public:
    MorphoCompProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~MorphoCompProcessor() override = default;

    const juce::String getName() const override { return "MorphoComp"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    // [JUCE Boilerplate - Identical to input]
    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    // Increased tail length slightly due to analysis latency and release times.
    double getTailLengthSeconds() const override { return 0.5; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    void updateCompressorAndSaturation(float amount, float response, float morphX, float morphY);

    // UPDATED: Use the robust analysis helpers instead of the internal analyzer
    // SignalAnalyzer analyzer; // REMOVED
    SpectralAnalyzer spectralAnalyzer;
    TransientDetector transientDetector;

    juce::dsp::Compressor<float> compressor;
    juce::dsp::WaveShaper<float> saturator;

    // Use Linear smoothing for the control signals (X/Y)
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> morphXSmoother, morphYSmoother;
    float currentSaturationDrive = 1.0f;

    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String amountParamId, responseParamId, modeParamId, morphXParamId, morphYParamId, mixParamId;
};


================================================================================
// File: FX_Modules/PhysicalResonatorProcessor.cpp
================================================================================

﻿//================================================================================
// File: FX_Modules/PhysicalResonatorProcessor.cpp
//================================================================================
#include "PhysicalResonatorProcessor.h"

// ===================== ExcitationGenerator Implementation =====================
ExcitationGenerator::ExcitationGenerator() {
    noiseGen.setType(DSPUtils::NoiseGenerator::NoiseType::White);
    // Configure filter type for coloring the noise
    colorFilter.setType(juce::dsp::StateVariableTPTFilterType::lowpass);
}

void ExcitationGenerator::prepare(const juce::dsp::ProcessSpec& spec) {
    sampleRate = spec.sampleRate;
    transientDetector.prepare(spec);
    spectralAnalyzer.prepare(spec);
    // Prepare the single filter instance for multi-channel operation
    colorFilter.prepare(spec);
    burstEnvelope.setSampleRate(sampleRate);
    smoothedExciteType.reset(sampleRate, 0.05);
    smoothedSensitivity.reset(sampleRate, 0.05);
    reset();
}

void ExcitationGenerator::reset() {
    transientDetector.reset();
    spectralAnalyzer.reset();
    colorFilter.reset();
    burstEnvelope.reset();
    smoothedExciteType.setCurrentAndTargetValue(0.5f);
    smoothedSensitivity.setCurrentAndTargetValue(0.5f);
}

// A simplified, robust excitation generator based on transient following.
void ExcitationGenerator::process(const juce::dsp::AudioBlock<float>& inputBlock, juce::dsp::AudioBlock<float>& outputExcitationBlock, const ExcitationParams& params) {
    noiseGen.setType(params.noiseType == 1 ? DSPUtils::NoiseGenerator::NoiseType::Pink : DSPUtils::NoiseGenerator::NoiseType::White);

    smoothedExciteType.setTargetValue(params.exciteType);
    smoothedSensitivity.setTargetValue(params.sensitivity);

    int numSamples = (int)inputBlock.getNumSamples();
    int numChannels = (int)inputBlock.getNumChannels();

    // Fixed cutoff for noise coloring (can be modulated later if desired)
    colorFilter.setCutoffFrequency(5000.0f);
    colorFilter.setResonance(0.7f);

    for (int i = 0; i < numSamples; ++i) {
        float currentExciteType = smoothedExciteType.getNextValue();
        float currentSensitivity = smoothedSensitivity.getNextValue();

        // 1. Transient Detection (Mono analysis)
        float monoSample = 0.0f;
        for (int ch = 0; ch < numChannels; ++ch)
            monoSample += inputBlock.getSample(ch, i);
        if (numChannels > 0) monoSample /= (float)numChannels;

        transientDetector.processSample(monoSample);
        float transientLevel = transientDetector.getTransientValue();

        // 2. Envelope Generation (Transient following)
        float env = juce::jlimit(0.0f, 1.0f, transientLevel * currentSensitivity * 2.0f);

        // 3. Excitation Signal Synthesis
        for (int ch = 0; ch < numChannels; ++ch) {
            // Source A: Continuous (Input Audio)
            float continuous = inputBlock.getSample(ch, i) * currentSensitivity;

            // Source B: Impulsive (Noise Burst)
            float noise = noiseGen.getNextSample();
            // Process using the multi-channel aware filter instance
            // Note: StateVariableTPTFilter also requires the channel index in JUCE 8.
            float filteredNoise = colorFilter.processSample(ch, noise);
            float impulsive = filteredNoise * env;

            // Crossfade (Excite Type: 0.0 = Continuous, 1.0 = Impulsive)
            float excitation = (continuous * (1.0f - currentExciteType)) + (impulsive * currentExciteType);

            outputExcitationBlock.setSample(ch, i, excitation * 1.5f); // Slight boost
        }
    }
}

// ===================== ModalResonator Implementation =====================
// ... (ModalResonator implementation remains unchanged as it uses IIR::Filter) ...
void ModalResonator::prepare(const juce::dsp::ProcessSpec& spec) {
    sampleRate = spec.sampleRate;
    initializeMaterialTables();

    if (channelFilters.size() != spec.numChannels)
        channelFilters.resize(spec.numChannels);

    // CRITICAL FIX: Prepare filters as MONO since we have dedicated instances per channel.
    juce::dsp::ProcessSpec monoSpec = spec;
    monoSpec.numChannels = 1;

    for (auto& bank : channelFilters) {
        for (auto& f : bank) {
            f.prepare(monoSpec);
        }
    }
}

void ModalResonator::reset() {
    for (auto& bank : channelFilters)
        for (auto& f : bank) f.reset();
}

void ModalResonator::initializeMaterialTables() {
    if (tablesInitialized) return;

    // Expanded archetypes based on Blueprint Section 3.3.1 (Ratios / Gains / Qs)

    // Wood (Marimba-like)
    float woodRatios[] = { 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576 };
    float woodGains[] = { 1, 0.6f, 0.3f, 0.2f, 0.15f, 0.1f, 0.08f, 0.06f, 0.05f, 0.04f, 0.035f, 0.03f, 0.028f, 0.025f, 0.02f, 0.018f, 0.016f, 0.014f, 0.012f, 0.01f, 0.009f, 0.008f, 0.007f, 0.006f };
    float woodQs[] = { 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470, 490, 510 };

    // Metal (Vibraphone-like)
    float metalRatios[] = { 1, 3.95f, 8.8f, 15.5f, 24.0f, 34.2f, 46.0f, 59.8f, 75.7f, 93.7f, 113.8f, 136.0f, 160.3f, 186.7f, 215.2f, 245.8f, 278.5f, 313.3f, 340.2f, 380.0f, 415.5f, 450.1f, 490.2f, 530.8f };
    float metalGains[] = { 0.9f, 1.0f, 0.8f, 0.7f, 0.6f, 0.5f, 0.45f, 0.40f, 0.38f, 0.36f, 0.34f, 0.32f, 0.30f, 0.28f, 0.26f, 0.24f, 0.22f, 0.20f, 0.18f, 0.16f, 0.15f, 0.14f, 0.13f, 0.12f };
    float metalQs[] = { 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 1700, 1600, 1500, 1400, 1300, 1200, 1100, 1000, 950, 900, 850, 800, 780, 760, 740, 720 };

    // Glass/Bell (Highly inharmonic)
    float glassRatios[] = { 1, 1.5f, 2.0f, 2.76f, 3.00f, 3.50f, 4.2f, 4.9f, 5.7f, 6.6f, 7.6f, 8.7f, 9.9f, 11.2f, 12.6f, 14.1f, 15.7f, 17.4f, 19.2f, 21.1f, 23.1f, 25.2f, 27.4f, 29.7f };
    float glassGains[] = { 0.8f, 1.0f, 0.9f, 0.75f, 0.85f, 0.6f, 0.55f, 0.50f, 0.45f, 0.40f, 0.36f, 0.33f, 0.30f, 0.27f, 0.24f, 0.22f, 0.20f, 0.18f, 0.16f, 0.15f, 0.14f, 0.13f, 0.12f, 0.11f };
    float glassQs[] = { 1000, 1500, 2000, 2500, 3000, 3500, 3400, 3300, 3200, 3100, 3000, 2900, 2800, 2700, 2600, 2500, 2400, 2300, 2200, 2100, 2050, 2000, 1950, 1900 };

    for (int i = 0; i < NUM_MODES; ++i) {
        woodData.ratios[i] = woodRatios[i]; woodData.gains[i] = woodGains[i]; woodData.qs[i] = woodQs[i];
        metalData.ratios[i] = metalRatios[i]; metalData.gains[i] = metalGains[i]; metalData.qs[i] = metalQs[i];
        glassData.ratios[i] = glassRatios[i]; glassData.gains[i] = glassGains[i]; glassData.qs[i] = glassQs[i];
    }
    tablesInitialized = true;
}

void ModalResonator::computeModeParams(float tuneHz, float structure, float brightness, float damping, float position) {
    // Structure: 0.0 Wood -> 0.5 Metal -> 1.0 Glass
    auto lerp = [](float a, float b, float t) { return a + (b - a) * t; };
    const float split = 0.5f;

    float tA = juce::jlimit(0.0f, 1.0f, structure / split);
    float tB = juce::jlimit(0.0f, 1.0f, (structure - split) / (1.0f - split));

    for (int m = 0; m < NUM_MODES; ++m) {
        float r, g, q;

        if (structure < split) { // Wood to Metal
            r = lerp(woodData.ratios[m], metalData.ratios[m], tA);
            g = lerp(woodData.gains[m], metalData.gains[m], tA);
            q = lerp(woodData.qs[m], metalData.qs[m], tA);
        }
        else { // Metal to Glass
            r = lerp(metalData.ratios[m], glassData.ratios[m], tB);
            g = lerp(metalData.gains[m], glassData.gains[m], tB);
            q = lerp(metalData.qs[m], glassData.qs[m], tB);
        }

        // Apply Modifiers

        // Brightness: Exponential scaling of gain based on mode index.
        float brightAtten = std::pow(juce::jmap(brightness, 0.1f, 1.0f), (float)m * 0.1f);

        // Damping: Scales Q (0.0 = long decay, 1.0 = short decay). Exponential mapping.
        float dampingScale = std::pow(10.0f, juce::jmap(damping, 0.0f, 1.0f, 1.0f, -1.5f));

        // Position: Simulate strike position (Simple attenuation of harmonics)
        float pos = position * 2.0f;
        if (pos > 1.0f) pos = 2.0f - pos; // 0 (edge) to 1 (center)

        float posShape = 1.0f;
        if (pos > 0.8f) { // Near center, attenuate even harmonics
            if ((m + 1) % 2 == 0)
                posShape = 1.0f - (pos - 0.8f) * 5.0f;
        }

        // Final Calculations and Safety Clamping
        modeFreqs[m] = tuneHz * r;
        modeGains[m] = g * brightAtten * posShape;
        modeQs[m] = q * dampingScale;

        modeFreqs[m] = juce::jlimit(20.0f, (float)sampleRate * 0.49f, modeFreqs[m]);
        modeQs[m] = juce::jlimit(5.0f, 10000.0f, modeQs[m]);
    }
}

void ModalResonator::process(const juce::dsp::AudioBlock<float>& excitationBlock,
    juce::dsp::AudioBlock<float>& outputBlock,
    float tune, float structure, float brightness, float damping, float position) {

    if (channelFilters.empty()) return;

    // Map normalized tune to Hz
    float tuneHz = tuneToHz(tune);
    computeModeParams(tuneHz, structure, brightness, damping, position);

    int numChannels = (int)outputBlock.getNumChannels();
    int numSamples = (int)outputBlock.getNumSamples();

    // Update filter coefficients
    for (int ch = 0; ch < numChannels; ++ch) {
        if ((size_t)ch >= channelFilters.size()) continue;
        auto& bank = channelFilters[(size_t)ch];
        for (int m = 0; m < NUM_MODES; ++m) {
            // Configure IIR filter as Bandpass. This handles gain normalization automatically.
            *bank[m].coefficients = *juce::dsp::IIR::Coefficients<float>::makeBandPass(sampleRate, modeFreqs[m], modeQs[m]);
        }
    }

    // Process Loop
    for (int i = 0; i < numSamples; ++i) {
        for (int ch = 0; ch < numChannels; ++ch) {
            if ((size_t)ch >= channelFilters.size()) continue;

            float in = excitationBlock.getSample(ch, i);
            float acc = 0.0f;
            auto& bank = channelFilters[(size_t)ch];

            // Sum the output of all modes
            for (int m = 0; m < NUM_MODES; ++m) {
                // Process the input through the filter. No manual Q-normalization needed.
                // Use single-argument processSample because filters are prepared as MONO.
                // Note: juce::dsp::IIR::Filter supports the single-argument overload.
                float filtered = bank[m].processSample(in);
                acc += filtered * modeGains[m];
            }

            // Global scaling factor to keep levels manageable.
            const float globalGain = 0.2f;
            outputBlock.setSample(ch, i, acc * globalGain);
        }
    }
}

// ===================== SympatheticStringResonator Implementation =====================

void SympatheticStringResonator::prepare(const juce::dsp::ProcessSpec& spec) {
    sampleRate = spec.sampleRate;
    // Max delay time for 20Hz
    maxDelaySamples = (int)(sampleRate / 20.0) + 100;

    channelDelays.resize(spec.numChannels);
    channelFilters.resize(spec.numChannels);
    feedbackGains.resize(spec.numChannels);

    // Prepare as MONO
    juce::dsp::ProcessSpec monoSpec = spec;
    monoSpec.numChannels = 1;

    for (size_t ch = 0; ch < spec.numChannels; ++ch) {
        for (int s = 0; s < NUM_STRINGS; ++s) {
            channelDelays[ch][s].setMaximumDelayInSamples(maxDelaySamples);
            // DelayLine preparation uses the full spec for internal buffer allocation, even if accessed per channel.
            channelDelays[ch][s].prepare(spec);
            // Filters must be prepared as MONO.
            channelFilters[ch][s].prepare(monoSpec);
            feedbackGains[ch][s] = 0.0f;
        }
    }
    reset();
}

void SympatheticStringResonator::reset() {
    for (auto& bank : channelDelays)
        for (auto& d : bank) d.reset();
    for (auto& bank : channelFilters)
        for (auto& f : bank) f.reset();
    for (auto& bank : feedbackGains)
        std::fill(bank.begin(), bank.end(), 0.0f);
}

void SympatheticStringResonator::updateTunings(float structure) {
    // Structure maps to interval presets (Blueprint Section 4.2)
    if (structure < 0.2f) { // Unison/Octaves
        currentRatios = { 1.0f, 2.0f, 0.5f, 4.0f, 1.01f, 0.99f };
    }
    else if (structure < 0.4f) { // Fifths
        currentRatios = { 1.0f, 1.5f, 2.0f, 3.0f, 0.5f, 0.75f };
    }
    else if (structure < 0.6f) { // Major Triad
        currentRatios = { 1.0f, 1.25f, 1.5f, 2.0f, 2.5f, 3.0f };
    }
    else if (structure < 0.8f) { // Minor Triad
        currentRatios = { 1.0f, 1.2f, 1.5f, 2.0f, 2.4f, 3.0f };
    }
    else { // Suspended 4th
        currentRatios = { 1.0f, 1.333f, 1.5f, 2.0f, 2.666f, 3.0f };
    }
}

void SympatheticStringResonator::process(const juce::dsp::AudioBlock<float>& excitationBlock, juce::dsp::AudioBlock<float>& outputBlock,
    float tune, float structure, float brightness, float damping, float position) {

    float tuneHz = tuneToHz(tune);
    updateTunings(structure);

    // Damping maps to feedback gain (0.0 = short, 1.0 = long)
    float feedbackGain = std::pow(damping, 0.3f) * 0.995f;

    // Brightness maps to LPF cutoff
    float brightnessCutoff = juce::jmap(brightness, 500.0f, (float)sampleRate * 0.45f);

    int numChannels = (int)outputBlock.getNumChannels();
    int numSamples = (int)outputBlock.getNumSamples();

    // Update parameters
    for (int ch = 0; ch < numChannels; ++ch) {
        if ((size_t)ch >= channelDelays.size()) continue;
        for (int s = 0; s < NUM_STRINGS; ++s) {
            float freq = tuneHz * currentRatios[s];
            float delayTimeSamples = (float)sampleRate / juce::jlimit(20.0f, (float)sampleRate * 0.45f, freq);
            channelDelays[ch][s].setDelay(delayTimeSamples);
            channelFilters[ch][s].setCutoffFrequency(brightnessCutoff);
        }
    }

    // Process Loop (Comb Filter implementation)
    for (int i = 0; i < numSamples; ++i) {
        for (int ch = 0; ch < numChannels; ++ch) {
            if ((size_t)ch >= channelDelays.size()) continue;

            float in = excitationBlock.getSample(ch, i);
            float acc = 0.0f;

            for (int s = 0; s < NUM_STRINGS; ++s) {
                // 1. Read from delay line
                // Use the channel index for DelayLine access if prepared with multi-channel spec
                float delayedSample = channelDelays[ch][s].popSample(ch);

                // 2. Apply damping (LPF)
                // FIX C2660 (JUCE 8): FirstOrderTPTFilter requires the channel index.
                // Since the filters are prepared as MONO, we pass 0.
                float dampedSample = channelFilters[ch][s].processSample(0, delayedSample);

                // 3. Calculate new input (Excitation + Feedback from previous iteration)
                float feedbackIn = feedbackGains[ch][s];
                float newSample = in + feedbackIn;

                // 4. Write to delay line
                channelDelays[ch][s].pushSample(ch, newSample);

                // 5. Update feedback storage for next iteration
                feedbackGains[ch][s] = dampedSample * feedbackGain;

                // Output is the damped sample (Position ignored for simplicity here)
                acc += dampedSample;
            }

            // Global scaling
            outputBlock.setSample(ch, i, acc * 0.3f);
        }
    }
}

// ===================== StringResonator (Karplus-Strong) Implementation =====================
void StringResonator::prepare(const juce::dsp::ProcessSpec& spec) {
    sampleRate = spec.sampleRate;
    maxDelaySamples = (int)(sampleRate / 20.0) + 100;

    channelDelays.resize(spec.numChannels);
    channelDampingFilters.resize(spec.numChannels);
    channelDispersionFilters.resize(spec.numChannels);
    feedback.resize(spec.numChannels, 0.0f);

    // Prepare as MONO
    juce::dsp::ProcessSpec monoSpec = spec;
    monoSpec.numChannels = 1;

    for (size_t ch = 0; ch < spec.numChannels; ++ch) {
        channelDelays[ch].setMaximumDelayInSamples(maxDelaySamples);
        channelDelays[ch].prepare(spec);
        // Filters must be prepared as MONO.
        channelDampingFilters[ch].prepare(monoSpec);
        channelDispersionFilters[ch].prepare(monoSpec);
    }
    reset();
}

void StringResonator::reset() {
    for (auto& d : channelDelays) d.reset();
    for (auto& f : channelDampingFilters) f.reset();
    for (auto& f : channelDispersionFilters) f.reset();
    std::fill(feedback.begin(), feedback.end(), 0.0f);
}

void StringResonator::process(const juce::dsp::AudioBlock<float>& excitationBlock, juce::dsp::AudioBlock<float>& outputBlock,
    float tune, float structure, float brightness, float damping, float position) {

    float tuneHz = tuneToHz(tune);
    float delayTimeSamples = (float)sampleRate / juce::jlimit(20.0f, (float)sampleRate * 0.45f, tuneHz);

    // Damping (Feedback Gain)
    float feedbackGain = std::pow(damping, 0.5f) * 0.998f;

    // Brightness (Damping Filter Cutoff)
    float brightnessCutoff = juce::jmap(brightness, 1000.0f, (float)sampleRate * 0.45f);

    // Structure (Inharmonicity/Dispersion) - maps to all-pass filter Q/coefficient
    float dispersionQ = structure * 0.5f + 0.01f;

    int numChannels = (int)outputBlock.getNumChannels();
    int numSamples = (int)outputBlock.getNumSamples();

    // Update parameters
    for (int ch = 0; ch < numChannels; ++ch) {
        if ((size_t)ch >= channelDelays.size()) continue;
        channelDelays[ch].setDelay(delayTimeSamples);
        channelDampingFilters[ch].setCutoffFrequency(brightnessCutoff);
        // Configure IIR as All-pass for dispersion
        *channelDispersionFilters[ch].coefficients = *juce::dsp::IIR::Coefficients<float>::makeAllPass(sampleRate, tuneHz, dispersionQ);
    }

    // Process Loop (Extended Karplus-Strong)
    for (int i = 0; i < numSamples; ++i) {
        for (int ch = 0; ch < numChannels; ++ch) {
            if ((size_t)ch >= channelDelays.size()) continue;

            float in = excitationBlock.getSample(ch, i);

            // 1. Read from delay line
            float delayedSample = channelDelays[ch].popSample(ch);

            // 2. Apply filters in the feedback loop (MONO processing)
            // Damping (Brightness)
            // FIX C2660 (JUCE 8): FirstOrderTPTFilter requires the channel index.
            // Since the filters are prepared as MONO, we pass 0.
            float dampedSample = channelDampingFilters[ch].processSample(0, delayedSample);

            // Dispersion (Inharmonicity)
            // Note: channelDispersionFilters uses IIR::Filter, which supports the single-argument call.
            float dispersedSample = channelDispersionFilters[ch].processSample(dampedSample);

            // 3. Calculate new input (Excitation + Feedback)
            float feedbackIn = feedback[ch];
            float newSample = in + feedbackIn;

            // 4. Write to delay line
            channelDelays[ch].pushSample(ch, newSample);

            // 5. Update feedback storage
            feedback[ch] = dispersedSample * feedbackGain;

            // Output (Position ignored for simplicity here)
            outputBlock.setSample(ch, i, dispersedSample * 0.8f);
        }
    }
}


// ===================== PhysicalResonatorProcessor Implementation =====================
PhysicalResonatorProcessor::PhysicalResonatorProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)), mainApvts(apvts) {

    // Define Parameter IDs
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_PHYSRES_";

    modelParamId = slotPrefix + "MODEL";
    tuneParamId = slotPrefix + "TUNE";
    structureParamId = slotPrefix + "STRUCTURE";
    brightnessParamId = slotPrefix + "BRIGHTNESS";
    dampingParamId = slotPrefix + "DAMPING";
    positionParamId = slotPrefix + "POSITION";
    exciteTypeParamId = slotPrefix + "EXCITE_TYPE";
    sensitivityParamId = slotPrefix + "SENSITIVITY";
    mixParamId = slotPrefix + "MIX";
    noiseTypeParamId = slotPrefix + "NOISE_TYPE";
    // ADSR IDs (optional)
    attackParamId = slotPrefix + "ATTACK";
    decayParamId = slotPrefix + "DECAY";
    sustainParamId = slotPrefix + "SUSTAIN";
    releaseParamId = slotPrefix + "RELEASE";
}

void PhysicalResonatorProcessor::prepareToPlay(double sampleRate, int samplesPerBlock) {
    juce::uint32 numChannels = (juce::uint32)std::max(getTotalNumInputChannels(), getTotalNumOutputChannels());
    if (numChannels == 0) numChannels = 2; // Default to stereo if channel info isn't ready

    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, numChannels };

    // Prepare all components
    excitationGenerator.prepare(spec);
    modalResonator.prepare(spec);
    sympatheticResonator.prepare(spec);
    stringResonator.prepare(spec);
    safetyLimiter.prepare(spec);

    // Configure limiter
    safetyLimiter.setThreshold(0.95f);
    safetyLimiter.setRelease(50.0f);

    // Setup buffers
    excitationBuffer.setSize((int)spec.numChannels, (int)spec.maximumBlockSize);
    wetOutputBuffer.setSize((int)spec.numChannels, (int)spec.maximumBlockSize);

    // Initialize smoothed values
    double smoothingTime = 0.02; // 20ms
    smoothedTune.reset(sampleRate, smoothingTime);
    smoothedStructure.reset(sampleRate, smoothingTime);
    smoothedBrightness.reset(sampleRate, smoothingTime);
    smoothedDamping.reset(sampleRate, smoothingTime);
    smoothedPosition.reset(sampleRate, smoothingTime);
    smoothedMix.reset(sampleRate, smoothingTime);

    updateResonatorCore((int)mainApvts.getRawParameterValue(modelParamId)->load());
    reset();
}

void PhysicalResonatorProcessor::releaseResources() {
    reset();
}

void PhysicalResonatorProcessor::reset() {
    excitationGenerator.reset();
    modalResonator.reset();
    sympatheticResonator.reset();
    stringResonator.reset();
    safetyLimiter.reset();
    instabilityFlag = false;
}

void PhysicalResonatorProcessor::updateResonatorCore(int newModelIndex) {
    if (newModelIndex == currentModelIndex && activeResonator != nullptr) return;

    // Reset the previous one to silence tails when switching
    if (activeResonator) {
        activeResonator->reset();
    }

    currentModelIndex = newModelIndex;

    switch (newModelIndex) {
    case 0: activeResonator = &modalResonator; break;
    case 1: activeResonator = &sympatheticResonator; break;
    case 2: activeResonator = &stringResonator; break;
    default: activeResonator = &modalResonator; break;
    }
}

// Returns true if instability was detected and handled
bool PhysicalResonatorProcessor::checkAndHandleInstability(float sampleValue) {
    if (std::isnan(sampleValue) || std::isinf(sampleValue) || std::abs(sampleValue) > 100.0f) {
        if (!instabilityFlag) {
            // DBG("PhysicalResonator: Numerical instability detected. Resetting.");
            instabilityFlag = true;
            reset(); // Reset all DSP components
        }
        return true;
    }
    return false;
}


void PhysicalResonatorProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&) {
    juce::ScopedNoDenormals noDenormals;
    auto totalIn = getTotalNumInputChannels();
    auto totalOut = getTotalNumOutputChannels();

    for (auto i = totalIn; i < totalOut; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    int numSamples = buffer.getNumSamples();
    // Use the maximum channel count for processing logic
    int numChannels = std::max(totalIn, totalOut);

    if (numChannels == 0) return;

    // If we previously detected instability, clear the flag now that we are processing a new block.
    instabilityFlag = false;

    // 1. Update Model Selection
    int modelIndex = (int)mainApvts.getRawParameterValue(modelParamId)->load();
    updateResonatorCore(modelIndex);

    if (!activeResonator) return;

    // 2. Update Smoothed Parameter Targets
    // Helper lambda to safely retrieve parameters
    auto getParam = [&](const juce::String& id) {
        if (auto* p = mainApvts.getRawParameterValue(id)) return p->load();
        return 0.0f;
        };

    smoothedTune.setTargetValue(getParam(tuneParamId));
    smoothedStructure.setTargetValue(getParam(structureParamId));
    smoothedBrightness.setTargetValue(getParam(brightnessParamId));
    smoothedDamping.setTargetValue(getParam(dampingParamId));
    smoothedPosition.setTargetValue(getParam(positionParamId));
    smoothedMix.setTargetValue(getParam(mixParamId));

    // Ensure buffers are adequate size
    if (excitationBuffer.getNumSamples() < numSamples || excitationBuffer.getNumChannels() < numChannels) {
        excitationBuffer.setSize(numChannels, numSamples, false, true, true);
        wetOutputBuffer.setSize(numChannels, numSamples, false, true, true);
    }

    // Setup AudioBlocks
    juce::dsp::AudioBlock<float> dryBlock(buffer);
    juce::dsp::AudioBlock<float> excitationBlock(excitationBuffer);
    juce::dsp::AudioBlock<float> wetBlock(wetOutputBuffer);

    // Create sub-blocks based on actual input channels for the dry source
    auto activeDry = dryBlock.getSubBlock(0, (size_t)numSamples);
    if (totalIn > 0) {
        activeDry = activeDry.getSubsetChannelBlock(0, (size_t)totalIn);
    }

    auto activeExcite = excitationBlock.getSubBlock(0, (size_t)numSamples).getSubsetChannelBlock(0, (size_t)numChannels);
    auto activeWet = wetBlock.getSubBlock(0, (size_t)numSamples).getSubsetChannelBlock(0, (size_t)numChannels);

    activeExcite.clear();
    activeWet.clear();

    // 3. Generate Excitation Signal
    ExcitationGenerator::ExcitationParams ep;
    ep.exciteType = getParam(exciteTypeParamId);
    ep.sensitivity = getParam(sensitivityParamId);
    ep.noiseType = (int)getParam(noiseTypeParamId);

    // Only process excitation if there is input audio
    if (totalIn > 0) {
        excitationGenerator.process(activeDry, activeExcite, ep);
    }

    // 4. Process through Resonator Core (Sample-by-sample for smooth parameter updates)
    for (int i = 0; i < numSamples; ++i) {
        // Get the next smoothed normalized value
        float tune = smoothedTune.getNextValue();
        float structure = smoothedStructure.getNextValue();
        float brightness = smoothedBrightness.getNextValue();
        float damping = smoothedDamping.getNextValue();
        float position = smoothedPosition.getNextValue();

        // Create single-sample blocks
        auto exciteSample = activeExcite.getSubBlock((size_t)i, 1);
        auto wetSample = activeWet.getSubBlock((size_t)i, 1);

        // Process the sample
        activeResonator->process(exciteSample, wetSample, tune, structure, brightness, damping, position);
    }

    // 5. Safety Check and Limiting
    // Check for NaN/Inf/Explosions
    for (int ch = 0; ch < numChannels; ++ch) {
        for (int i = 0; i < numSamples; ++i) {
            if (checkAndHandleInstability(activeWet.getSample(ch, i))) {
                // If instability occurred, the wet buffer might contain invalid data. Clear it.
                activeWet.clear();
                break; // Stop checking this block
            }
        }
        if (instabilityFlag) break;
    }

    // Apply safety limiter to the wet signal
    if (!instabilityFlag) {
        safetyLimiter.process(juce::dsp::ProcessContextReplacing<float>(activeWet));
    }

    // 6. Wet/Dry Mixing (Equal Power)
    for (int i = 0; i < numSamples; ++i) {
        float mix = smoothedMix.getNextValue();
        float wetGain = std::sin(mix * juce::MathConstants<float>::halfPi);
        float dryGain = std::cos(mix * juce::MathConstants<float>::halfPi);

        for (int ch = 0; ch < totalOut; ++ch) {
            // Ensure safe access if input/output counts differ
            float dry = (ch < totalIn) ? buffer.getSample(ch, i) : 0.0f;
            float wet = (ch < numChannels && ch < (int)activeWet.getNumChannels()) ? activeWet.getSample(ch, i) : 0.0f;

            float out = dry * dryGain + wet * wetGain;

            buffer.setSample(ch, i, out);
        }
    }
}

================================================================================
// File: FX_Modules/PhysicalResonatorProcessor.h
================================================================================

//================================================================================
// File: FX_Modules/PhysicalResonatorProcessor.h
//================================================================================
#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>
#include <array>
#include <vector>
#include <cmath>
#include <algorithm>

// Assuming these includes exist in your project structure
#include "../DSPUtils.h"
#include "../DSP_Helpers/TransientDetector.h"
#include "../DSP_Helpers/SpectralAnalyzer.h"

// ===================== ExcitationGenerator =====================
class ExcitationGenerator {
public:
    ExcitationGenerator();
    void prepare(const juce::dsp::ProcessSpec&);
    void reset();
    struct ExcitationParams {
        float exciteType = 0.5f;
        float sensitivity = 0.5f;
        int noiseType = 0;
        // ADSR parameters are kept if defined in APVTS, but unused in the current implementation.
        float attack = 0.001f; float decay = 0.05f; float sustain = 0.0f; float release = 0.01f;
    };
    void process(const juce::dsp::AudioBlock<float>& inputBlock, juce::dsp::AudioBlock<float>& outputExcitationBlock, const ExcitationParams& params);
private:
    double sampleRate = 44100.0;
    TransientDetector transientDetector;
    // SpectralAnalyzer is currently unused but kept for potential future features (e.g., spectral-dependent excitation)
    SpectralAnalyzer spectralAnalyzer;
    DSPUtils::NoiseGenerator noiseGen;
    // Using a single filter instance prepared for multi-channel processing
    juce::dsp::StateVariableTPTFilter<float> colorFilter;
    juce::ADSR burstEnvelope;
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedExciteType, smoothedSensitivity;
};

// ===================== ResonatorCore (Abstract Base Class) =====================
class ResonatorCore {
public:
    virtual ~ResonatorCore() = default;
    virtual void prepare(const juce::dsp::ProcessSpec&) = 0;
    virtual void reset() = 0;
    // Parameters are passed normalized (0.0 - 1.0)
    virtual void process(const juce::dsp::AudioBlock<float>& excitationBlock, juce::dsp::AudioBlock<float>& outputBlock,
        float tune, float structure, float brightness, float damping, float position) = 0;
protected:
    double sampleRate = 44100.0;
    // Helper to convert normalized Tune (0-1) to Hz
    float tuneToHz(float tuneNorm) {
        // Logarithmic mapping from 50 Hz to 4000 Hz
        return 50.0f * std::pow(2.0f, tuneNorm * 6.3219f); // 6.3219 octaves
    }
};

// ===================== ModalResonator (Model 0) =====================
class ModalResonator : public ResonatorCore {
public:
    static constexpr int NUM_MODES = 24; // Increased modes for richness
    struct MaterialData {
        std::array<float, NUM_MODES> ratios;
        std::array<float, NUM_MODES> gains;
        std::array<float, NUM_MODES> qs;
    };
    void prepare(const juce::dsp::ProcessSpec&) override;
    void reset() override;
    void process(const juce::dsp::AudioBlock<float>& excitationBlock, juce::dsp::AudioBlock<float>& outputBlock,
        float tune, float structure, float brightness, float damping, float position) override;
private:
    void initializeMaterialTables();
    void computeModeParams(float tuneHz, float structure, float brightness, float damping, float position);

    // Using IIR::Filter (Biquad) for robust, normalized gain behavior.
    using Filter = juce::dsp::IIR::Filter<float>;
    // Structure: [Channel][Mode]
    std::vector<std::array<Filter, NUM_MODES>> channelFilters;

    std::array<float, NUM_MODES> modeFreqs{};
    std::array<float, NUM_MODES> modeGains{};
    std::array<float, NUM_MODES> modeQs{};

    bool tablesInitialized = false;
    MaterialData woodData{}, metalData{}, glassData{};
};

// ===================== SympatheticStringResonator (Model 1) =====================
class SympatheticStringResonator : public ResonatorCore {
public:
    static constexpr int NUM_STRINGS = 6;
    void prepare(const juce::dsp::ProcessSpec& spec) override;
    void reset() override;
    void process(const juce::dsp::AudioBlock<float>& excitationBlock, juce::dsp::AudioBlock<float>& outputBlock,
        float tune, float structure, float brightness, float damping, float position) override;

private:
    void updateTunings(float structure);

    using Delay = juce::dsp::DelayLine<float, juce::dsp::DelayLineInterpolationTypes::Linear>;
    // Structure: [Channel][String]
    std::vector<std::array<Delay, NUM_STRINGS>> channelDelays;

    // Damping filter in the feedback loop
    using LPFilter = juce::dsp::FirstOrderTPTFilter<float>;
    std::vector<std::array<LPFilter, NUM_STRINGS>> channelFilters;

    std::array<float, NUM_STRINGS> currentRatios;
    int maxDelaySamples = 0;
    // Storing feedback explicitly for the comb filter implementation
    std::vector<std::array<float, NUM_STRINGS>> feedbackGains;
};

// ===================== StringResonator (Karplus-Strong) (Model 2) =====================
class StringResonator : public ResonatorCore {
public:
    void prepare(const juce::dsp::ProcessSpec& spec) override;
    void reset() override;
    void process(const juce::dsp::AudioBlock<float>& excitationBlock, juce::dsp::AudioBlock<float>& outputBlock,
        float tune, float structure, float brightness, float damping, float position) override;

private:
    // Main delay line (Higher order interpolation for better tuning stability)
    using Delay = juce::dsp::DelayLine<float, juce::dsp::DelayLineInterpolationTypes::Lagrange3rd>;
    std::vector<Delay> channelDelays;

    // Damping filter (Brightness)
    using DampingFilter = juce::dsp::FirstOrderTPTFilter<float>;
    std::vector<DampingFilter> channelDampingFilters;

    // Dispersion filter (Inharmonicity/Structure) - using All-pass
    using DispersionFilter = juce::dsp::IIR::Filter<float>;
    std::vector<DispersionFilter> channelDispersionFilters;

    int maxDelaySamples = 0;
    std::vector<float> feedback; // Per channel feedback storage
};

// ===================== PhysicalResonatorProcessor (Main Processor) =====================
class PhysicalResonatorProcessor : public juce::AudioProcessor {
public:
    PhysicalResonatorProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex);
    ~PhysicalResonatorProcessor() override = default;

    // Standard Processor Methods
    const juce::String getName() const override { return "Physical Resonator"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages) override;

    // Boilerplate required methods (GUI handled externally)
    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    double getTailLengthSeconds() const override { return 5.0; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    void updateResonatorCore(int newModelIndex);
    bool checkAndHandleInstability(float sampleValue);

    // DSP Components
    ExcitationGenerator excitationGenerator;
    ModalResonator modalResonator;
    SympatheticStringResonator sympatheticResonator;
    StringResonator stringResonator;
    ResonatorCore* activeResonator = nullptr;

    // Buffers
    juce::AudioBuffer<float> excitationBuffer, wetOutputBuffer;

    // Parameter Handling
    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String modelParamId, tuneParamId, structureParamId, brightnessParamId, dampingParamId, positionParamId;
    juce::String exciteTypeParamId, sensitivityParamId, mixParamId, noiseTypeParamId;
    juce::String attackParamId, decayParamId, sustainParamId, releaseParamId;

    // Smoothed Parameters (operating in normalized 0-1 range)
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedTune, smoothedStructure, smoothedBrightness, smoothedDamping, smoothedPosition, smoothedMix;

    int currentModelIndex = -1;
    bool instabilityFlag = false;

    // Safety Limiter
    juce::dsp::Limiter<float> safetyLimiter;
};

================================================================================
// File: FX_Modules/ReverbProcessor.cpp
================================================================================

#include "ReverbProcessor.h"

ReverbProcessor::ReverbProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_";
    roomSizeParamId = slotPrefix + "REVERB_ROOM_SIZE";
    dampingParamId = slotPrefix + "REVERB_DAMPING";
    mixParamId = slotPrefix + "REVERB_MIX";
    widthParamId = slotPrefix + "REVERB_WIDTH";
}

void ReverbProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };
    reverb.prepare(spec);
    reset();
}

void ReverbProcessor::releaseResources()
{
    reset();
}

void ReverbProcessor::reset()
{
    reverb.reset();
}

void ReverbProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&)
{
    juce::ScopedNoDenormals noDenormals;

    // === FIX P1: Add standard boilerplate ===
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    // Clear any output channels that didn't contain input data
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());
    // ========================================

    juce::dsp::Reverb::Parameters reverbParams;
    reverbParams.roomSize = mainApvts.getRawParameterValue(roomSizeParamId)->load();
    reverbParams.damping = mainApvts.getRawParameterValue(dampingParamId)->load();
    reverbParams.wetLevel = mainApvts.getRawParameterValue(mixParamId)->load();
    reverbParams.dryLevel = 1.0f - reverbParams.wetLevel;
    reverbParams.width = mainApvts.getRawParameterValue(widthParamId)->load();
    reverb.setParameters(reverbParams);

    juce::dsp::AudioBlock<float> block(buffer);
    juce::dsp::ProcessContextReplacing<float> context(block);
    reverb.process(context);
}

================================================================================
// File: FX_Modules/ReverbProcessor.h
================================================================================

#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include <juce_dsp/juce_dsp.h>

class ReverbProcessor : public juce::AudioProcessor
{
public:
    ReverbProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~ReverbProcessor() override = default;

    const juce::String getName() const override { return "Reverb"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    double getTailLengthSeconds() const override { return 8.0; }

    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    juce::dsp::Reverb reverb;

    juce::AudioProcessorValueTreeState& mainApvts;
    juce::String roomSizeParamId, dampingParamId, mixParamId, widthParamId;
};

================================================================================
// File: FX_Modules/SpectralAnimatorEngine.cpp
================================================================================

﻿//================================================================================
// File: FX_Modules/SpectralAnimatorEngine.cpp
//================================================================================
#include "SpectralAnimatorEngine.h"

SpectralAnimatorEngine::SpectralAnimatorEngine()
    : forwardFFT(FFT_ORDER),
    // Initialize Hann window (suitable for 75% overlap)
    window(FFT_SIZE, juce::dsp::WindowingFunction<float>::WindowingMethod::hann)
{
    harmonicMask.resize(NUM_BINS, 0.0f);
    formantMask.resize(NUM_BINS, 0.0f);
}

// Helper function for Vowel Space Interpolation (Formant Mode)
SpectralAnimatorEngine::FormantProfile SpectralAnimatorEngine::getVowel(float x, float y)
{
    // X-axis: F2 (Front/Back) -> High X = Front ('i'), Low X = Back ('u')
    // Y-axis: F1 (Open/Close) -> High Y = Open ('a'), Low Y = Close ('i'/'u')

    // Define corner vowels (F1, F2) - typical adult male approximations
    const FormantProfile i = { 270, 2290 }; // Close Front ("see")
    const FormantProfile u = { 300, 870 };  // Close Back ("boot")
    const FormantProfile a = { 730, 1090 }; // Open Mid/Back ("father")
    const FormantProfile ae = { 660, 1720 }; // Open Front ("had")

    auto interpolate = [](float v1, float v2, float t) { return v1 * (1.0f - t) + v2 * t; };

    // Bilinear interpolation
    float f1_close = interpolate(u.f1, i.f1, x);
    float f1_open = interpolate(a.f1, ae.f1, x);
    float f1 = interpolate(f1_close, f1_open, y);

    float f2_close = interpolate(u.f2, i.f2, x);
    float f2_open = interpolate(a.f2, ae.f2, x);
    float f2 = interpolate(f2_close, f2_open, y);

    return { f1, f2 };
}


void SpectralAnimatorEngine::prepare(const juce::dsp::ProcessSpec& spec)
{
    sampleRate = spec.sampleRate;
    numChannels = (int)spec.numChannels;

    // 1. Initialize Buffers
    inputFIFO.setSize(numChannels, FFT_SIZE);
    // Output Buffer size: 2 * FFT_SIZE (provides ample space for OLA accumulation)
    int outputBufferSize = FFT_SIZE * 2;
    outputBuffer.setSize(numChannels, outputBufferSize);

    // Initialize temporary FFT buffers
    channelTimeDomain.resize(numChannels);
    channelFreqDomain.resize(numChannels);
    for (int ch = 0; ch < numChannels; ++ch)
    {
        channelTimeDomain[ch].resize(FFT_SIZE, 0.0f);
        // JUCE requires 2*N space for real-only FFT operations
        channelFreqDomain[ch].resize(FFT_SIZE * 2, 0.0f);
    }

    // 2. Initialize Transient Detectors (Per Channel)
    transientDetectors.resize(numChannels);
    juce::dsp::ProcessSpec monoSpec = spec;
    monoSpec.numChannels = 1;

    // 30ms decay for the mix envelope (as per design document)
    float decayTimeMs = 30.0f;

    for (auto& detector : transientDetectors)
    {
        detector.highPassFilter.prepare(monoSpec);
        // Set high-pass cutoff (e.g., 2kHz)
        detector.highPassFilter.setCutoffFrequency(2000.0f);

        detector.envelopeFollower.prepare(monoSpec);
        // Fast attack/release for the detection signal itself
        detector.envelopeFollower.setAttackTime(1.0f);
        detector.envelopeFollower.setReleaseTime(10.0f);

        // Calculate time-based exponential decay factor for the mix control
        if (sampleRate > 0)
            detector.decayFactor = std::exp(-1.0f / (float)(sampleRate * decayTimeMs / 1000.0f));
    }

    // FIX: Initialize smoothers (e.g., 5ms smoothing time for fast response)
    double smoothingTime = 0.005;
    smoothedMorph.reset(sampleRate, smoothingTime);
    smoothedTransientPreservation.reset(sampleRate, smoothingTime);

    reset();
}

void SpectralAnimatorEngine::reset()
{
    inputFIFO.clear();
    outputBuffer.clear();
    fifoIndex = 0;
    outputBufferWritePos = 0;
    outputBufferReadPos = 0;

    for (auto& detector : transientDetectors)
    {
        detector.highPassFilter.reset();
        detector.envelopeFollower.reset();
        detector.transientMix = 0.0f;
    }

    // FIX: Reset smoothers to default values (1.0)
    smoothedMorph.setCurrentAndTargetValue(1.0f);
    smoothedTransientPreservation.setCurrentAndTargetValue(1.0f);

    masksNeedUpdate = true;
}

// Parameter setters (trigger mask updates if necessary)
void SpectralAnimatorEngine::setMode(Mode newMode) { if (currentMode != newMode) { currentMode = newMode; masksNeedUpdate = true; } }
void SpectralAnimatorEngine::setPitch(float newPitchHz) { if (pitchHz != newPitchHz) { pitchHz = newPitchHz; masksNeedUpdate = true; } }
void SpectralAnimatorEngine::setFormant(float x, float y) { formantXY = { x, y }; masksNeedUpdate = true; }
void SpectralAnimatorEngine::setMorph(float amount) { smoothedMorph.setTargetValue(amount); }
void SpectralAnimatorEngine::setTransientPreservation(float amount) { smoothedTransientPreservation.setTargetValue(amount); }


// Main process loop implementing STFT buffering and transient mixing
void SpectralAnimatorEngine::process(juce::AudioBuffer<float>& buffer)
{
    int numSamples = buffer.getNumSamples();
    int outputBufferSize = outputBuffer.getNumSamples();

    // Update masks if parameters changed
    if (masksNeedUpdate)
    {
        updateMasks();
        masksNeedUpdate = false;
    }

    // Main audio loop
    for (int i = 0; i < numSamples; ++i)
    {
        bool frameReady = false;

        // FIX (C4189): Advance smoothers once per sample frame.
        // We must advance the smoother, but we don't use the 'morph' value in this loop scope.
        smoothedMorph.getNextValue();
        float currentTransientPreservation = smoothedTransientPreservation.getNextValue();


        for (int ch = 0; ch < numChannels; ++ch)
        {
            float inputSample = buffer.getSample(ch, i);

            // --- Transient Detection Path (2.2 Logic) ---
            auto& detector = transientDetectors[ch];

            // Note: Filters/Followers prepared with monoSpec require channel index 0 when calling processSample
            float highPassed = detector.highPassFilter.processSample(0, inputSample);
            float envelope = detector.envelopeFollower.processSample(0, std::abs(highPassed));

            // Fast attack, exponential decay mix control (The "transient preservation envelope")
            if (envelope > transientThreshold)
                detector.transientMix = 1.0f; // Attack immediately
            else
                detector.transientMix *= detector.decayFactor; // Decay smoothly


            // --- STFT Path (2.2 Logic) ---

            // 1. Push input sample into FIFO
            inputFIFO.setSample(ch, fifoIndex, inputSample);

            // 3. Retrieve output sample from OLA buffer
            float outputSample = outputBuffer.getSample(ch, outputBufferReadPos);
            // Clear the sample we just read for the next accumulation
            outputBuffer.setSample(ch, outputBufferReadPos, 0.0f);

            // 4. Final Mix (Transient Integration)
            // FIX: Use the smoothed value (currentTransientPreservation)
            float mixControl = detector.transientMix * currentTransientPreservation;
            // Linear crossfade: Wet * (1-Mix) + Dry * Mix
            float finalSample = outputSample * (1.0f - mixControl) + inputSample * mixControl;

            buffer.setSample(ch, i, finalSample);
        }

        // Advance indices
        fifoIndex++;
        outputBufferReadPos = (outputBufferReadPos + 1) % outputBufferSize;

        // 2. Check if we have enough data for a frame (FFT_SIZE)
        if (fifoIndex >= FFT_SIZE)
        {
            frameReady = true;
            // Reset index relative to the overlap for the next accumulation phase
            fifoIndex -= HOP_SIZE;
        }

        // Process the frame if ready
        if (frameReady)
        {
            for (int ch = 0; ch < numChannels; ++ch)
            {
                // Copy data from FIFO to processing buffer (channelTimeDomain)
                // The data corresponding to the current frame is at the start of the FIFO before shifting.
                std::copy(inputFIFO.getReadPointer(ch), inputFIFO.getReadPointer(ch) + FFT_SIZE, channelTimeDomain[ch].begin());

                processFrame(ch);
            }

            // Shift input FIFO by hopSize for all channels (Efficient FIFO management)
            for (int ch = 0; ch < numChannels; ++ch)
            {
                // Using std::rotate on the underlying float array
                float* data = inputFIFO.getWritePointer(ch);
                // This shifts the buffer content left by HOP_SIZE
                std::rotate(data, data + HOP_SIZE, data + FFT_SIZE);
            }

            // Advance output buffer write position for the next OLA
            outputBufferWritePos = (outputBufferWritePos + HOP_SIZE) % outputBufferSize;
        }
    }
}

// STFT core: FFT -> Modification -> IFFT -> OLA
void SpectralAnimatorEngine::processFrame(int channel)
{
    auto& timeDomain = channelTimeDomain[channel];
    auto& freqDomain = channelFreqDomain[channel];
    int outputBufferSize = outputBuffer.getNumSamples();

    // 1. Windowing (Analysis window)
    window.multiplyWithWindowingTable(timeDomain.data(), FFT_SIZE);

    // 2. Forward FFT
    // Copy time domain data to frequency domain buffer for FFT operation
    std::copy(timeDomain.begin(), timeDomain.end(), freqDomain.begin());
    forwardFFT.performRealOnlyForwardTransform(freqDomain.data());

    // 3. Spectral Modification
    const std::vector<float>& mask = (currentMode == Mode::Pitch) ? harmonicMask : formantMask;

    // FIX: Get the current morph value for this frame
    float currentMorph = smoothedMorph.getCurrentValue();


    // Iterate over bins (including DC and Nyquist)
    for (int k = 0; k < NUM_BINS; ++k)
    {
        float real, imag;
        // Unpack JUCE packed format (DC at [0], Nyquist at [1])
        if (k == 0) { real = freqDomain[0]; imag = 0.0f; } // DC
        else if (k == NUM_BINS - 1) { real = freqDomain[1]; imag = 0.0f; } // Nyquist
        else { real = freqDomain[2 * k]; imag = freqDomain[2 * k + 1]; }

        // Calculate Magnitude and Phase (Phase Vocoder core)
        float magnitude = std::sqrt(real * real + imag * imag);
        float phase = std::atan2(imag, real);

        // Apply Shaping Mask
        float modifiedMag = magnitude * mask[k];

        // Apply Morph Control (Linear interpolation)
        // FIX: Use the current smoothed value (currentMorph)
        float finalMag = magnitude * (1.0f - currentMorph) + modifiedMag * currentMorph;

        // 4. Convert back to Complex (using original phase)
        real = finalMag * std::cos(phase);
        imag = finalMag * std::sin(phase);

        // Pack back into JUCE format
        if (k == 0) { freqDomain[0] = real; }
        else if (k == NUM_BINS - 1) { freqDomain[1] = real; }
        else { freqDomain[2 * k] = real; freqDomain[2 * k + 1] = imag; }
    }

    // 5. Perform inverse FFT (In-place on freqDomain)
    // Note: JUCE FFT handles normalization internally.
    forwardFFT.performRealOnlyInverseTransform(freqDomain.data());

    // 6. Window (Synthesis window) and overlap-add
    // Copy result back to time domain buffer for synthesis windowing
    std::copy(freqDomain.begin(), freqDomain.begin() + FFT_SIZE, timeDomain.begin());
    window.multiplyWithWindowingTable(timeDomain.data(), FFT_SIZE);

    // Overlap-Add into the output buffer starting at the current write position
    for (int i = 0; i < FFT_SIZE; ++i)
    {
        int index = (outputBufferWritePos + i) % outputBufferSize;
        // Add the windowed frame to the accumulation buffer
        outputBuffer.addSample(channel, index, timeDomain[i]);
    }
}

// Mask generation for Pitch and Formant modes
void SpectralAnimatorEngine::updateMasks()
{
    if (sampleRate <= 0) return;
    float binWidth = (float)sampleRate / (float)FFT_SIZE;

    if (currentMode == Mode::Pitch)
    {
        // Pitch Mode: Create a harmonic mask using Gaussian peaks.
        std::fill(harmonicMask.begin(), harmonicMask.end(), 0.0f);
        float f0 = pitchHz;
        if (f0 < binWidth) return;

        // Define the width (sigma) of the harmonic peaks in bins
        const float harmonicWidth = 1.5f;
        const float widthSquared = harmonicWidth * harmonicWidth;

        for (int h = 1; ; ++h)
        {
            float freq = f0 * (float)h;
            if (freq >= sampleRate / 2.0f) break;

            float binIndex = freq / binWidth;
            int centerBin = (int)(binIndex + 0.5f);

            if (centerBin >= NUM_BINS) break;

            // Create the Gaussian peak
            // Iterate over a practical range around the center bin (e.g., +/- 3*sigma)
            int range = (int)(harmonicWidth * 3.0f);
            int startBin = juce::jmax(0, centerBin - range);
            int endBin = juce::jmin(NUM_BINS - 1, centerBin + range);

            for (int i = startBin; i <= endBin; ++i)
            {
                float distance = (float)i - binIndex;
                // Gaussian function: exp(-0.5 * (x/sigma)^2)
                float gain = std::exp(-0.5f * (distance * distance) / widthSquared);
                // Ensure we take the maximum if harmonics overlap
                harmonicMask[i] = juce::jmax(harmonicMask[i], gain);
            }
        }
    }
    else if (currentMode == Mode::Formant)
    {
        // Formant Mode: Use the interpolated vowel space
        FormantProfile vowel = getVowel(formantXY.x, formantXY.y);

        std::fill(formantMask.begin(), formantMask.end(), 0.0f);

        // Define formants (F1, F2, F3) and their bandwidths
        const std::array<float, 3> freqs = { vowel.f1, vowel.f2, 2500.0f }; // F3 fixed approximation
        const std::array<float, 3> bandwidths = { 100.0f, 150.0f, 200.0f }; // In Hz

        for (int f = 0; f < 3; ++f)
        {
            float centerFreq = freqs[f];
            float bw = bandwidths[f];

            // Create a resonant peak shape (using a Lorentzian/Cauchy model approximation)
            // Gain = 1 / (1 + ((freq - center) / bandwidth)^2)
            for (int k = 0; k < NUM_BINS; ++k)
            {
                float freq = k * binWidth;
                float normalizedDistance = (freq - centerFreq) / bw;
                float gain = 1.0f / (1.0f + normalizedDistance * normalizedDistance);
                // Take the maximum if formants overlap
                formantMask[k] = juce::jmax(formantMask[k], gain);
            }
        }

        // Normalize the mask so the maximum gain is 1.0 (preserves overall energy)
        float maxGain = *std::max_element(formantMask.begin(), formantMask.end());
        if (maxGain > 0.0f)
        {
            for (float& val : formantMask) val /= maxGain;
        }
    }
}

================================================================================
// File: FX_Modules/SpectralAnimatorEngine.h
================================================================================

﻿//================================================================================
// File: FX_Modules/SpectralAnimatorEngine.h
//================================================================================
#pragma once
#include <juce_dsp/juce_dsp.h>
#include <vector>
#include <array>
#include <complex>
#include <cmath>
#include <algorithm>

class SpectralAnimatorEngine
{
public:
    static constexpr int FFT_ORDER = 11;
    static constexpr int FFT_SIZE = 1 << FFT_ORDER;
    static constexpr int HOP_SIZE = FFT_SIZE / 4;
    static constexpr int NUM_BINS = FFT_SIZE / 2 + 1;

    enum class Mode { Pitch, Formant };

    SpectralAnimatorEngine();
    void prepare(const juce::dsp::ProcessSpec& spec);
    void reset();
    void process(juce::AudioBuffer<float>& buffer);

    void setMode(Mode newMode);
    void setPitch(float newPitchHz);
    void setFormant(float x, float y);
    void setMorph(float amount);
    void setTransientPreservation(float amount);
private:
    void processFrame(int channel);
    void updateMasks();

    struct FormantProfile { float f1, f2; };
    FormantProfile getVowel(float x, float y);

    double sampleRate = 44100.0;
    int numChannels = 0;

    juce::dsp::FFT forwardFFT;
    juce::dsp::WindowingFunction<float> window;

    juce::AudioBuffer<float> inputFIFO;
    juce::AudioBuffer<float> outputBuffer;
    int fifoIndex = 0;
    int outputBufferWritePos = 0;
    int outputBufferReadPos = 0;

    std::vector<std::vector<float>> channelTimeDomain;
    std::vector<std::vector<float>> channelFreqDomain;

    struct TransientDetectorChannel {
        juce::dsp::FirstOrderTPTFilter<float> highPassFilter;
        juce::dsp::BallisticsFilter<float> envelopeFollower;
        float transientMix = 0.0f;
        float decayFactor = 0.99f;
    };
    std::vector<TransientDetectorChannel> transientDetectors;
    const float transientThreshold = 0.05f;

    // --- Parameters ---
    Mode currentMode = Mode::Pitch;
    float pitchHz = 440.0f;

    // ✅ FIX: Replaced juce::Point<float> with a simple internal struct
    struct XYPair { float x = 0.5f; float y = 0.5f; };
    XYPair formantXY;

    // FIX: Replaced raw floats with SmoothedValue for glitch-free modulation.
    // float morphAmount = 1.0f; // REMOVED
    // float transientPreservation = 1.0f; // REMOVED
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedMorph;
    juce::SmoothedValue<float, juce::ValueSmoothingTypes::Linear> smoothedTransientPreservation;


    // --- Spectral Masks (Shared across channels) ---
    std::vector<float> harmonicMask;
    std::vector<float> formantMask;
    bool masksNeedUpdate = true;
};


================================================================================
// File: FX_Modules/SpectralAnimatorProcessor.cpp
================================================================================

//================================================================================
// File: FX_Modules/SpectralAnimatorProcessor.cpp
//================================================================================
#include "SpectralAnimatorProcessor.h"

SpectralAnimatorProcessor::SpectralAnimatorProcessor(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : AudioProcessor(BusesProperties().withInput("Input", juce::AudioChannelSet::stereo(), true)
        .withOutput("Output", juce::AudioChannelSet::stereo(), true)),
    mainApvts(apvts)
{
    // Define Parameter IDs (Using a distinct prefix SPECANIM_)
    auto slotPrefix = "SLOT_" + juce::String(slotIndex + 1) + "_SPECANIM_";
    modeParamId = slotPrefix + "MODE";
    pitchParamId = slotPrefix + "PITCH";
    formantXParamId = slotPrefix + "FORMANT_X";
    formantYParamId = slotPrefix + "FORMANT_Y";
    morphParamId = slotPrefix + "MORPH";
    transientParamId = slotPrefix + "TRANSIENT_PRESERVE";
}

void SpectralAnimatorProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)
{
    juce::dsp::ProcessSpec spec{ sampleRate, (juce::uint32)samplesPerBlock, (juce::uint32)getTotalNumInputChannels() };
    engine.prepare(spec);

    // Report the latency introduced by the STFT process (equal to the FFT Size).
    setLatencySamples(SpectralAnimatorEngine::FFT_SIZE);
}

void SpectralAnimatorProcessor::releaseResources()
{
    engine.reset();
}

void SpectralAnimatorProcessor::reset()
{
    engine.reset();
}

void SpectralAnimatorProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer&)
{
    juce::ScopedNoDenormals noDenormals;
    // P1 Boilerplate
    auto totalNumInputChannels = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    // Update Parameters (Ensure parameters exist before accessing)
    if (!mainApvts.getRawParameterValue(modeParamId) || !mainApvts.getRawParameterValue(pitchParamId) ||
        !mainApvts.getRawParameterValue(formantXParamId) || !mainApvts.getRawParameterValue(formantYParamId) ||
        !mainApvts.getRawParameterValue(morphParamId) || !mainApvts.getRawParameterValue(transientParamId))
    {
        return;
    }

    // Load parameters and update the engine
    auto mode = static_cast<SpectralAnimatorEngine::Mode>(static_cast<int>(mainApvts.getRawParameterValue(modeParamId)->load()));
    float pitch = mainApvts.getRawParameterValue(pitchParamId)->load();
    float formantX = mainApvts.getRawParameterValue(formantXParamId)->load();
    float formantY = mainApvts.getRawParameterValue(formantYParamId)->load();
    float morph = mainApvts.getRawParameterValue(morphParamId)->load();
    float transient = mainApvts.getRawParameterValue(transientParamId)->load();

    engine.setMode(mode);
    engine.setPitch(pitch);
    engine.setFormant(formantX, formantY);
    engine.setMorph(morph);
    engine.setTransientPreservation(transient);

    // Process audio through the engine
    engine.process(buffer);
}

================================================================================
// File: FX_Modules/SpectralAnimatorProcessor.h
================================================================================

//================================================================================
// File: FX_Modules/SpectralAnimatorProcessor.h
//================================================================================
#pragma once
#include <juce_audio_processors/juce_audio_processors.h>
#include "SpectralAnimatorEngine.h"

class SpectralAnimatorProcessor : public juce::AudioProcessor
{
public:
    SpectralAnimatorProcessor(juce::AudioProcessorValueTreeState& mainApvts, int slotIndex);
    ~SpectralAnimatorProcessor() override = default;

    const juce::String getName() const override { return "Spectral Animator"; }
    void prepareToPlay(double sampleRate, int samplesPerBlock) override;
    void releaseResources() override;
    void reset() override;
    void processBlock(juce::AudioBuffer<float>&, juce::MidiBuffer&) override;

    // Standard JUCE Boilerplate
    juce::AudioProcessorEditor* createEditor() override { return nullptr; }
    bool hasEditor() const override { return false; }
    bool acceptsMidi() const override { return false; }
    bool producesMidi() const override { return false; }
    // The STFT process introduces latency and a tail.
    double getTailLengthSeconds() const override { return 0.5; }
    int getNumPrograms() override { return 1; }
    int getCurrentProgram() override { return 0; }
    void setCurrentProgram(int) override {}
    const juce::String getProgramName(int) override { return {}; }
    void changeProgramName(int, const juce::String&) override {}
    void getStateInformation(juce::MemoryBlock&) override {}
    void setStateInformation(const void*, int) override {}

private:
    // The DSP engine instance
    SpectralAnimatorEngine engine;

    juce::AudioProcessorValueTreeState& mainApvts;
    // Parameter IDs
    juce::String modeParamId, pitchParamId, formantXParamId, formantYParamId, morphParamId, transientParamId;
};

================================================================================
// File: FX_Modules/SpectralDiffuser.cpp
================================================================================

//================================================================================
// File: FX_Modules/SpectralDiffuser.cpp
//================================================================================
#include "SpectralDiffuser.h"

// JUCE 8 FIX (C2084): Remove the constructor implementation here.

void SpectralDiffuser::prepare(const juce::dsp::ProcessSpec& spec)
{
    int numChannels = (int)spec.numChannels;

    // Initialize FIFOs (size FFT_SIZE)
    inputFIFO.setSize(numChannels, FFT_SIZE);
    outputFIFO.setSize(numChannels, FFT_SIZE);

    // Initialize FFT data buffers (size 2*FFT_SIZE)
    fftData.resize(numChannels);
    for (auto& channelData : fftData)
    {
        channelData.resize(FFT_SIZE * 2);
    }

    reset();
}

void SpectralDiffuser::reset()
{
    fifoIndex = 0;
    inputFIFO.clear();
    outputFIFO.clear();
}

// FIX: Corrected the loop structure (Samples outer, Channels inner) for proper OLA implementation.
// The original implementation iterated Channel first, then Sample, breaking time alignment.
void SpectralDiffuser::process(juce::AudioBuffer<float>& buffer, float diffusionAmount)
{
    juce::ScopedNoDenormals noDenormals;

    int numSamples = buffer.getNumSamples();
    int numChannels = buffer.getNumChannels();

    // Bypass processing if diffusion is negligible
    if (diffusionAmount < 0.001f)
        return;

    // Iterate over samples first (Outer loop)
    for (int i = 0; i < numSamples; ++i)
    {
        // Iterate over channels for the current sample index 'i' (Inner loop)
        for (int channel = 0; channel < numChannels; ++channel)
        {
            float inputSample = buffer.getSample(channel, i);

            // 1. Push input sample into Input FIFO
            inputFIFO.setSample(channel, fifoIndex, inputSample);

            // 2. Retrieve output sample from Output FIFO (delayed by HOP_SIZE)
            float outputSample = outputFIFO.getSample(channel, fifoIndex);
            buffer.setSample(channel, i, outputSample);

            // Clear the sample we just read
            outputFIFO.setSample(channel, fifoIndex, 0.0f);
        }

        // 3. Advance FIFO index (Done after all channels are processed for this time step)
        fifoIndex++;

        // 4. Check if the input FIFO is full (ready for FFT)
        if (fifoIndex == FFT_SIZE)
        {
            // Process the frame for all channels
            for (int ch = 0; ch < numChannels; ++ch)
            {
                processFrame(ch, diffusionAmount);

                // Shift the input FIFO to handle the overlap
                // Move the second half (at index HOP_SIZE) to the beginning (at index 0).
                for (int j = 0; j < HOP_SIZE; ++j)
                {
                    inputFIFO.setSample(ch, j, inputFIFO.getSample(ch, j + HOP_SIZE));
                }
            }
            // Reset index to the start of the next frame accumulation
            fifoIndex = HOP_SIZE;
        }
    }
}

void SpectralDiffuser::processFrame(int channel, float diffusionAmount)
{
    auto& data = fftData[channel];

    // 1. Copy Input FIFO to FFT buffer
    std::copy(inputFIFO.getReadPointer(channel),
        inputFIFO.getReadPointer(channel) + FFT_SIZE,
        data.begin());

    // 2. Apply Analysis Window
    window.multiplyWithWindowingTable(data.data(), FFT_SIZE);

    // 3. Perform Forward FFT (in-place)
    fft.performRealOnlyForwardTransform(data.data());

    // 4. Process Spectrum (Phase Randomization)
    // FIX: Iterate from bin 1 up to (but not including) Nyquist (i < FFT_SIZE/2).
    // We MUST skip DC (i=0) and Nyquist (i=FFT_SIZE/2) as their phase must remain fixed for real signals.
    // The original code incorrectly iterated over and randomized these bins.
    for (int i = 1; i < FFT_SIZE / 2; ++i)
    {
        float real = data[2 * i];
        float imag = data[2 * i + 1];

        // Convert to polar coordinates
        float magnitude = std::sqrt(real * real + imag * imag);
        float phase = std::atan2(imag, real);

        // Add random phase shift scaled by diffusion amount
        phase += distribution(randomEngine) * diffusionAmount;

        // Convert back to rectangular coordinates
        data[2 * i] = magnitude * std::cos(phase);
        data[2 * i + 1] = magnitude * std::sin(phase);
    }
    // DC (data[0]) and Nyquist (data[1]) components remain untouched.


    // 5. Perform Inverse FFT (in-place)
    fft.performRealOnlyInverseTransform(data.data());

    // 6. Apply Synthesis Window
    window.multiplyWithWindowingTable(data.data(), FFT_SIZE);

    // 7. Overlap-Add into Output FIFO
    // We add the result starting at the beginning of the output FIFO.
    // For Hann window with 50% overlap, the gain is constant if the window normalization is correct (handled by JUCE).
    for (int i = 0; i < FFT_SIZE; ++i)
    {
        outputFIFO.addSample(channel, i, data[i]);
    }
}

================================================================================
// File: FX_Modules/SpectralDiffuser.h
================================================================================

//================================================================================
// File: FX_Modules/SpectralDiffuser.h
//================================================================================
#pragma once
#include <juce_dsp/juce_dsp.h>
#include <vector>
#include <random>
#include <algorithm>
#include <cmath>

class SpectralDiffuser
{
public:
    // OPTIMIZATION: Reduced FFT Order from 11 (2048) to 10 (1024).
    // This significantly reduces CPU load while still providing effective diffusion.
    static constexpr int FFT_ORDER = 10;
    static constexpr int FFT_SIZE = 1 << FFT_ORDER;
    static constexpr int HOP_SIZE = FFT_SIZE / 2; // 50% Overlap

    // JUCE 8 FIX (C2039/C2065): Initialize using the WindowingMethod enum and a standard window.
    SpectralDiffuser()
        : fft(FFT_ORDER),
        window(FFT_SIZE, juce::dsp::WindowingFunction<float>::WindowingMethod::hann),
        distribution(-juce::MathConstants<float>::pi, juce::MathConstants<float>::pi)
    {
        // Ensure unique seeding
        randomEngine.seed(static_cast<unsigned long>(juce::Time::currentTimeMillis()));
    }


    void prepare(const juce::dsp::ProcessSpec& spec);
    void reset();
    void process(juce::AudioBuffer<float>& buffer, float diffusionAmount);
    int getLatencyInSamples() const { return HOP_SIZE; }

private:
    void processFrame(int channel, float diffusionAmount);

    juce::dsp::FFT fft;
    juce::dsp::WindowingFunction<float> window;

    juce::AudioBuffer<float> inputFIFO;
    juce::AudioBuffer<float> outputFIFO;
    std::vector<std::vector<float>> fftData;
    int fifoIndex = 0;

    std::minstd_rand randomEngine;
    std::uniform_real_distribution<float> distribution;
};

================================================================================
// File: FX_Modules/TapeSaturation.h
================================================================================

﻿//================================================================================
// File: FX_Modules/TapeSaturation.h (CORRECTED V2)
// Description: Optimized polynomial tape saturation model.
//================================================================================
#pragma once
#include <juce_dsp/juce_dsp.h>
#include <vector>
#include <cmath>
#include <algorithm>

namespace TapeDSP
{
    /**
     * OptimizedTapeSaturator implementing cubic nonlinearity with asymmetry.
     * Optimized for high performance using SIMD.
     */
    class OptimizedTapeSaturator
    {
    private:
        // Define the filter type used for DC blocking
        using DCFilter = juce::dsp::IIR::Filter<float>;

    public:
        void prepare(const juce::dsp::ProcessSpec& spec)
        {
            numChannels = (int)spec.numChannels;

            // Initialize the std::vector of filters.
            dcBlockers.resize(numChannels);

            if (spec.sampleRate > 0)
            {
                // High-pass filter at 5Hz to remove offsets. Calculate coefficients once.
                auto coefficients = juce::dsp::IIR::Coefficients<float>::makeHighPass(spec.sampleRate, 5.0f);

                // Configure each filter instance.
                // We must use a MONO spec for individual IIR filters when managing them manually per channel.
                juce::dsp::ProcessSpec monoSpec = spec;
                monoSpec.numChannels = 1;

                for (auto& filter : dcBlockers)
                {
                    filter.prepare(monoSpec);
                    // Assign the coefficients.
                    *filter.coefficients = *coefficients;
                }
            }
            reset();
        }

        void reset()
        {
            // Reset all filters in the vector.
            for (auto& filter : dcBlockers)
            {
                filter.reset();
            }
            alpha = 0.0f;
            beta = 0.0f;
        }

        // Set the drive (0.0 to 1.0). Internally maps to the alpha coefficient.
        void setDrive(float drive)
        {
            // Alpha controls the intensity of the cubic term (x^3).
            // Constraining alpha to [0, 1/3].
            alpha = drive * 0.333f;
        }

        // Set asymmetry (0.0 to 1.0). Controls the quadratic term (x^2).
        void setAsymmetry(float asymmetry)
        {
            // Beta controls the amount of asymmetry (even harmonics).
            // Constraining beta for stability.
            beta = asymmetry * 0.2f;
        }

        // FIX: Complete the truncated file by adding the missing processSample and members.

        // Process a single sample.
        // Note: Requires the channel index 'ch' for accessing the correct DC blocker instance.
        float processSample(int ch, float input)
        {
            if (ch >= numChannels || ch < 0) return input;

            // 1. Apply DC blocking before saturation.
            // IIR::Filter::processSample takes one argument when prepared with mono spec.
            float x = dcBlockers[ch].processSample(input);

            // 2. Optimized polynomial saturation (Horner's method)
            // y = x * (1 + x * (beta - alpha*x))
            float y = x * (1.0f + x * (beta - alpha * x));

            // 3. Safety Clipping
            return juce::jlimit(-1.5f, 1.5f, y);
        }

    private:
        float alpha = 0.0f; // Controls cubic saturation (symmetric)
        float beta = 0.0f;  // Controls quadratic saturation (asymmetric)
        int numChannels = 0;

        // Vector of DC blocker filters (one per channel)
        std::vector<DCFilter> dcBlockers;
    };

} // namespace TapeDSP

================================================================================
// File: UI/CustomLookAndFeel.cpp
================================================================================

// File: UI/CustomLookAndFeel.cpp
#include "CustomLookAndFeel.h"

CustomLookAndFeel::CustomLookAndFeel()
{
    setColour(juce::ResizableWindow::backgroundColourId, juce::Colour(0xff2d2d2d));
    setColour(juce::ComboBox::outlineColourId, juce::Colours::transparentBlack);
    setColour(juce::TextButton::buttonColourId, juce::Colour(0xff3a3a3a));
    setColour(juce::ComboBox::buttonColourId, juce::Colours::transparentBlack);

    moduleBgColour = juce::Colour(0xff3a3a3a);
    emptySlotColour = juce::Colour(0xff2d2d2d);
    accentColour = juce::Colour(0xfff0c419);
    textColour = juce::Colours::white;
}

void CustomLookAndFeel::drawRotarySlider(juce::Graphics& g, int x, int y, int width, int height, float sliderPos,
    const float rotaryStartAngle, const float rotaryEndAngle, juce::Slider& slider)
{
    const float radius = (float)juce::jmin(width / 2, height / 2) - 5.0f;
    const float centreX = (float)x + (float)width * 0.5f;
    const float centreY = (float)y + (float)height * 0.5f;
    const float angle = rotaryStartAngle + sliderPos * (rotaryEndAngle - rotaryStartAngle);
    const float arcThickness = 3.0f;

    // Define Colors (Matching the image)
    juce::Colour trackColour = juce::Colour(0xff5c5c5c); // Dark grey track
    juce::Colour fillColour = juce::Colour(0xfff7c842);  // Yellow/Gold fill
    juce::Colour indicatorColour = juce::Colours::white;

    // 1. Draw the background track (Grey arc)
    juce::Path backgroundArc;
    backgroundArc.addCentredArc(centreX, centreY, radius, radius, 0.0f,
        rotaryStartAngle, rotaryEndAngle, true);
    g.setColour(trackColour);
    g.strokePath(backgroundArc, juce::PathStrokeType(arcThickness, juce::PathStrokeType::curved, juce::PathStrokeType::rounded));

    // 2. Draw the value fill (Yellow arc)
    if (slider.isEnabled())
    {
        juce::Path valueArc;
        valueArc.addCentredArc(centreX, centreY, radius, radius, 0.0f,
            rotaryStartAngle, angle, true);
        g.setColour(fillColour);
        g.strokePath(valueArc, juce::PathStrokeType(arcThickness, juce::PathStrokeType::curved, juce::PathStrokeType::rounded));
    }

    // 3. Draw the indicator (White line in the center)
    juce::Path indicator;
    const float indicatorLength = radius * 0.7f;
    const float indicatorStart = radius * 0.2f; // Start slightly away from the center

    indicator.startNewSubPath(centreX + std::sin(angle) * indicatorStart,
        centreY - std::cos(angle) * indicatorStart);
    indicator.lineTo(centreX + std::sin(angle) * indicatorLength,
        centreY - std::cos(angle) * indicatorLength);

    g.setColour(indicatorColour);
    g.strokePath(indicator, juce::PathStrokeType(2.0f));
}

// UPDATED: Overhauled for a modern, clean look, including Bipolar visualization, corrected geometry, and thumb outline.
void CustomLookAndFeel::drawLinearSlider(juce::Graphics& g, int x, int y, int width, int height,
    float sliderPos, float minSliderPos, float maxSliderPos, const juce::Slider::SliderStyle style, juce::Slider& slider)
{
    // FIXED: Address C4100 warnings by ignoring unused parameters.
    juce::ignoreUnused(minSliderPos);
    juce::ignoreUnused(maxSliderPos);

    // Check for standard linear styles (Horizontal/Vertical)
    if (style == juce::Slider::LinearHorizontal || style == juce::Slider::LinearVertical)
    {
        auto bounds = juce::Rectangle<int>(x, y, width, height).toFloat();

        // 1. Determine Thumb Size FIRST (Crucial for track calculation)
        // FIX: Use a consistent thumb size (16.0f) for both vertical and horizontal sliders
        // to match the appearance of the Master Mix slider.
        // auto thumbDiameter = (style == juce::Slider::LinearVertical) ? 12.0f : 16.0f; // OLD
        auto thumbDiameter = 16.0f; // NEW
        auto thumbRadius = thumbDiameter / 2.0f;

        // 2. Define the track appearance
        // FIX: Increased thickness to match the Master Mix slider visual weight.
        // float trackThickness = 4.0f; // OLD
        float trackThickness = 8.0f; // NEW
        float cornerRadius = trackThickness / 2.0f;

        // 3. Calculate Track Bounds (THE FIX)
        // We reduce the bounds by the thumb radius at the ends so the track visualization aligns with sliderPos.
        juce::Rectangle<float> trackBounds;

        if (style == juce::Slider::LinearHorizontal)
        {
            // Horizontal: Reduce the width by the thumb radius on both sides
            trackBounds = bounds.reduced(thumbRadius, 0)
                .withHeight(trackThickness)
                .withCentre(bounds.getCentre());
        }
        else
        {
            // Vertical: Reduce the height by the thumb radius on both top and bottom
            trackBounds = bounds.reduced(0, thumbRadius)
                .withWidth(trackThickness)
                .withCentre(bounds.getCentre());
        }


        // 4. Draw the background track
        g.setColour(moduleBgColour.brighter(0.3f)); // Slightly brighter than module background
        g.fillRoundedRectangle(trackBounds, cornerRadius);

        // 5. Draw the value track (the filled portion)
        juce::Rectangle<float> valueTrackBounds = trackBounds;

        // Use effectiveSliderPos clamped to the visual track bounds for drawing the fill
        float effectiveSliderPos;

        if (style == juce::Slider::LinearHorizontal)
        {
            effectiveSliderPos = juce::jlimit(trackBounds.getX(), trackBounds.getRight(), sliderPos);
            // Standard horizontal fill (Master Mix)
            valueTrackBounds = valueTrackBounds.withWidth(effectiveSliderPos - trackBounds.getX());
        }
        else // Vertical
        {
            effectiveSliderPos = juce::jlimit(trackBounds.getY(), trackBounds.getBottom(), sliderPos);

            // Bipolar visualization for vertical sliders (Input/Output Gain)
            // This logic is kept as it correctly visualizes gain from the center 0dB point.
            if (slider.getMinimum() < 0.0 && slider.getMaximum() > 0.0)
            {
                // Calculate the zero position based on OUR track geometry.
                const float proportion = (float)slider.valueToProportionOfLength(0.0);
                // Note: In JUCE vertical sliders (default), proportion 1.0 is at the TOP, 0.0 is at the BOTTOM.
                float zeroPos = trackBounds.getBottom() - trackBounds.getHeight() * proportion;

                // Clamp zeroPos within track bounds just in case of precision issues
                zeroPos = juce::jlimit(trackBounds.getY(), trackBounds.getBottom(), zeroPos);

                if (slider.getValue() >= 0.0)
                {
                    // Positive value: Fill from zeroPos UPWARDS to effectiveSliderPos
                    valueTrackBounds = trackBounds.withTop(effectiveSliderPos).withHeight(zeroPos - effectiveSliderPos);
                }
                else
                {
                    // Negative value: Fill from zeroPos DOWNWARDS to effectiveSliderPos
                    valueTrackBounds = trackBounds.withTop(zeroPos).withHeight(effectiveSliderPos - zeroPos);
                }
            }
            else
            {
                // Standard visualization (fill from bottom up)
                valueTrackBounds = valueTrackBounds.withTop(effectiveSliderPos).withHeight(trackBounds.getBottom() - effectiveSliderPos);
            }
        }

        g.setColour(accentColour);
        g.fillRoundedRectangle(valueTrackBounds, cornerRadius);

        // 6. Draw the Thumb
        juce::Rectangle<float> thumbBounds(thumbDiameter, thumbDiameter);

        // The input sliderPos is the correct center point for the thumb.
        if (style == juce::Slider::LinearHorizontal)
        {
            thumbBounds.setCentre({ sliderPos, trackBounds.getCentreY() });
        }
        else
        {
            thumbBounds.setCentre({ trackBounds.getCentreX(), sliderPos });
        }

        g.setColour(accentColour);
        g.fillEllipse(thumbBounds);

        // FIX: Add an outline to the thumb (Matches Picture 2).
        g.setColour(emptySlotColour); // Use the darkest color for outline contrast
        g.drawEllipse(thumbBounds.reduced(1.0f), 1.5f);
    }
    // Keep the existing logic for Bar style if needed
    // FIX: Replace deprecated slider.isBar()
    // else if (slider.isBar()) // OLD
    else if (style == juce::Slider::LinearBar || style == juce::Slider::LinearBarVertical) // NEW
    {
        // (Existing bar implementation remains)
        g.setColour(moduleBgColour.brighter(0.2f));
        g.fillRect(slider.getLocalBounds().toFloat());

        g.setColour(accentColour);
        const float value = (float)slider.valueToProportionOfLength(slider.getValue());
        if (value > 0)
            g.fillRect(slider.getLocalBounds().withWidth((int)((float)slider.getWidth() * value)).toFloat());
    }
    else
    {
        // (Fallback implementation remains the same)
        auto bounds = juce::Rectangle<int>(x, y, width, height).toFloat().reduced(0.5f);
        g.setColour(moduleBgColour.brighter(0.2f));
        g.fillRoundedRectangle(bounds, 5.0f);

        auto thumbWidth = 10.0f;
        auto thumbBounds = juce::Rectangle<float>(thumbWidth, (float)height).withCentre(bounds.getCentre());
        thumbBounds.setX(sliderPos - (thumbWidth / 2.0f));

        g.setColour(accentColour);
        g.fillRoundedRectangle(thumbBounds, 5.0f);
    }
}

void CustomLookAndFeel::drawToggleButton(juce::Graphics& g, juce::ToggleButton& button,
    bool shouldDrawButtonAsHighlighted, bool shouldDrawButtonAsDown)
{
    juce::ignoreUnused(shouldDrawButtonAsHighlighted, shouldDrawButtonAsDown);
    auto bounds = button.getLocalBounds().toFloat().reduced(2.0f);

    g.setColour(button.getToggleState() ? accentColour : moduleBgColour.brighter(0.2f));
    g.fillRoundedRectangle(bounds, 5.0f);

    g.setColour(textColour);
    g.drawFittedText(button.getButtonText(), bounds.toNearestInt(), juce::Justification::centred, 1);
}

void CustomLookAndFeel::drawComboBox(juce::Graphics& g, int width, int height, bool,
    int, int, int, int, juce::ComboBox& box)
{
    juce::ignoreUnused(box);
    auto cornerSize = 5.0f;
    juce::Rectangle<int> boxBounds(0, 0, width, height);

    g.setColour(moduleBgColour.brighter(0.2f));
    g.fillRoundedRectangle(boxBounds.toFloat(), cornerSize);
}

void CustomLookAndFeel::positionComboBoxText(juce::ComboBox& box, juce::Label& label)
{
    label.setBounds(box.getLocalBounds().reduced(5, 0));
    label.setFont(juce::FontOptions((float)box.getHeight() * 0.7f));
    label.setColour(juce::Label::textColourId, textColour);
    label.setJustificationType(juce::Justification::centredLeft);
}

juce::Font CustomLookAndFeel::getLabelFont(juce::Label&)
{
    return juce::Font(juce::FontOptions().withHeight(14.0f));
}

void CustomLookAndFeel::drawTextBoxedText(juce::Graphics& g, const juce::String& text, juce::Rectangle<int> bounds)
{
    g.setColour(moduleBgColour.brighter(0.2f));
    g.fillRoundedRectangle(bounds.toFloat(), 4.0f);

    g.setColour(textColour.withAlpha(0.5f));
    g.drawRect(bounds.toFloat(), 1.0f);

    g.setColour(textColour);
    g.drawFittedText(text, bounds, juce::Justification::centred, 1);
}

================================================================================
// File: UI/CustomLookAndFeel.h
================================================================================

#pragma once
#include <juce_gui_basics/juce_gui_basics.h>

class CustomLookAndFeel : public juce::LookAndFeel_V4
{
public:
    CustomLookAndFeel();
    ~CustomLookAndFeel() override = default;

    void drawRotarySlider(juce::Graphics& g, int x, int y, int width, int height, float sliderPos,
        const float rotaryStartAngle, const float rotaryEndAngle, juce::Slider& slider) override;

    void drawLinearSlider(juce::Graphics& g, int x, int y, int width, int height,
        float sliderPos, float minSliderPos, float maxSliderPos,
        const juce::Slider::SliderStyle, juce::Slider& slider) override;

    void drawToggleButton(juce::Graphics& g, juce::ToggleButton& button,
        bool shouldDrawButtonAsHighlighted, bool shouldDrawButtonAsDown) override;

    void drawComboBox(juce::Graphics& g, int width, int height, bool,
        int, int, int, int, juce::ComboBox& box) override;

    // Add the declaration for our new function
    void positionComboBoxText(juce::ComboBox& box, juce::Label& label) override;

    juce::Font getLabelFont(juce::Label& label) override;

    // Helper function for drawing text labels for parameters
    void drawTextBoxedText(juce::Graphics& g, const juce::String& text, juce::Rectangle<int> bounds);

    juce::Colour moduleBgColour;
    juce::Colour emptySlotColour;
    juce::Colour accentColour;
    juce::Colour textColour;
};

================================================================================
// File: UI/EmbeddedSVGs.h
================================================================================

﻿#pragma once

namespace EmbeddedSVGs
{
    // Use Raw String Literals R"SVG(...)SVG" for embedding.
    // The base color is #000000 (black), which allows for dynamic recoloring in the UI.
    // 1. Distortion
    static const char* distortionData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>Distortion</title>
  <path d="M4 32 C 10 20, 18 20, 24 32 C 30 44, 32 44, 36 32 L 40 18 L 44 46 L 48 22 L 52 42 L 56 30 L 60 34"
        fill="none" stroke="#000000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
)SVG";

    // 2. Filter
    static const char* filterData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>Filter</title>
  <path d="M 4 20 H 30 C 40 20, 44 24, 48 32 C 52 40, 56 48, 60 52"
        fill="none" stroke="#000000" stroke-width="6" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
)SVG";

    // 3. Modulation
    static const char* modulationData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>Modulation</title>
  <path d="M 4 32 C 16 16, 24 16, 32 32 C 40 48, 48 48, 60 32"
        fill="none" stroke="#000000" stroke-width="4" stroke-linecap="round"/>
  <path d="M 4 32 C 16 48, 24 48, 32 32 C 40 16, 48 16, 60 32"
        fill="none" stroke="#000000" stroke-width="4" stroke-linecap="round" opacity="0.6"/>
</svg>
)SVG";

    // 4. Delay
    static const char* delayData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>Delay</title>
  <ellipse cx="14" cy="32" rx="10" ry="16" fill="#000000" opacity="1"/>
  <ellipse cx="34" cy="32" rx="8" ry="14" fill="#000000" opacity="0.6"/>
  <ellipse cx="50" cy="32" rx="6" ry="12" fill="#000000" opacity="0.3"/>
</svg>
)SVG";

    // 5. Reverb
    static const char* reverbData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>Reverb</title>
  <path d="M 24 50 C 36 44, 36 20, 24 14" fill="none" stroke="#000000" stroke-width="4" stroke-linecap="round" opacity="1"/>
  <path d="M 34 56 C 48 48, 48 16, 34 8" fill="none" stroke="#000000" stroke-width="4" stroke-linecap="round" opacity="0.7"/>
  <path d="M 44 62 C 60 52, 60 12, 44 2" fill="none" stroke="#000000" stroke-width="4" stroke-linecap="round" opacity="0.4"/>
</svg>
)SVG";

    // 6. Compressor
    static const char* compressorData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>Compressor</title>
  <path d="M4 18 H 24 L 28 26 H 36 L 40 18 H 60" fill="none" stroke="#000000" stroke-width="4" stroke-linejoin="round"/>
  <path d="M4 46 H 24 L 28 38 H 36 L 40 46 H 60" fill="none" stroke="#000000" stroke-width="4" stroke-linejoin="round"/>
  <path d="M 32 10 L 32 16 M 28 13 L 32 17 L 36 13" fill="none" stroke="#000000" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/>
  <path d="M 32 54 L 32 48 M 28 51 L 32 47 L 36 51" fill="none" stroke="#000000" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
)SVG";

    // 7. ChromaTape
    static const char* chromaTapeData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>ChromaTape</title>
  <circle cx="32" cy="32" r="28" fill="none" stroke="#000000" stroke-width="4"/>
  <circle cx="32" cy="32" r="8" fill="#000000"/>
  <rect x="12" y="20" width="40" height="6" fill="#000000" opacity="0.4"/>
  <rect x="12" y="30" width="40" height="6" fill="#000000" opacity="0.7"/>
  <rect x="12" y="40" width="40" height="6" fill="#000000" opacity="1.0"/>
</svg>
)SVG";

    // 8. MorphoComp
    static const char* morphoCompData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>MorphoComp</title>
  <path d="M 4 32 L 20 32 L 32 20 L 44 44 L 60 32" fill="none" stroke="#000000" stroke-width="5" stroke-linecap="round" stroke-linejoin="round" opacity="1"/>
  <path d="M 4 32 C 16 20, 24 20, 32 32 C 40 44, 48 44, 60 32" fill="none" stroke="#000000" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" opacity="0.5" stroke-dasharray="5 5"/>
</svg>
)SVG";

    // 9. Physical Resonator (Using Dice Icon as placeholder)
    static const char* diceData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>Random</title>
  <rect x="10" y="10" width="44" height="44" rx="8" fill="none" stroke="#000000" stroke-width="4"/>
  <circle cx="22" cy="22" r="4" fill="#000000"/>
  <circle cx="42" cy="22" r="4" fill="#000000"/>
  <circle cx="32" cy="32" r="4" fill="#000000"/>
  <circle cx="22" cy="42" r="4" fill="#000000"/>
  <circle cx="42" cy="42" r="4" fill="#000000"/>
</svg>
)SVG";

    // 10. Spectral Animator
    static const char* spectralAnimatorData = R"SVG(
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 64 64" width="64" height="64">
  <title>Spectral Animator</title>
  <path d="M 8 56 V 8 L 56 8 V 56 Z" fill="none" stroke="#000000" stroke-width="4" stroke-linejoin="round"/>
  <path d="M 16 48 V 24 L 24 40 L 32 16 L 40 44 L 48 20 V 48" fill="none" stroke="#000000" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
)SVG";
}

================================================================================
// File: UI/ModuleHeader.cpp
================================================================================

#include "ModuleHeader.h"
#include "CustomLookAndFeel.h"

ModuleHeader::ModuleHeader()
{
    addAndMakeVisible(title);
    title.setJustificationType(juce::Justification::centred);
    title.setFont(juce::FontOptions(16.0f));

    addAndMakeVisible(optionsButton);
    optionsButton.onClick = [this] { if (onMenuClicked) onMenuClicked(); };

    addAndMakeVisible(deleteButton);
    deleteButton.onClick = [this] { if (onDeleteClicked) onDeleteClicked(); };
}

void ModuleHeader::paint(juce::Graphics& g)
{
    if (isDragHovering)
    {
        CustomLookAndFeel laf;
        g.setColour(laf.accentColour);
        g.drawRect(getLocalBounds().toFloat(), 2.0f);
    }
}

void ModuleHeader::mouseDrag(const juce::MouseEvent& event)
{
    juce::ignoreUnused(event);
    auto* dragContainer = juce::DragAndDropContainer::findParentDragContainerFor(this);
    if (dragContainer)
    {
        juce::var dragDescription = getSlotIndex();
        // Create a dummy 1x1 image
        juce::Image dragImage(juce::Image::PixelFormat::ARGB, 1, 1, true);

        // FIX: Wrap the image in juce::ScaledImage to use the non-deprecated overload.
        dragContainer->startDragging(dragDescription, this, juce::ScaledImage(dragImage), false);
    }
}

bool ModuleHeader::isInterestedInDragSource(const SourceDetails&)
{
    return true;
}

void ModuleHeader::itemDropped(const SourceDetails& dragSourceDetails)
{
    int sourceSlotIndex = dragSourceDetails.description;
    int targetSlotIndex = getSlotIndex();
    if (onSlotMoved)
        onSlotMoved(sourceSlotIndex, targetSlotIndex);

    isDragHovering = false;
    repaint();
}

void ModuleHeader::itemDragEnter(const SourceDetails&)
{
    isDragHovering = true;
    repaint();
}

void ModuleHeader::itemDragExit(const SourceDetails&)
{
    isDragHovering = false;
    repaint();
}

void ModuleHeader::resized()
{
    auto bounds = getLocalBounds();
    deleteButton.setBounds(bounds.removeFromLeft(30).reduced(5));
    optionsButton.setBounds(bounds.removeFromRight(30).reduced(5));
    title.setBounds(bounds);
}

================================================================================
// File: UI/ModuleHeader.h
================================================================================

#pragma once
#include <juce_gui_basics/juce_gui_basics.h>

class ModuleHeader : public juce::Component,
    public juce::DragAndDropTarget
{
public:
    std::function<void()> onMenuClicked;
    std::function<void()> onDeleteClicked;
    std::function<int()> getSlotIndex;
    std::function<void(int, int)> onSlotMoved;

    juce::Label title;
    juce::TextButton optionsButton{ "..." };
    juce::TextButton deleteButton{ "-" };

    ModuleHeader();

    void paint(juce::Graphics& g) override;
    void mouseDrag(const juce::MouseEvent& event) override;

    // Drag and Drop Target overrides
    bool isInterestedInDragSource(const SourceDetails& dragSourceDetails) override;
    void itemDropped(const SourceDetails& dragSourceDetails) override;
    void itemDragEnter(const SourceDetails& dragSourceDetails) override;
    void itemDragExit(const SourceDetails& dragSourceDetails) override;

    void resized() override;
private:
    bool isDragHovering = false;
    JUCE_DECLARE_NON_COPYABLE_WITH_LEAK_DETECTOR(ModuleHeader)
};

================================================================================
// File: UI/ModuleSelectionGrid.cpp
================================================================================

#include "ModuleSelectionGrid.h"
#include "EmbeddedSVGs.h" // Include the new SVG data

//==============================================================================
// ModuleGridButton Implementation
//==============================================================================

ModuleGridButton::ModuleGridButton(const juce::String& text, const char* svgData)
    : juce::Button(text)
{
    // Load the SVG data from the embedded string.
    if (svgData != nullptr)
    {
        // FIXED: Simply construct the juce::String from the const char* as it is null-terminated.
        juce::String svgString(svgData);

        // Use parseXML (free function) to get the XmlElement
        if (auto svgElement = juce::parseXML(svgString))
        {
            // Create the Drawable from the XmlElement
            svgImage = juce::Drawable::createFromSVG(*svgElement);
        }
    }
    // Ensure the button doesn't toggle state, it's just for selection
    setClickingTogglesState(false);
}

// CLEANED: Removed invisible characters (0xa0) that caused C3872 errors.
void ModuleGridButton::paintButton(juce::Graphics& g, bool shouldDrawButtonAsHighlighted, bool shouldDrawButtonAsDown) {
    // FIX: Retrieve the active LookAndFeel and cast it to access custom colors.
    auto* lnf = dynamic_cast<CustomLookAndFeel*>(&getLookAndFeel());

    // Define Colors based on the active LAF, providing fallbacks if the cast fails.
    const juce::Colour defaultBackground = (lnf != nullptr) ? lnf->moduleBgColour : juce::Colour(0xff3a3a3a);
    const juce::Colour highlightColour = (lnf != nullptr) ?
        lnf->accentColour : juce::Colour(0xfff0c419);
    const juce::Colour defaultIconColour = (lnf != nullptr) ? lnf->textColour : juce::Colours::white;
    const juce::Colour highlightIconColour = (lnf != nullptr) ? lnf->emptySlotColour : juce::Colour(0xff2d2d2d);

    bool isInteracting = shouldDrawButtonAsHighlighted || shouldDrawButtonAsDown;
    juce::Colour effectiveBackground;
    juce::Colour effectiveIconColour;

    // Set colors based on state
    if (isInteracting)
    {
        effectiveBackground = highlightColour;
        effectiveIconColour = highlightIconColour;
    }
    else
    {
        effectiveBackground = defaultBackground;
        effectiveIconColour = defaultIconColour;
    }

    // 1. Draw Background
    g.setColour(effectiveBackground);
    g.fillRoundedRectangle(getLocalBounds().toFloat(), 5.0f);
    // 2. Define Areas for Icon and Text
    auto bounds = getLocalBounds().reduced(5);
    auto textArea = bounds.removeFromBottom(20);
    auto iconArea = bounds.reduced(5); // Padding for the icon

    // 3. Draw Icon
    if (svgImage != nullptr)
    {
        // CRITICAL: Correctly handle dynamic recoloring for persistent Drawables.
        // Step A: Replace the base color (black) with the effective color.
        svgImage->replaceColour(juce::Colours::black, effectiveIconColour);

        // Step B: Draw the SVG.
        svgImage->drawWithin(g, iconArea.toFloat(),
            juce::RectanglePlacement::centred, 1.0f);
        // Step C: Revert the color back to the base color (black) so it's ready for the next paint cycle.
        svgImage->replaceColour(effectiveIconColour, juce::Colours::black);
    }

    // 4. Draw Text
    g.setColour(effectiveIconColour);
    g.setFont(13.0f);
    g.drawText(getButtonText(), textArea, juce::Justification::centred);
}

//==============================================================================
// ModuleSelectionGrid Implementation
//==============================================================================

ModuleSelectionGrid::ModuleSelectionGrid(juce::StringArray choices)
{
    // Ensure the grid uses the custom LAF for background color
    setLookAndFeel(&lookAndFeel);
    for (int i = 0; i < choices.size(); ++i)
    {
        auto* button = new ModuleGridButton(choices[i], getSvgDataForChoice(i + 1));
        button->onClick = [this, i]
            {
                // Dismiss the CallOutBox when a selection is made
                if (auto* callout = findParentComponentOfClass<juce::CallOutBox>())
                    callout->dismiss();
                if (onModuleSelected)
                    onModuleSelected(i + 1);
            };
        buttons.add(button);
        addAndMakeVisible(button);
    }
}

ModuleSelectionGrid::~ModuleSelectionGrid()
{
    setLookAndFeel(nullptr);
}

void ModuleSelectionGrid::paint(juce::Graphics& g) {
    // Set the background color for the entire grid area (the popup background)
    // Use the darkest color (emptySlotColour or ResizableWindow::backgroundColourId)
    g.fillAll(lookAndFeel.emptySlotColour);
}

// UPDATED: 4 columns x 3 rows layout for 10 modules
void ModuleSelectionGrid::resized() {
    juce::Grid grid;
    using Track = juce::Grid::TrackInfo;
    using Fr = juce::Grid::Fr;

    // UPDATED: 4 columns x 3 rows layout.
    grid.templateColumns = { Track(Fr(1)), Track(Fr(1)), Track(Fr(1)), Track(Fr(1)) };
    grid.templateRows = { Track(Fr(1)), Track(Fr(1)), Track(Fr(1)) };
    // Add spacing
    grid.setGap(juce::Grid::Px(8));

    for (auto* b : buttons)
        grid.items.add(juce::GridItem(b));
    // Perform layout with padding
    grid.performLayout(getLocalBounds().reduced(10));
}

// UPDATED: Aligned to 10 modules, removing BBDCloud and FractureTube
const char* ModuleSelectionGrid::getSvgDataForChoice(int choice) {
    switch (choice)
    {
    case 1: return EmbeddedSVGs::distortionData;
    case 2: return EmbeddedSVGs::filterData;
    case 3: return EmbeddedSVGs::modulationData;
    case 4: return EmbeddedSVGs::delayData;
    case 5: return EmbeddedSVGs::reverbData;
    case 6: return EmbeddedSVGs::compressorData;
    case 7: return EmbeddedSVGs::chromaTapeData;
    case 8: return EmbeddedSVGs::morphoCompData;
    case 9: return EmbeddedSVGs::diceData; // For Physical Resonator
    case 10: return EmbeddedSVGs::spectralAnimatorData;
    default: return nullptr;
    }
}

================================================================================
// File: UI/ModuleSelectionGrid.h
================================================================================

#pragma once
#include <juce_gui_basics/juce_gui_basics.h>
#include "CustomLookAndFeel.h"

// Renamed from IconTextButton and updated for SVG rendering
class ModuleGridButton : public juce::Button
{
public:
    // Updated constructor to take SVG data (const char*)
    ModuleGridButton(const juce::String& text, const char* svgData);
    // Updated paintButton signature
    void paintButton(juce::Graphics& g, bool shouldDrawButtonAsHighlighted, bool shouldDrawButtonAsDown) override;
private:
    // Use juce::Drawable for SVG
    std::unique_ptr<juce::Drawable> svgImage;
    // CustomLookAndFeel lookAndFeel; // <-- REMOVE THIS LINE
};

class ModuleSelectionGrid : public juce::Component
{
public:
    std::function<void(int)> onModuleSelected;

    ModuleSelectionGrid(juce::StringArray choices);
    ~ModuleSelectionGrid() override; // Added destructor

    // Added paint override for the grid background
    void paint(juce::Graphics& g) override;
    void resized() override;
private:
    // Helper function updated to return SVG data
    const char* getSvgDataForChoice(int choice);
    // Updated array type
    juce::OwnedArray<ModuleGridButton> buttons;
    CustomLookAndFeel lookAndFeel;
};

================================================================================
// File: UI/ModuleSlot.cpp
================================================================================

﻿// File: UI/ModuleSlot.cpp
#include "ModuleSlot.h"
#include "ModuleHeader.h"
#include "ModuleSelectionGrid.h"
#include "SlotEditors.h"
// NEW: Explicitly include the new editor definition
#include "PhysicalResonatorSlotEditor.h"

ModuleSlot::ModuleSlot(juce::AudioProcessorValueTreeState& apvts, int slotIndex)
    : valueTreeState(apvts), index(slotIndex)
{
    setLookAndFeel(&lookAndFeel);
    slotChoiceParamId = "SLOT_" + juce::String(index + 1) + "_CHOICE";
    slotPrefix = "SLOT_" + juce::String(index + 1) + "_";
    header = std::make_unique<ModuleHeader>();
    addAndMakeVisible(*header);
    header->onMenuClicked = [this] { showModuleMenu(); };
    header->getSlotIndex = [this] { return index; };
    header->onDeleteClicked = [this]
        {
            auto* param = valueTreeState.getParameter(slotChoiceParamId);
            param->setValueNotifyingHost(0.0f);
        };
    header->onSlotMoved = [this](int sourceSlot, int targetSlot)
        {
            auto sourceParamId = "SLOT_" + juce::String(sourceSlot + 1) + "_CHOICE";
            auto targetParamId = "SLOT_" + juce::String(targetSlot + 1) + "_CHOICE";

            auto* sourceParam = valueTreeState.getParameter(sourceParamId);
            auto* targetParam = valueTreeState.getParameter(targetParamId);
            if (sourceParam && targetParam)
            {
                float sourceVal = sourceParam->getValue();
                float targetVal = targetParam->getValue();
                sourceParam->setValueNotifyingHost(targetVal);
                targetParam->setValueNotifyingHost(sourceVal);
            }
        };

    addAndMakeVisible(addModuleButton);
    addModuleButton.onClick = [this] { showModuleMenu(); };

    // === FIX: Initialize Synchronously ===
    // We must initialize the module content synchronously before adding the listener.
    if (auto* paramValue = valueTreeState.getRawParameterValue(slotChoiceParamId))
    {
        // Call createModule directly.
        createModule(static_cast<int>(paramValue->load()));
    }
    else
    {
        createModule(0);
        // Safety fallback
    }

    // Now register the listener for future changes.
    valueTreeState.addParameterListener(slotChoiceParamId, this);
}

ModuleSlot::~ModuleSlot()
{
    setLookAndFeel(nullptr);
    valueTreeState.removeParameterListener(slotChoiceParamId, this);
}

void ModuleSlot::paint(juce::Graphics& g) {
    auto bounds = getLocalBounds();
    g.setColour(lookAndFeel.moduleBgColour);
    g.fillRoundedRectangle(bounds.toFloat(), 8.0f);

    if (currentEditor == nullptr)
    {
        g.setColour(lookAndFeel.emptySlotColour);
        g.fillRoundedRectangle(bounds.toFloat(), 8.0f);
        g.setColour(lookAndFeel.emptySlotColour.brighter(0.1f));
        for (int i = -bounds.getHeight(); i < bounds.getWidth(); i += 15)
        {
            g.drawLine((float)i, (float)bounds.getBottom(), (float)i + (float)bounds.getHeight(), (float)bounds.getY(), 2.0f);
        }
    }
}

void ModuleSlot::resized() {
    auto bounds = getLocalBounds();
    header->setBounds(bounds.removeFromTop(30));
    if (currentEditor != nullptr)
        currentEditor->setBounds(bounds);
    else
        addModuleButton.setBounds(bounds.withSizeKeepingCentre(40, 40));
}

// === FIX: Implement Hybrid Sync/Async Update ===
void ModuleSlot::parameterChanged(const juce::String& parameterID, float newValue) {
    if (parameterID == slotChoiceParamId)
    {
        // If we are on the message thread (e.g., user clicked the UI), update immediately (synchronously).
        if (juce::MessageManager::getInstance()->isThisTheMessageThread())
        {
            createModule((int)newValue);
        }
        else
        {
            // If called from another thread (e.g., automation), schedule it safely (asynchronously).
            // Use SafePointer in case the slot is deleted (e.g., row removed) before the async call runs.
            juce::Component::SafePointer<ModuleSlot> safeThis(this);
            int choice = (int)newValue;

            juce::MessageManager::callAsync([safeThis, choice] {
                if (ModuleSlot* slot = safeThis.getComponent()) {
                    slot->createModule(choice);
                }
                });
        }
    }
}

void ModuleSlot::createModule(int choice) {
    currentEditor.reset();
    if (choice == 0)
    {
        header->setVisible(false);
        addAndMakeVisible(addModuleButton);
    }
    else
    {
        header->setVisible(true);
        currentEditor = createEditorForChoice(choice);
        if (currentEditor)
        {
            header->title.setText(getModuleName(choice), juce::dontSendNotification);
            removeChildComponent(&addModuleButton);
            addAndMakeVisible(*currentEditor);
            resized();
        }
    }
    repaint();
}

std::unique_ptr<juce::Component> ModuleSlot::createEditorForChoice(int choice) {
    switch (choice)
    {
    case 1: return std::make_unique<DistortionSlotEditor>(valueTreeState, slotPrefix);
    case 2: return std::make_unique<FilterSlotEditor>(valueTreeState, slotPrefix);
    case 3: return std::make_unique<ModulationSlotEditor>(valueTreeState, slotPrefix);
    case 4: return std::make_unique<AdvancedDelaySlotEditor>(valueTreeState, slotPrefix);
    case 5: return std::make_unique<ReverbSlotEditor>(valueTreeState, slotPrefix);
    case 6: return std::make_unique<AdvancedCompressorSlotEditor>(valueTreeState, slotPrefix);
    case 7: return std::make_unique<ChromaTapeSlotEditor>(valueTreeState, slotPrefix);
    case 8: return std::make_unique<MorphoCompSlotEditor>(valueTreeState, slotPrefix);
    case 9: return std::make_unique<PhysicalResonatorSlotEditor>(valueTreeState, slotPrefix);
    case 10: return std::make_unique<SpectralAnimatorSlotEditor>(valueTreeState, slotPrefix);
    default: return nullptr;
    }
}
juce::String ModuleSlot::getModuleName(int choice) {
    switch (choice)
    {
    case 1: return "Distortion";
    case 2: return "Filter";
    case 3: return "Modulation";
    case 4: return "Delay";
    case 5: return "Reverb";
    case 6: return "Compressor";
    case 7: return "ChromaTape";
    case 8: return "MorphoComp";
    case 9: return "Physical Resonator";
    case 10: return "Spectral Animator";
    default: return "";
    }
}

void ModuleSlot::showModuleMenu() {
    auto* parameter = valueTreeState.getParameter(slotChoiceParamId);
    if (parameter == nullptr) return;
    auto choices = parameter->getAllValueStrings();
    choices.remove(0); // Remove "Empty"

    auto* grid = new ModuleSelectionGrid(choices);
    grid->setSize(420, 330);
    grid->onModuleSelected = [this, parameter](int choice)
        {
            parameter->setValueNotifyingHost(parameter->convertTo0to1(static_cast<float>(choice)));
        };

    juce::Rectangle<int> launchBounds;
    if (currentEditor == nullptr)
    {
        launchBounds = addModuleButton.getScreenBounds();
    }
    else
    {
        launchBounds = header->optionsButton.getScreenBounds();
    }

    juce::CallOutBox::launchAsynchronously(std::unique_ptr<juce::Component>(grid), launchBounds, nullptr);
}

================================================================================
// File: UI/ModuleSlot.h
================================================================================

#pragma once
#include <juce_gui_basics/juce_gui_basics.h>
#include <juce_audio_processors/juce_audio_processors.h>
#include "CustomLookAndFeel.h"

class ModuleSelectionGrid;
class ModuleHeader;

class ModuleSlot : public juce::Component,
    private juce::AudioProcessorValueTreeState::Listener
{
public:
    ModuleSlot(juce::AudioProcessorValueTreeState& apvts, int slotIndex);
    ~ModuleSlot() override;

    void paint(juce::Graphics& g) override;
    void resized() override;
private:
    void parameterChanged(const juce::String& parameterID, float newValue) override;

    void createModule(int choice);
    // UPDATED: No longer returns an AudioProcessorEditor
    std::unique_ptr<juce::Component> createEditorForChoice(int choice);
    juce::String getModuleName(int choice);
    void showModuleMenu();

    juce::AudioProcessorValueTreeState& valueTreeState;
    int index;
    juce::String slotChoiceParamId;
    juce::String slotPrefix;

    CustomLookAndFeel lookAndFeel;

    std::unique_ptr<ModuleHeader> header;
    // UPDATED: No more temp processor, just a simple component for the editor
    std::unique_ptr<juce::Component> currentEditor;
    juce::TextButton addModuleButton{ "+" };

    juce::CallOutBox* callOut = nullptr;
};

================================================================================
// File: UI/OrbController.h
================================================================================

#pragma once
#include <JuceHeader.h>
#include "UIConfig.h"

class OrbController : public juce::Component, public juce::Slider::Listener, public juce::Timer
{
public:
    juce::Slider tuneSlider; // Y axis
    juce::Slider mixSlider;  // X axis

    OrbController()
    {
        configureSlider(tuneSlider);
        configureSlider(mixSlider);
        currentMixNormalised = (float)mixSlider.valueToProportionOfLength(mixSlider.getValue());
        currentTuneNormalised = (float)tuneSlider.valueToProportionOfLength(tuneSlider.getValue());
        startTimerHz(60);
    }

    void paint(juce::Graphics& g) override
    {
        auto full = getLocalBounds().toFloat();
        // Padding so orb not clipped
        auto area = full.reduced(full.getWidth() * 0.15f, full.getHeight() * 0.15f);

        // Map normalized to position within area
        float x = area.getX() + currentMixNormalised * area.getWidth();
        float y = area.getBottom() - currentTuneNormalised * area.getHeight(); // invert Y

        float pulsation = 0.05f * currentMixNormalised * std::sin(phase);
        float baseRadius = juce::jmin(area.getWidth(), area.getHeight()) * 0.18f;
        float radius = baseRadius * (1.0f + pulsation);

        juce::Colour primaryColour = juce::Colours::yellow;
#ifdef UIConfig_h
        primaryColour = UIConfig::PRIMARY_COLOUR;
#endif

        juce::ColourGradient gradient(primaryColour.withAlpha(juce::jlimit(0.2f, 0.8f, currentMixNormalised * 1.2f)), x, y,
            primaryColour.withAlpha(0.0f), x, y + radius * 2.0f, true);
        g.setGradientFill(gradient);
        g.fillEllipse(x - radius * 2.0f, y - radius * 2.0f, radius * 4.0f, radius * 4.0f);

        g.setColour(primaryColour.withAlpha(0.9f));
        g.drawEllipse(x - radius, y - radius, radius * 2.0f, radius * 2.0f, 2.0f);

        g.setColour(juce::Colours::grey);
        g.setFont(10.0f);
        g.drawText("Drag: Tune (Y) / Mix (X)", full.removeFromBottom(18), juce::Justification::centred, false);
    }

    void mouseDown(const juce::MouseEvent& event) override
    {
        isDragging = true;
        startDragNormalisedValue.x = (float)mixSlider.valueToProportionOfLength(mixSlider.getValue());
        startDragNormalisedValue.y = (float)tuneSlider.valueToProportionOfLength(tuneSlider.getValue());
        mixSlider.startedDragging();
        tuneSlider.startedDragging();
        setMouseCursor(juce::MouseCursor::CrosshairCursor);
    }
    void mouseUp(const juce::MouseEvent&) override
    {
        if (isDragging)
        {
            mixSlider.stoppedDragging();
            tuneSlider.stoppedDragging();
        }
        isDragging = false;
        setMouseCursor(juce::MouseCursor::NormalCursor);
    }
    void mouseDrag(const juce::MouseEvent& event) override
    {
        if (!isDragging) return;
        auto delta = event.getOffsetFromDragStart();
        float sensitivity = 1.0f / 180.0f; // slightly faster
        float newMixNorm = juce::jlimit(0.0f, 1.0f, startDragNormalisedValue.x + delta.x * sensitivity);
        float newTuneNorm = juce::jlimit(0.0f, 1.0f, startDragNormalisedValue.y - delta.y * sensitivity);
        double newMixValue = mixSlider.proportionOfLengthToValue(newMixNorm);
        double newTuneValue = tuneSlider.proportionOfLengthToValue(newTuneNorm);
        mixSlider.setValue(newMixValue, juce::sendNotification);
        tuneSlider.setValue(newTuneValue, juce::sendNotification);
    }

    void sliderValueChanged(juce::Slider* slider) override
    {
        if (slider == &mixSlider)
            currentMixNormalised = (float)mixSlider.valueToProportionOfLength(mixSlider.getValue());
        else if (slider == &tuneSlider)
            currentTuneNormalised = (float)tuneSlider.valueToProportionOfLength(tuneSlider.getValue());
        repaint();
    }

    void timerCallback() override
    {
        phase += 0.08f; if (phase > juce::MathConstants<float>::twoPi) phase -= juce::MathConstants<float>::twoPi; repaint();
    }
private:
    float currentMixNormalised = 0.5f;
    float currentTuneNormalised = 0.5f;
    float phase = 0.0f;
    juce::Point<float> startDragNormalisedValue;
    bool isDragging = false;

    void configureSlider(juce::Slider& slider)
    {
        slider.setSliderStyle(juce::Slider::LinearHorizontal);
        slider.setTextBoxStyle(juce::Slider::NoTextBox, true, 0, 0);
        slider.addListener(this);
        addAndMakeVisible(slider);
        slider.setVisible(false);
    }
};

================================================================================
// File: UI/ParameterUIs.cpp
================================================================================

#include "ParameterUIs.h"
#include <JuceHeader.h> // Also needed here!

ParameterTextBox::ParameterTextBox(juce::AudioProcessorValueTreeState& apvtsRef, const juce::String& pId, const juce::String& lText)
    : apvts(apvtsRef), paramId(pId), labelText(lText)
{
    parameter = apvts.getParameter(paramId);
    apvts.addParameterListener(paramId, this);
    startTimerHz(30);
}

ParameterTextBox::~ParameterTextBox()
{
    apvts.removeParameterListener(paramId, this);
}

void ParameterTextBox::paint(juce::Graphics& g)
{
    auto bounds = getLocalBounds();
    auto labelBounds = bounds.removeFromLeft(bounds.getWidth() / 2);
    g.setColour(lookAndFeel.textColour);
    g.drawFittedText(labelText, labelBounds, juce::Justification::centredLeft, 1);

    if (parameter)
    {
        lookAndFeel.drawTextBoxedText(g, parameter->getCurrentValueAsText(), bounds);
    }
}

void ParameterTextBox::resized()
{
}

void ParameterTextBox::parameterChanged(const juce::String&, float)
{
}

================================================================================
// File: UI/ParameterUIs.h
================================================================================

﻿// File: UI/ParameterUIs.h
#pragma once
#include <JuceHeader.h>
#include "CustomLookAndFeel.h"

// UPDATED: Inherit from juce::SettableTooltipClient
class RotaryKnobWithLabels : public juce::Component, public juce::SettableTooltipClient
{
public:
    RotaryKnobWithLabels(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramID, const juce::String& labelText)
    {
        slider.setSliderStyle(juce::Slider::RotaryHorizontalVerticalDrag);
        slider.setTextBoxStyle(juce::Slider::NoTextBox, false, 0, 0);
        addAndMakeVisible(slider);

        attachment = std::make_unique<juce::AudioProcessorValueTreeState::SliderAttachment>(apvts, paramID, slider);

        label.setText(labelText, juce::dontSendNotification);
        label.setJustificationType(juce::Justification::centred);
        label.setFont(juce::FontOptions(14.0f));
        addAndMakeVisible(label);
    }

    void resized() override
    {
        auto bounds = getLocalBounds();
        label.setBounds(bounds.removeFromBottom(20));
        slider.setBounds(bounds);
    }

    // FIX: Removed 'override' keyword (C3668)
    void setTooltip(const juce::String& newTooltip)
    {
        // FIX: Call the implementation provided by juce::SettableTooltipClient (C2039)
        juce::SettableTooltipClient::setTooltip(newTooltip);
        // Also ensure child components explicitly have the tooltip set
        slider.setTooltip(newTooltip);
        label.setTooltip(newTooltip);
    }
private:
    juce::Slider slider;
    juce::Label label;
    std::unique_ptr<juce::AudioProcessorValueTreeState::SliderAttachment> attachment;
};

// =============================================================================
// NEW: Helper class for ComboBoxes (Used in PhysicalResonator)
// =============================================================================
class ComboBoxWithLabel : public juce::Component, public juce::SettableTooltipClient
{
public:
    ComboBoxWithLabel(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramID, const juce::String& name)
    {
        addAndMakeVisible(comboBox);
        // Populate the combo box items from the parameter definition
        if (auto* param = apvts.getParameter(paramID))
        {
            comboBox.addItemList(param->getAllValueStrings(), 1);
        }

        label.setText(name, juce::dontSendNotification);
        label.setJustificationType(juce::Justification::centred);
        label.setFont(juce::FontOptions(14.0f));
        addAndMakeVisible(label);

        attachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, paramID, comboBox);
    }

    void resized() override
    {
        // Layout matching RotaryKnobWithLabels for consistency
        auto bounds = getLocalBounds();
        label.setBounds(bounds.removeFromBottom(20));
        // Adjust the bounds for the ComboBox aesthetics within the remaining space
        // Center the combobox vertically with a fixed height of 30
        comboBox.setBounds(bounds.withSizeKeepingCentre(bounds.getWidth(), 30));
    }

    void setTooltip(const juce::String& newTooltip)
    {
        juce::SettableTooltipClient::setTooltip(newTooltip);
        comboBox.setTooltip(newTooltip);
        label.setTooltip(newTooltip);
    }

    juce::ComboBox& getComboBox() { return comboBox; }
private:
    juce::ComboBox comboBox;
    juce::Label label;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> attachment;
};

// NEW: An encapsulated component for the Input/Output vertical faders.
// UPDATED: Inherit from juce::SettableTooltipClient
class VerticalFaderWithAttachment : public juce::Component, public juce::SettableTooltipClient
{
public:
    VerticalFaderWithAttachment(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramID, const juce::String& labelText)
    {
        // Configure slider for vertical movement
        slider.setSliderStyle(juce::Slider::LinearVertical);
        // Hide the text box as shown in the screenshot
        slider.setTextBoxStyle(juce::Slider::NoTextBox, false, 0, 0);
        addAndMakeVisible(slider);

        /* FIX: Removed the manual setRange call. The SliderAttachment handles this automatically and robustly.
        // Explicitly set the range to ensure the LookAndFeel correctly identifies the 0 point for bipolar visualization
        if (auto* param = apvts.getParameter(paramID)) {
            slider.setRange(param->getNormalisableRange().start, param->getNormalisableRange().end);
        }
        */

        // Setup the attachment
        attachment = std::make_unique<juce::AudioProcessorValueTreeState::SliderAttachment>(apvts, paramID, slider);

        // Configure the label
        label.setText(labelText, juce::dontSendNotification);
        label.setJustificationType(juce::Justification::centred);
        label.setFont(juce::FontOptions(14.0f));
        addAndMakeVisible(label);
    }

    void resized() override
    {
        auto bounds = getLocalBounds();
        // Label at the top
        label.setBounds(bounds.removeFromTop(20));
        slider.setBounds(bounds);
    }

    // Implement setTooltip for consistency
    void setTooltip(const juce::String& newTooltip)
    {
        juce::SettableTooltipClient::setTooltip(newTooltip);
        slider.setTooltip(newTooltip);
        label.setTooltip(newTooltip);
    }
private:
    juce::Slider slider;
    juce::Label label;
    std::unique_ptr<juce::AudioProcessorValueTreeState::SliderAttachment> attachment;
};
// A vertical slider component with a label (used in ChromaTape)
// UPDATED: Inherit from juce::SettableTooltipClient
class VerticalSliderWithLabel : public juce::Component, public juce::SettableTooltipClient
{
public:
    VerticalSliderWithLabel(const juce::String& labelText)
    {
        slider.setSliderStyle(juce::Slider::LinearVertical);
        slider.setTextBoxStyle(juce::Slider::NoTextBox, false, 0, 0);
        addAndMakeVisible(slider);

        label.setText(labelText, juce::dontSendNotification);
        label.setJustificationType(juce::Justification::centred);
        label.setFont(juce::FontOptions(14.0f));
        addAndMakeVisible(label);
    }

    void resized() override
    {
        auto bounds = getLocalBounds();
        // Label at the top, matching the screenshot (Saturation, Wow, Flutter labels)
        label.setBounds(bounds.removeFromTop(20));
        slider.setBounds(bounds);
    }

    // Public accessor for the internal slider
    juce::Slider& getSlider() {
        return slider;
    }

    // Implement setTooltip
    void setTooltip(const juce::String& newTooltip)
    {
        juce::SettableTooltipClient::setTooltip(newTooltip);
        slider.setTooltip(newTooltip);
        label.setTooltip(newTooltip);
    }
private:
    juce::Slider slider;
    juce::Label label;
};
// A text box for displaying parameter values
// UPDATED: Inherit from juce::SettableTooltipClient
class ParameterTextBox : public juce::Component, public juce::SettableTooltipClient,
    private juce::AudioProcessorValueTreeState::Listener,
    private juce::Timer
{
public:
    ParameterTextBox(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramID, const juce::String& labelText);
    ~ParameterTextBox() override;

    void paint(juce::Graphics& g) override;
    void resized() override;

    // Implement setTooltip
    void setTooltip(const juce::String& newTooltip)
    {
        juce::SettableTooltipClient::setTooltip(newTooltip);
    }
private:
    void parameterChanged(const juce::String& parameterID, float newValue) override;
    void timerCallback() override {
        repaint();
    }

    juce::AudioProcessorValueTreeState& apvts;
    juce::String paramId;
    juce::String labelText;
    juce::RangedAudioParameter* parameter = nullptr;

    CustomLookAndFeel lookAndFeel;
};

================================================================================
// File: UI/PhysicalResonatorSlotEditor.cpp
================================================================================

#include "PhysicalResonatorSlotEditor.h"

PhysicalResonatorSlotEditor::PhysicalResonatorSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& prefix)
    : SlotEditorBase(apvts, prefix),
    // RESTORE: Physical Resonator parameter prefix must include PHYSRES_
    physResPrefix(prefix + "PHYSRES_")
{
    // --- Setup Components ---
    addAndMakeVisible(orbController);
    addAndMakeVisible(xyPad);
    addAndMakeVisible(modelSelector);
    addAndMakeVisible(noiseTypeSelector);

    // Labels
    addAndMakeVisible(modelLabel);
    modelLabel.setText("Model", juce::dontSendNotification);
    modelLabel.attachToComponent(&modelSelector, false);
    modelLabel.setJustificationType(juce::Justification::centred);

    addAndMakeVisible(noiseTypeLabel);
    noiseTypeLabel.setText("Noise Type", juce::dontSendNotification);
    noiseTypeLabel.attachToComponent(&noiseTypeSelector, false);
    noiseTypeLabel.setJustificationType(juce::Justification::centred);

    addAndMakeVisible(excitationLabel);
    excitationLabel.setText("Excitation (X: Excite Type / Y: Sensitivity)", juce::dontSendNotification);
    excitationLabel.setJustificationType(juce::Justification::centred);

    // Populate ComboBoxes from APVTS (only if parameters exist)
    if (auto* param = apvts.getParameter(physResPrefix + "MODEL"))
        modelSelector.addItemList(param->getAllValueStrings(), 1);

    if (auto* param = apvts.getParameter(physResPrefix + "NOISE_TYPE"))
        noiseTypeSelector.addItemList(param->getAllValueStrings(), 1);

    // --- Setup Attachments (Correct parameter IDs) ---
    tuneAttachment = std::make_unique<SliderAttachment>(apvts, physResPrefix + "TUNE", orbController.tuneSlider);
    mixAttachment = std::make_unique<SliderAttachment>(apvts, physResPrefix + "MIX", orbController.mixSlider);
    modelAttachment = std::make_unique<ComboBoxAttachment>(apvts, physResPrefix + "MODEL", modelSelector);

    exciteTypeAttachment = std::make_unique<SliderAttachment>(apvts, physResPrefix + "EXCITE_TYPE", xyPad.xSlider);
    sensitivityAttachment = std::make_unique<SliderAttachment>(apvts, physResPrefix + "SENSITIVITY", xyPad.ySlider);
    noiseTypeAttachment = std::make_unique<ComboBoxAttachment>(apvts, physResPrefix + "NOISE_TYPE", noiseTypeSelector);

    // Ensure initial internal normalised values reflect current slider state
    orbController.sliderValueChanged(&orbController.mixSlider);
    xyPad.sliderValueChanged(&xyPad.xSlider);
    xyPad.sliderValueChanged(&xyPad.ySlider);

    setSize(300, 450);
}

void PhysicalResonatorSlotEditor::paint(juce::Graphics& g)
{
    // Background handled externally.
}

void PhysicalResonatorSlotEditor::resized()
{
    auto bounds = getLocalBounds();
    bounds.reduce(10, 15); // Add some padding

    // 1. Resonator Core Area
    auto resonatorArea = bounds.removeFromTop(bounds.getHeight() * 0.55f);

    // Model Selector (placed above the Orb)
    modelSelector.setBounds(resonatorArea.removeFromTop(50).reduced(60, 10));

    // The Orb
    orbController.setBounds(resonatorArea);

    // 2. Excitation Engine Area
    bounds.removeFromTop(10); // Spacer
    excitationLabel.setBounds(bounds.removeFromTop(20));

    auto excitationArea = bounds;

    // XY Pad
    xyPad.setBounds(excitationArea.removeFromTop(100).reduced(40, 0));

    // Noise Type Selector (placed below the XY Pad)
    noiseTypeSelector.setBounds(excitationArea.removeFromTop(50).reduced(60, 10));
}

================================================================================
// File: UI/PhysicalResonatorSlotEditor.h
================================================================================

#pragma once
#include "SlotEditors.h"
#include "UIConfig.h"
#include "OrbController.h"
#include "XYPad.h"

class PhysicalResonatorSlotEditor : public SlotEditorBase
{
public:
    PhysicalResonatorSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& prefix);
    ~PhysicalResonatorSlotEditor() override = default;

    void paint(juce::Graphics& g) override;
    void resized() override;

private:
    juce::String physResPrefix;

    // New UI Elements
    OrbController orbController;
    XYPad xyPad;

    // Standard Selectors
    juce::ComboBox modelSelector, noiseTypeSelector;
    juce::Label modelLabel, noiseTypeLabel, excitationLabel;

    // Attachments
    using SliderAttachment = juce::AudioProcessorValueTreeState::SliderAttachment;
    using ComboBoxAttachment = juce::AudioProcessorValueTreeState::ComboBoxAttachment;

    std::unique_ptr<SliderAttachment> tuneAttachment, mixAttachment, exciteTypeAttachment, sensitivityAttachment;
    std::unique_ptr<ComboBoxAttachment> modelAttachment, noiseTypeAttachment;
};

================================================================================
// File: UI/SlotEditors.cpp
================================================================================

//================================================================================
// File: UI/SlotEditors.cpp
//================================================================================
#include "SlotEditors.h"

//==============================================================================
// DistortionSlotEditor Implementation
//==============================================================================
DistortionSlotEditor::DistortionSlotEditor(juce::AudioProcessorValueTreeState& apvtsRef, const juce::String& paramPrefix)
    : SlotEditorBase(apvtsRef, paramPrefix),
    driveKnob(apvts, paramPrefix + "DISTORTION_DRIVE", "Drive"),
    levelKnob(apvts, paramPrefix + "DISTORTION_LEVEL", "Level"),
    biasKnob(apvts, paramPrefix + "DISTORTION_BIAS", "Bias"),
    characterKnob(apvts, paramPrefix + "DISTORTION_CHARACTER", "Character")
{
    addAndMakeVisible(driveKnob);
    addAndMakeVisible(levelKnob);
    addAndMakeVisible(biasKnob);
    addAndMakeVisible(characterKnob);

    typeBox.addItemList(apvts.getParameter(paramPrefix + "DISTORTION_TYPE")->getAllValueStrings(), 1);
    addAndMakeVisible(typeBox);
    typeAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, paramPrefix + "DISTORTION_TYPE", typeBox);

    apvts.addParameterListener(paramPrefix + "DISTORTION_TYPE", this);
    updateVisibilities();
}

DistortionSlotEditor::~DistortionSlotEditor()
{
    apvts.removeParameterListener(paramPrefix + "DISTORTION_TYPE", this);
}

void DistortionSlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    typeBox.setBounds(bounds.removeFromTop(30).reduced(5, 0));

    juce::FlexBox fb;
    fb.flexWrap = juce::FlexBox::Wrap::wrap;
    fb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    fb.alignContent = juce::FlexBox::AlignContent::spaceAround;

    float basis = (float)bounds.getWidth() / 2.0f;
    fb.items.add(LayoutHelpers::createFlexKnob(driveKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(levelKnob, basis));

    if (biasKnob.isVisible())
        fb.items.add(LayoutHelpers::createFlexKnob(biasKnob, basis));
    if (characterKnob.isVisible())
        fb.items.add(LayoutHelpers::createFlexKnob(characterKnob, basis));

    fb.performLayout(bounds);
}

void DistortionSlotEditor::parameterChanged(const juce::String&, float) { updateVisibilities(); }

void DistortionSlotEditor::updateVisibilities()
{
    auto type = static_cast<int>(apvts.getRawParameterValue(paramPrefix + "DISTORTION_TYPE")->load());
    biasKnob.setVisible(type == 0);
    characterKnob.setVisible(type == 1 || type == 2);
    if (getWidth() > 0 && getHeight() > 0)
        resized();
}

//==============================================================================
// FilterSlotEditor Implementation
//==============================================================================
FilterSlotEditor::FilterSlotEditor(juce::AudioProcessorValueTreeState& apvtsRef, const juce::String& paramPrefix)
    : SlotEditorBase(apvtsRef, paramPrefix),
    cutoffKnob(apvts, paramPrefix + "FILTER_CUTOFF", "Cutoff"),
    resonanceKnob(apvts, paramPrefix + "FILTER_RESONANCE", "Resonance"),
    driveKnob(apvts, paramPrefix + "FILTER_DRIVE", "Drive")
{
    addAndMakeVisible(cutoffKnob);
    addAndMakeVisible(resonanceKnob);
    addAndMakeVisible(driveKnob);

    profileBox.addItemList(apvts.getParameter(paramPrefix + "FILTER_PROFILE")->getAllValueStrings(), 1);
    addAndMakeVisible(profileBox);
    profileAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, paramPrefix + "FILTER_PROFILE", profileBox);

    typeBox.addItemList(apvts.getParameter(paramPrefix + "FILTER_TYPE")->getAllValueStrings(), 1);
    addAndMakeVisible(typeBox);
    typeAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, paramPrefix + "FILTER_TYPE", typeBox);

    apvts.addParameterListener(paramPrefix + "FILTER_PROFILE", this);
    updateVisibilities();
}

FilterSlotEditor::~FilterSlotEditor()
{
    apvts.removeParameterListener(paramPrefix + "FILTER_PROFILE", this);
}

void FilterSlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    auto topStrip = bounds.removeFromTop(30);

    if (typeBox.isVisible())
    {
        profileBox.setBounds(topStrip.removeFromLeft(topStrip.getWidth() / 2).reduced(5, 0));
        typeBox.setBounds(topStrip.reduced(5, 0));
    }
    else
    {
        profileBox.setBounds(topStrip.reduced(5, 0));
    }

    juce::FlexBox fb;
    fb.flexWrap = juce::FlexBox::Wrap::wrap;
    fb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    fb.alignContent = juce::FlexBox::AlignContent::spaceAround;
    int visibleKnobs = 2 + (driveKnob.isVisible() ? 1 : 0);
    float basis = (float)bounds.getWidth() / (float)visibleKnobs;

    fb.items.add(LayoutHelpers::createFlexKnob(cutoffKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(resonanceKnob, basis));
    if (driveKnob.isVisible())
        fb.items.add(LayoutHelpers::createFlexKnob(driveKnob, basis));

    fb.performLayout(bounds);
}

void FilterSlotEditor::parameterChanged(const juce::String&, float) { updateVisibilities(); }

void FilterSlotEditor::updateVisibilities()
{
    auto* profileParam = apvts.getRawParameterValue(paramPrefix + "FILTER_PROFILE");
    auto profile = static_cast<FilterProcessor::Profile>(static_cast<int>(profileParam->load()));

    typeBox.setVisible(profile == FilterProcessor::svfProfile);
    driveKnob.setVisible(profile == FilterProcessor::transistorLadder || profile == FilterProcessor::diodeLadder);
    if (getWidth() > 0 && getHeight() > 0)
        resized();
}


//==============================================================================
// AdvancedDelaySlotEditor Implementation
//==============================================================================
AdvancedDelaySlotEditor::AdvancedDelaySlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix)
    : SlotEditorBase(apvts, paramPrefix),
    advDelayPrefix(paramPrefix + "ADVDELAY_"),
    timeKnob(apvts, advDelayPrefix + "TIME", "Time"),
    feedbackKnob(apvts, advDelayPrefix + "FEEDBACK", "Feedback"),
    mixKnob(apvts, advDelayPrefix + "MIX", "Mix"),
    colorKnob(apvts, advDelayPrefix + "COLOR", "Color"),
    wowKnob(apvts, advDelayPrefix + "WOW", "Wow"),
    flutterKnob(apvts, advDelayPrefix + "FLUTTER", "Flutter"),
    ageKnob(apvts, advDelayPrefix + "AGE", "Age")
{
    addAndMakeVisible(timeKnob);
    addAndMakeVisible(feedbackKnob);
    addAndMakeVisible(mixKnob);
    addAndMakeVisible(colorKnob);
    addAndMakeVisible(wowKnob);
    addAndMakeVisible(flutterKnob);
    addAndMakeVisible(ageKnob);

    if (apvts.getParameter(advDelayPrefix + "MODE"))
    {
        modeBox.addItemList(apvts.getParameter(advDelayPrefix + "MODE")->getAllValueStrings(), 1);
        addAndMakeVisible(modeBox);
        modeAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, advDelayPrefix + "MODE", modeBox);
    }
}

void AdvancedDelaySlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    if (modeBox.isVisible())
        modeBox.setBounds(bounds.removeFromTop(30).reduced(5, 0));

    juce::FlexBox fb;
    fb.flexWrap = juce::FlexBox::Wrap::wrap;
    fb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    fb.alignContent = juce::FlexBox::AlignContent::spaceAround;

    float basis = (float)bounds.getWidth() / 3.0f;
    if (basis < LayoutHelpers::minKnobWidth && bounds.getWidth() > LayoutHelpers::minKnobWidth * 2)
        basis = (float)bounds.getWidth() / 2.0f;
    fb.items.add(LayoutHelpers::createFlexKnob(timeKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(feedbackKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(mixKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(colorKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(wowKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(flutterKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(ageKnob, basis));

    fb.performLayout(bounds);
}

//==============================================================================
// ModulationSlotEditor Implementation
//==============================================================================
ModulationSlotEditor::ModulationSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix)
    : SlotEditorBase(apvts, paramPrefix),
    rateKnob(apvts, paramPrefix + "MODULATION_RATE", "Rate"),
    depthKnob(apvts, paramPrefix + "MODULATION_DEPTH", "Depth"),
    feedbackKnob(apvts, paramPrefix + "MODULATION_FEEDBACK", "Feedback"),
    mixKnob(apvts, paramPrefix + "MODULATION_MIX", "Mix")
{
    addAndMakeVisible(rateKnob);
    addAndMakeVisible(depthKnob);
    addAndMakeVisible(feedbackKnob);
    addAndMakeVisible(mixKnob);

    modeBox.addItemList(apvts.getParameter(paramPrefix + "MODULATION_MODE")->getAllValueStrings(), 1);
    addAndMakeVisible(modeBox);
    modeAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, paramPrefix + "MODULATION_MODE", modeBox);
}

void ModulationSlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    modeBox.setBounds(bounds.removeFromTop(30).reduced(5, 0));

    juce::FlexBox fb;
    fb.flexWrap = juce::FlexBox::Wrap::wrap;
    fb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    fb.alignContent = juce::FlexBox::AlignContent::spaceAround;

    float basis = (float)bounds.getWidth() / 2.0f;
    fb.items.add(LayoutHelpers::createFlexKnob(rateKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(depthKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(feedbackKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(mixKnob, basis));

    fb.performLayout(bounds);
}

//==============================================================================
// ReverbSlotEditor Implementation
//==============================================================================
ReverbSlotEditor::ReverbSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix)
    : SlotEditorBase(apvts, paramPrefix),
    roomSizeKnob(apvts, paramPrefix + "REVERB_ROOM_SIZE", "Room Size"),
    dampingKnob(apvts, paramPrefix + "REVERB_DAMPING", "Damping"),
    mixKnob(apvts, paramPrefix + "REVERB_MIX", "Mix"),
    widthKnob(apvts, paramPrefix + "REVERB_WIDTH", "Width")
{
    addAndMakeVisible(roomSizeKnob);
    addAndMakeVisible(dampingKnob);
    addAndMakeVisible(mixKnob);
    addAndMakeVisible(widthKnob);
}

void ReverbSlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    juce::FlexBox fb;
    fb.flexWrap = juce::FlexBox::Wrap::wrap;
    fb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    fb.alignContent = juce::FlexBox::AlignContent::spaceAround;

    float basis = (float)bounds.getWidth() / 2.0f;

    fb.items.add(LayoutHelpers::createFlexKnob(roomSizeKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(dampingKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(mixKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(widthKnob, basis));

    fb.performLayout(bounds);
}

//==============================================================================
// AdvancedCompressorSlotEditor Implementation
//==============================================================================
AdvancedCompressorSlotEditor::AdvancedCompressorSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix)
    : SlotEditorBase(apvts, paramPrefix),
    advCompPrefix(paramPrefix + "ADVCOMP_"),
    thresholdKnob(apvts, advCompPrefix + "THRESHOLD", "Threshold"),
    ratioKnob(apvts, advCompPrefix + "RATIO", "Ratio"),
    attackKnob(apvts, advCompPrefix + "ATTACK", "Attack"),
    releaseKnob(apvts, advCompPrefix + "RELEASE", "Release"),
    makeupKnob(apvts, advCompPrefix + "MAKEUP", "Makeup")
{

    addAndMakeVisible(thresholdKnob);
    addAndMakeVisible(ratioKnob);
    addAndMakeVisible(attackKnob);
    addAndMakeVisible(releaseKnob);
    addAndMakeVisible(makeupKnob);

    if (apvts.getParameter(advCompPrefix + "TOPOLOGY") && apvts.getParameter(advCompPrefix + "DETECTOR"))
    {
        topologyBox.addItemList(apvts.getParameter(advCompPrefix + "TOPOLOGY")->getAllValueStrings(), 1);
        addAndMakeVisible(topologyBox);
        topologyAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, advCompPrefix + "TOPOLOGY", topologyBox);

        detectorBox.addItemList(apvts.getParameter(advCompPrefix + "DETECTOR")->getAllValueStrings(), 1);
        addAndMakeVisible(detectorBox);
        detectorAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, advCompPrefix + "DETECTOR", detectorBox);
    }
}

void AdvancedCompressorSlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    auto topStrip = bounds.removeFromTop(30);

    if (topologyBox.isVisible() && detectorBox.isVisible())
    {
        topologyBox.setBounds(topStrip.removeFromLeft(topStrip.getWidth() / 2).reduced(5, 0));
        detectorBox.setBounds(topStrip.reduced(5, 0));
    }

    juce::FlexBox fb;
    fb.flexWrap = juce::FlexBox::Wrap::wrap;
    fb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    fb.alignContent = juce::FlexBox::AlignContent::spaceAround;

    float basis = (float)bounds.getWidth() / 3.0f;
    if (basis < LayoutHelpers::minKnobWidth && bounds.getWidth() > LayoutHelpers::minKnobWidth * 2)
        basis = (float)bounds.getWidth() / 2.0f;
    fb.items.add(LayoutHelpers::createFlexKnob(thresholdKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(ratioKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(attackKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(releaseKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(makeupKnob, basis));

    fb.performLayout(bounds);
}

//==============================================================================
// ChromaTapeSlotEditor Implementation
//==============================================================================
ChromaTapeSlotEditor::ChromaTapeSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix)
    : SlotEditorBase(apvts, paramPrefix),
    ctPrefix(paramPrefix + "CT_"),
    lowMidCrossKnob(apvts, ctPrefix + "LOWMID_CROSS", "L/M Blend"),
    midHighCrossKnob(apvts, ctPrefix + "MIDHIGH_CROSS", "M/H Blend"),
    saturationSlider("Saturation"),
    wowSlider("Wow"),
    flutterSlider("Flutter")
{
    addAndMakeVisible(lowMidCrossKnob);
    addAndMakeVisible(midHighCrossKnob);
    addAndMakeVisible(saturationSlider);
    addAndMakeVisible(wowSlider);
    addAndMakeVisible(flutterSlider);

    const std::array<juce::String, 3> bands = { "LOW", "MID", "HIGH" };
    for (int i = 0; i < 3; ++i)
    {
        sliderParams[&saturationSlider.getSlider()][i] = apvts.getParameter(ctPrefix + bands[i] + "_SATURATION");
        sliderParams[&wowSlider.getSlider()][i] = apvts.getParameter(ctPrefix + bands[i] + "_WOW");
        sliderParams[&flutterSlider.getSlider()][i] = apvts.getParameter(ctPrefix + bands[i] + "_FLUTTER");
    }

    setupSliders();
    setupButtons();
    lowButton.setToggleState(true, juce::dontSendNotification);
    updateSliderTargets();
    initializeAnimations();
    startTimerHz(60);
}

ChromaTapeSlotEditor::~ChromaTapeSlotEditor()
{
    stopTimer();
}

void ChromaTapeSlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    int crossoverHeight = 100;
    int buttonHeight = 40;
    auto crossoverArea = bounds.removeFromTop(crossoverHeight);
    auto buttonArea = bounds.removeFromBottom(buttonHeight);
    auto sliderArea = bounds;
    juce::FlexBox crossoverFb;
    crossoverFb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    crossoverFb.items.add(LayoutHelpers::createFlexKnob(lowMidCrossKnob, 100.0f));
    crossoverFb.items.add(LayoutHelpers::createFlexKnob(midHighCrossKnob, 100.0f));
    crossoverFb.performLayout(crossoverArea);

    juce::FlexBox sliderFb;
    sliderFb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    sliderFb.alignItems = juce::FlexBox::AlignItems::stretch;
    auto createSliderItem = [&](VerticalSliderWithLabel& slider) {
        return juce::FlexItem(slider).withFlex(1.0f).withMinWidth(50.0f).withMargin(5);
        };
    sliderFb.items.add(createSliderItem(saturationSlider));
    sliderFb.items.add(createSliderItem(wowSlider));
    sliderFb.items.add(createSliderItem(flutterSlider));
    sliderFb.performLayout(sliderArea);

    int btnHeight = 30;
    lowButton.setBounds(buttonArea.withSize(saturationSlider.getWidth(), btnHeight)
        .withCentre(juce::Point<int>(saturationSlider.getBounds().getCentreX(), buttonArea.getCentreY())));
    midButton.setBounds(buttonArea.withSize(wowSlider.getWidth(), btnHeight)
        .withCentre(juce::Point<int>(wowSlider.getBounds().getCentreX(), buttonArea.getCentreY())));
    highButton.setBounds(buttonArea.withSize(flutterSlider.getWidth(), btnHeight)
        .withCentre(juce::Point<int>(flutterSlider.getBounds().getCentreX(), buttonArea.getCentreY())));
}

void ChromaTapeSlotEditor::timerCallback()
{
    updateSliderTargets();
    const float animationSpeed = 0.25f;

    for (auto& pair : sliderAnimations)
    {
        juce::Slider* slider = pair.first;
        AnimationState& state = pair.second;

        if (std::abs(state.target - state.current) > 1e-4)
        {
            state.current += (state.target - state.current) * animationSpeed;
            slider->setValue(slider->proportionOfLengthToValue(state.current), juce::dontSendNotification);
        }
        else if (state.current != state.target)
        {
            state.current = state.target;
            slider->setValue(slider->proportionOfLengthToValue(state.current), juce::dontSendNotification);
        }
    }
}

void ChromaTapeSlotEditor::bandButtonClicked(int bandIndex)
{
    if (currentBand == bandIndex) return;
    currentBand = bandIndex;
}

void ChromaTapeSlotEditor::sliderValueChanged(juce::Slider* slider)
{
    auto* param = sliderParams[slider][currentBand];
    if (param)
    {
        float normalizedValue = (float)slider->valueToProportionOfLength(slider->getValue());
        if (std::abs(param->getValue() - normalizedValue) > 1e-6)
        {
            param->setValueNotifyingHost(normalizedValue);
        }

        sliderAnimations[slider].current = normalizedValue;
        sliderAnimations[slider].target = normalizedValue;
    }
}

void ChromaTapeSlotEditor::updateSliderTargets()
{
    for (auto& pair : sliderParams)
    {
        juce::Slider* slider = pair.first;
        auto* param = pair.second[currentBand];
        if (param)
        {
            slider->setNormalisableRange(LayoutHelpers::toDoubleRange(param->getNormalisableRange()));
            sliderAnimations[slider].target = param->getValue();
        }
    }
}

void ChromaTapeSlotEditor::setupSliders()
{
    auto configureSlider = [&](VerticalSliderWithLabel& vSlider)
        {
            juce::Slider& slider = vSlider.getSlider();
            slider.onValueChange = [this, &slider] { sliderValueChanged(&slider); };
        };

    configureSlider(saturationSlider);
    configureSlider(wowSlider);
    configureSlider(flutterSlider);
}

void ChromaTapeSlotEditor::setupButtons()
{
    addAndMakeVisible(lowButton);
    addAndMakeVisible(midButton);
    addAndMakeVisible(highButton);
    const int radioGroup = 1001;
    lowButton.setRadioGroupId(radioGroup);
    midButton.setRadioGroupId(radioGroup);
    highButton.setRadioGroupId(radioGroup);
    lowButton.setClickingTogglesState(true);
    midButton.setClickingTogglesState(true);
    highButton.setClickingTogglesState(true);

    auto* laf = &getLookAndFeel();
    lowButton.setLookAndFeel(laf);
    midButton.setLookAndFeel(laf);
    highButton.setLookAndFeel(laf);
    lowButton.onClick = [this] { bandButtonClicked(0); };
    midButton.onClick = [this] { bandButtonClicked(1); };
    highButton.onClick = [this] { bandButtonClicked(2); };
}

void ChromaTapeSlotEditor::initializeAnimations()
{
    for (auto& pair : sliderParams)
    {
        juce::Slider* slider = pair.first;
        auto* param = pair.second[0];
        if (param)
        {
            slider->setNormalisableRange(LayoutHelpers::toDoubleRange(param->getNormalisableRange()));
        }
    }

    updateSliderTargets();
    for (auto& pair : sliderAnimations)
    {
        pair.second.current = pair.second.target;
        juce::Slider* slider = pair.first;
        slider->setValue(slider->proportionOfLengthToValue(pair.second.current), juce::dontSendNotification);
    }
}

//==============================================================================
// MorphoCompSlotEditor Implementation
//==============================================================================
MorphoCompSlotEditor::MorphoCompSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix)
    : SlotEditorBase(apvts, paramPrefix),
    amountKnob(apvts, paramPrefix + "MORPHO_AMOUNT", "Amount"),
    responseKnob(apvts, paramPrefix + "MORPHO_RESPONSE", "Response"),
    mixKnob(apvts, paramPrefix + "MORPHO_MIX", "Mix"),
    morphXKnob(apvts, paramPrefix + "MORPHO_X", "Morph X"),
    morphYKnob(apvts, paramPrefix + "MORPHO_Y", "Morph Y")

{
    addAndMakeVisible(amountKnob);
    addAndMakeVisible(responseKnob);
    addAndMakeVisible(mixKnob);
    addAndMakeVisible(morphXKnob);
    addAndMakeVisible(morphYKnob);

    modeBox.addItemList(apvts.getParameter(paramPrefix + "MORPHO_MODE")->getAllValueStrings(), 1);
    addAndMakeVisible(modeBox);
    modeAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, paramPrefix + "MORPHO_MODE", modeBox);
}

void MorphoCompSlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    modeBox.setBounds(bounds.removeFromTop(30).reduced(5, 0));


    juce::FlexBox fb;
    fb.flexWrap = juce::FlexBox::Wrap::wrap;
    fb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    fb.alignContent = juce::FlexBox::AlignContent::spaceAround;
    float basis = (float)bounds.getWidth() / 3.0f;
    fb.items.add(LayoutHelpers::createFlexKnob(amountKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(responseKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(mixKnob, basis));

    fb.items.add(LayoutHelpers::createFlexKnob(morphXKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(morphYKnob, basis));

    fb.performLayout(bounds);
}

//==============================================================================
// SpectralAnimatorSlotEditor Implementation
//==============================================================================
SpectralAnimatorSlotEditor::SpectralAnimatorSlotEditor(juce::AudioProcessorValueTreeState& apvtsRef, const juce::String& paramPrefix)
    : SlotEditorBase(apvtsRef, paramPrefix),
    specAnimPrefix(paramPrefix + "SPECANIM_"),
    pitchKnob(apvts, specAnimPrefix + "PITCH", "Pitch"),
    formantXKnob(apvts, specAnimPrefix + "FORMANT_X", "Formant X"),
    formantYKnob(apvts, specAnimPrefix + "FORMANT_Y", "Formant Y"),
    morphKnob(apvts, specAnimPrefix + "MORPH", "Morph"),
    transientKnob(apvts, specAnimPrefix + "TRANSIENT_PRESERVE", "Transients")
{
    addAndMakeVisible(pitchKnob);
    addAndMakeVisible(formantXKnob);
    addAndMakeVisible(formantYKnob);
    addAndMakeVisible(morphKnob);
    addAndMakeVisible(transientKnob);

    // Setup Mode ComboBox
    if (auto* modeParam = apvts.getParameter(specAnimPrefix + "MODE"))
    {
        modeBox.addItemList(modeParam->getAllValueStrings(), 1);
        addAndMakeVisible(modeBox);
        modeAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(apvts, specAnimPrefix + "MODE", modeBox);
    }

    // Register listener for mode changes
    apvts.addParameterListener(specAnimPrefix + "MODE", this);
    updateVisibilities(); // Initial visibility setup
}

SpectralAnimatorSlotEditor::~SpectralAnimatorSlotEditor()
{
    apvts.removeParameterListener(specAnimPrefix + "MODE", this);
}

void SpectralAnimatorSlotEditor::resized()
{
    auto bounds = getLocalBounds().reduced(10);
    if (modeBox.isVisible())
        modeBox.setBounds(bounds.removeFromTop(30).reduced(5, 0));

    juce::FlexBox fb;
    fb.flexWrap = juce::FlexBox::Wrap::wrap;
    fb.justifyContent = juce::FlexBox::JustifyContent::spaceAround;
    fb.alignContent = juce::FlexBox::AlignContent::spaceAround;

    float basis = (float)bounds.getWidth() / 3.0f;

    if (pitchKnob.isVisible()) fb.items.add(LayoutHelpers::createFlexKnob(pitchKnob, basis));
    if (formantXKnob.isVisible()) fb.items.add(LayoutHelpers::createFlexKnob(formantXKnob, basis));
    if (formantYKnob.isVisible()) fb.items.add(LayoutHelpers::createFlexKnob(formantYKnob, basis));

    fb.items.add(LayoutHelpers::createFlexKnob(morphKnob, basis));
    fb.items.add(LayoutHelpers::createFlexKnob(transientKnob, basis));

    fb.performLayout(bounds);
}
void SpectralAnimatorSlotEditor::parameterChanged(const juce::String& parameterID, float newValue)
{
    if (parameterID == specAnimPrefix + "MODE")
    {
        updateVisibilities();
    }
    juce::ignoreUnused(newValue);
}

void SpectralAnimatorSlotEditor::updateVisibilities()
{
    if (auto* modeParam = apvts.getRawParameterValue(specAnimPrefix + "MODE"))
    {
        auto mode = static_cast<int>(modeParam->load());
        pitchKnob.setVisible(mode == 0); // Pitch Mode
        formantXKnob.setVisible(mode == 1); // Formant Mode
        formantYKnob.setVisible(mode == 1);
    }

    if (getWidth() > 0 && getHeight() > 0)
        resized();
}

================================================================================
// File: UI/SlotEditors.h
================================================================================

﻿//================================================================================
// File: UI/SlotEditors.h
//================================================================================
#pragma once
#include <JuceHeader.h>
#include "ParameterUIs.h"
#include "../FX_Modules/FilterProcessor.h"
#include <map>

// ... (namespace LayoutHelpers remains the same) ...
namespace LayoutHelpers {
    constexpr float minKnobWidth = 50.0f;
    constexpr float labelHeight = 20.0f;
    constexpr float minKnobHeight = minKnobWidth + labelHeight;

    inline juce::FlexItem createFlexKnob(juce::Component& component, float basis) {
        return juce::FlexItem(component)
            .withFlex(1.0f, 1.0f, basis)
            .withMinWidth(minKnobWidth)
            .withMinHeight(minKnobHeight);
    }

    inline juce::NormalisableRange<double> toDoubleRange(const juce::NormalisableRange<float>& range)
    {
        return juce::NormalisableRange<double>(
            (double)range.start,
            (double)range.end,
            [range](double start, double end, double normalized) {
                juce::ignoreUnused(start, end);
                return (double)range.convertFrom0to1((float)normalized);
            },
            [range](double start, double end, double value) {
                juce::ignoreUnused(start, end);
                return (double)range.convertTo0to1((float)value);
            },
            [range](double start, double end, double value) {
                juce::ignoreUnused(start, end);
                return (double)range.snapToLegalValue((float)value);
            }
        );
    }
}


// ... (SlotEditorBase and other editor class definitions remain) ...
class SlotEditorBase : public juce::Component
{
public:
    SlotEditorBase(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix)
        : apvts(apvts), paramPrefix(paramPrefix) {
    }
protected:
    juce::AudioProcessorValueTreeState& apvts;
    juce::String paramPrefix;
};

//==============================================================================
// Standard Editors
//==============================================================================

class DistortionSlotEditor : public SlotEditorBase,
    private juce::AudioProcessorValueTreeState::Listener
{
public:
    DistortionSlotEditor(juce::AudioProcessorValueTreeState& apvtsRef, const juce::String& paramPrefix);
    ~DistortionSlotEditor() override;
    void resized() override;
private:
    void parameterChanged(const juce::String&, float) override;
    void updateVisibilities();

    RotaryKnobWithLabels driveKnob, levelKnob, biasKnob, characterKnob;
    juce::ComboBox typeBox;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> typeAttachment;
};

class FilterSlotEditor : public SlotEditorBase,
    private juce::AudioProcessorValueTreeState::Listener
{
public:
    FilterSlotEditor(juce::AudioProcessorValueTreeState& apvtsRef, const juce::String& paramPrefix);
    ~FilterSlotEditor() override;
    void resized() override;
private:
    void parameterChanged(const juce::String&, float) override;
    void updateVisibilities();

    RotaryKnobWithLabels cutoffKnob, resonanceKnob, driveKnob;
    juce::ComboBox profileBox, typeBox;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> profileAttachment, typeAttachment;
};

class AdvancedDelaySlotEditor : public SlotEditorBase
{
public:
    AdvancedDelaySlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix);
    void resized() override;
private:
    juce::String advDelayPrefix;
    RotaryKnobWithLabels timeKnob, feedbackKnob, mixKnob, colorKnob, wowKnob, flutterKnob, ageKnob;
    juce::ComboBox modeBox;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> modeAttachment;
};

class ModulationSlotEditor : public SlotEditorBase
{
public:
    ModulationSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix);
    void resized() override;
private:
    RotaryKnobWithLabels rateKnob, depthKnob, feedbackKnob, mixKnob;
    juce::ComboBox modeBox;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> modeAttachment;
};

class ReverbSlotEditor : public SlotEditorBase
{
public:
    ReverbSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix);
    void resized() override;
private:
    RotaryKnobWithLabels roomSizeKnob, dampingKnob, mixKnob, widthKnob;
};

class AdvancedCompressorSlotEditor : public SlotEditorBase
{
public:
    AdvancedCompressorSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix);
    void resized() override;
private:
    juce::String advCompPrefix;
    RotaryKnobWithLabels thresholdKnob, ratioKnob, attackKnob, releaseKnob, makeupKnob;
    juce::ComboBox topologyBox, detectorBox;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> topologyAttachment, detectorAttachment;
};

class ChromaTapeSlotEditor : public SlotEditorBase,
    private juce::Timer
{
public:
    ChromaTapeSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix);
    ~ChromaTapeSlotEditor() override;
    void resized() override;
private:
    void timerCallback() override;
    void bandButtonClicked(int bandIndex);
    void sliderValueChanged(juce::Slider* slider);
    void updateSliderTargets();
    void setupSliders();
    void setupButtons();
    void initializeAnimations();

    juce::String ctPrefix;
    int currentBand = 0;
    RotaryKnobWithLabels lowMidCrossKnob, midHighCrossKnob;
    VerticalSliderWithLabel saturationSlider, wowSlider, flutterSlider;
    juce::TextButton lowButton{ "Low" }, midButton{ "Mid" }, highButton{ "High" };
    struct AnimationState { float current = 0.0f; float target = 0.0f; };
    std::map<juce::Slider*, AnimationState> sliderAnimations;
    std::map<juce::Slider*, std::array<juce::RangedAudioParameter*, 3>> sliderParams;
};

class MorphoCompSlotEditor : public SlotEditorBase
{
public:
    MorphoCompSlotEditor(juce::AudioProcessorValueTreeState& apvts, const juce::String& paramPrefix);
    void resized() override;
private:
    RotaryKnobWithLabels amountKnob, responseKnob, mixKnob, morphXKnob, morphYKnob;
    juce::ComboBox modeBox;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> modeAttachment;
};

class SpectralAnimatorSlotEditor : public SlotEditorBase,
    private juce::AudioProcessorValueTreeState::Listener
{
public:
    SpectralAnimatorSlotEditor(juce::AudioProcessorValueTreeState& apvtsRef, const juce::String& paramPrefix);
    ~SpectralAnimatorSlotEditor() override;
    void resized() override;
private:
    void parameterChanged(const juce::String& parameterID, float newValue) override;
    void updateVisibilities();

    juce::String specAnimPrefix;
    RotaryKnobWithLabels pitchKnob, formantXKnob, formantYKnob, morphKnob, transientKnob;
    juce::ComboBox modeBox;
    std::unique_ptr<juce::AudioProcessorValueTreeState::ComboBoxAttachment> modeAttachment;
};

================================================================================
// File: UI/UIConfig.h
================================================================================

#pragma once
#include <JuceHeader.h>

namespace UIConfig
{
    const juce::Colour PRIMARY_COLOUR = juce::Colour(0xffFFD700); // Gold/Yellow
    const juce::Colour BACKGROUND_COLOUR = juce::Colour(0xff282828);
}

================================================================================
// File: UI/XYPad.h
================================================================================

// File: XYPad.h
#pragma once
#include <JuceHeader.h>
// Assuming UIConfig.h exists and defines UIConfig::PRIMARY_COLOUR
#include "UIConfig.h"

class XYPad : public juce::Component, public juce::Slider::Listener
{
public:
    // Public hidden sliders required for APVTS attachment
    juce::Slider xSlider;
    juce::Slider ySlider;

    XYPad()
    {
        configureSlider(xSlider);
        configureSlider(ySlider);
        // Initialize internal state using public API
        normX = (float)xSlider.valueToProportionOfLength(xSlider.getValue());
        normY = (float)ySlider.valueToProportionOfLength(ySlider.getValue());
    }

    void paint(juce::Graphics& g) override
    {
        auto bounds = getPaddedBounds();

        // Define colors
        juce::Colour primaryColour = juce::Colours::yellow;
        juce::Colour secondaryColour = juce::Colours::grey;
#ifdef UIConfig_h
        primaryColour = UIConfig::PRIMARY_COLOUR;
#endif

        // Background grid visualization
        g.setColour(secondaryColour.darker(0.5f));
        g.drawRect(bounds, 2.0f);

        g.setColour(secondaryColour.withAlpha(0.3f));
        g.drawLine(bounds.getCentreX(), bounds.getY(), bounds.getCentreX(), bounds.getBottom());
        g.drawLine(bounds.getX(), bounds.getCentreY(), bounds.getRight(), bounds.getCentreY());

        // The Dot (Puck)
        float dotRadius = 8.0f;
        // Calculate position based on normalized values.
        float posX = bounds.getX() + normX * bounds.getWidth();
        // Y axis is inverted in graphics (0.0 is top), but parameters assume 0.0 is bottom.
        float posY = bounds.getY() + (1.0f - normY) * bounds.getHeight();

        // Use the primary colour (yellow) for the dot
        g.setColour(primaryColour);
        g.fillEllipse(posX - dotRadius, posY - dotRadius, dotRadius * 2.0f, dotRadius * 2.0f);
    }

    // --- Interaction Logic (Using Public API) ---
    void mouseDown(const juce::MouseEvent& event) override
    {
        // FIX: Use startedDragging() for automation gestures.
        xSlider.startedDragging();
        ySlider.startedDragging();
        // Immediately update position to the click location
        mouseDrag(event);
    }

    void mouseUp(const juce::MouseEvent& event) override
    {
        // FIX: Use stoppedDragging() for automation gestures.
        xSlider.stoppedDragging();
        ySlider.stoppedDragging();
    }

    void mouseDrag(const juce::MouseEvent& event) override
    {
        auto bounds = getPaddedBounds();
        if (bounds.getWidth() <= 0 || bounds.getHeight() <= 0) return;

        // Calculate normalized position based on mouse coordinates relative to the padded bounds
        float newNormX = (event.position.x - bounds.getX()) / bounds.getWidth();
        // Invert Y axis calculation (Graphics Y=0 is top, Parameter Y=0 is bottom)
        float newNormY = 1.0f - ((event.position.y - bounds.getY()) / bounds.getHeight());

        // Clamp values
        newNormX = juce::jlimit(0.0f, 1.0f, newNormX);
        newNormY = juce::jlimit(0.0f, 1.0f, newNormY);

        // FIX: Update sliders by converting normalized values back to actual values.
        double newXValue = xSlider.proportionOfLengthToValue(newNormX);
        double newYValue = ySlider.proportionOfLengthToValue(newNormY);

        // Set the value. sendNotification is crucial.
        xSlider.setValue(newXValue, juce::sendNotification);
        ySlider.setValue(newYValue, juce::sendNotification);
    }

    void sliderValueChanged(juce::Slider* slider) override
    {
        // Update internal normalized values when parameters change
        // FIX: Use public API for normalization.
        if (slider == &xSlider)
            normX = (float)xSlider.valueToProportionOfLength(xSlider.getValue());
        else if (slider == &ySlider)
            normY = (float)ySlider.valueToProportionOfLength(ySlider.getValue());

        // CRUCIAL: Repaint the component to move the dot visually
        repaint();
    }

private:
    // Internal tracking of normalized positions
    float normX = 0.5f;
    float normY = 0.5f;
    // Add padding so the dot isn't clipped at the edges
    const float padding = 5.0f;

    juce::Rectangle<float> getPaddedBounds() const
    {
        return getLocalBounds().toFloat().reduced(padding);
    }

    void configureSlider(juce::Slider& slider)
    {
        slider.setSliderStyle(juce::Slider::LinearHorizontal);
        slider.setTextBoxStyle(juce::Slider::NoTextBox, true, 0, 0);
        // DO NOT set range manually. Let the attachment handle it.
        slider.addListener(this);
        addAndMakeVisible(slider);
        slider.setVisible(false);
    }
};

